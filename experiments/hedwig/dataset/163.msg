Return-Path: <no-reply@arXiv.org>
Received: from lib-arxiv-015.serverfarm.cornell.edu (mail.arxiv.org
 [128.84.4.11]) by mail.kth-assert.net with ESMTP id 132;
 Tue, 11 Feb 2020 14:50:35 +0000 (UTC)
Received: from lib-arxiv-007.serverfarm.cornell.edu
 (lib-arxiv-007.serverfarm.cornell.edu [128.84.4.12])
 by lib-arxiv-015.serverfarm.cornell.edu (8.14.4/8.14.4) with ESMTP id
 01A95Dh2039752; Mon, 10 Feb 2020 04:05:13 -0500
Received: from lib-arxiv-007.serverfarm.cornell.edu (localhost [127.0.0.1])
 by lib-arxiv-007.serverfarm.cornell.edu (8.14.4/8.14.4) with ESMTP id
 01A95DsG051042; Mon, 10 Feb 2020 04:05:13 -0500
Received: (from e-prints@localhost)
 by lib-arxiv-007.serverfarm.cornell.edu (8.14.4/8.14.4/Submit) id
 01A955or050926; Mon, 10 Feb 2020 04:05:05 -0500
Date: Mon, 10 Feb 2020 04:05:05 -0500
Message-Id: <202002100905.01A955or050926@lib-arxiv-007.serverfarm.cornell.edu>
X-Authentication-Warning: lib-arxiv-007.serverfarm.cornell.edu: e-prints set
 sender to no-reply@arXiv.org using -f
Precedence: bulk
From: no-reply@arXiv.org (send mail ONLY to cs)
Reply-To: cs@arXiv.org
To: rabble@arXiv.org (cs daily title/abstract distribution)
Subject: cs daily Subj-class mailing 3ffffffff 126

------------------------------------------------------------------------------
------------------------------------------------------------------------------
Send any comments regarding submissions directly to submitter.
------------------------------------------------------------------------------
Archives at http://arxiv.org/
To unsubscribe, e-mail To: cs@arXiv.org, Subject: cancel
------------------------------------------------------------------------------
 Submissions to:
Artificial Intelligence
Computational Complexity
Computational Engineering, Finance, and Science
Computational Geometry
Computation and Language
Cryptography and Security
Computer Vision and Pattern Recognition
Computers and Society
Databases
Distributed, Parallel, and Cluster Computing
Digital Libraries
Discrete Mathematics
Data Structures and Algorithms
Emerging Technologies
Formal Languages and Automata Theory
Graphics
Computer Science and Game Theory
Human-Computer Interaction
Information Retrieval
Information Theory
Machine Learning
Logic in Computer Science
Multiagent Systems
Multimedia
Numerical Analysis
Neural and Evolutionary Computing
Networking and Internet Architecture
Programming Languages
Robotics
Symbolic Computation
Sound
Software Engineering
Social and Information Networks
Systems and Control
 received from  Thu  6 Feb 20 19:00:00 GMT  to  Fri  7 Feb 20 19:00:00 GMT
------------------------------------------------------------------------------
------------------------------------------------------------------------------
\\
arXiv:2002.02697
Date: Fri, 7 Feb 2020 10:08:18 GMT   (840kb,D)

Title: Accelerating Reinforcement Learning for Reaching using Continuous
  Curriculum Learning
Authors: Sha Luo, Hamidreza Kasaei, Lambert Schomaker
Categories: cs.AI cs.RO
\\
  Reinforcement learning has shown great promise in the training of robot
behavior due to the sequential decision making characteristics. However, the
required enormous amount of interactive and informative training data provides
the major stumbling block for progress. In this study, we focus on accelerating
reinforcement learning (RL) training and improving the performance of
multi-goal reaching tasks. Specifically, we propose a precision-based
continuous curriculum learning (PCCL) method in which the requirements are
gradually adjusted during the training process, instead of fixing the parameter
in a static schedule. To this end, we explore various continuous curriculum
strategies for controlling a training process. This approach is tested using a
Universal Robot 5e in both simulation and real-world multi-goal reach
experiments. Experimental results support the hypothesis that a static training
schedule is suboptimal, and using an appropriate decay function for curriculum
learning provides superior results in a faster way.
\\ ( https://arxiv.org/abs/2002.02697 ,  840kb)
------------------------------------------------------------------------------
\\
arXiv:2002.02878
Date: Fri, 7 Feb 2020 16:22:36 GMT   (4275kb,D)

Title: I love your chain mail! Making knights smile in a fantasy game world:
  Open-domain goal-orientated dialogue agents
Authors: Shrimai Prabhumoye and Margaret Li and Jack Urbanek and Emily Dinan
  and Douwe Kiela and Jason Weston and Arthur Szlam
Categories: cs.AI cs.CL stat.ML
\\
  Dialogue research tends to distinguish between chit-chat and goal-oriented
tasks. While the former is arguably more naturalistic and has a wider use of
language, the latter has clearer metrics and a straightforward learning signal.
Humans effortlessly combine the two, for example engaging in chit-chat with the
goal of exchanging information or eliciting a specific response. Here, we
bridge the divide between these two domains in the setting of a rich
multi-player text-based fantasy environment where agents and humans engage in
both actions and dialogue. Specifically, we train a goal-oriented model with
reinforcement learning against an imitation-learned ``chit-chat'' model with
two approaches: the policy either learns to pick a topic or learns to pick an
utterance given the top-K utterances from the chit-chat model. We show that
both models outperform an inverse model baseline and can converse naturally
with their dialogue partner in order to achieve goals.
\\ ( https://arxiv.org/abs/2002.02878 ,  4275kb)
------------------------------------------------------------------------------
\\
arXiv:2002.02938
Date: Fri, 7 Feb 2020 18:15:51 GMT   (196kb,D)

Title: Student/Teacher Advising through Reward Augmentation
Authors: Cameron Reid
Categories: cs.AI
\\
  Transfer learning is an important new subfield of multiagent reinforcement
learning that aims to help an agent learn about a problem by using knowledge
that it has gained solving another problem, or by using knowledge that is
communicated to it by an agent who already knows the problem. This is useful
when one wishes to change the architecture or learning algorithm of an agent
(so that the new knowledge need not be built "from scratch"), when new agents
are frequently introduced to the environment with no knowledge, or when an
agent must adapt to similar but different problems. Great progress has been
made in the agent-to-agent case using the Teacher/Student framework proposed by
(Torrey and Taylor 2013). However, that approach requires that learning from a
teacher be treated differently from learning in every other reinforcement
learning context. In this paper, I propose a method which allows the
teacher/student framework to be applied in a way that fits directly and
naturally into the more general reinforcement learning framework by integrating
the teacher feedback into the reward signal received by the learning agent. I
show that this approach can significantly improve the rate of learning for an
agent playing a one-player stochastic game; I give examples of potential
pitfalls of the approach; and I propose further areas of research building on
this framework.
\\ ( https://arxiv.org/abs/2002.02938 ,  196kb)
------------------------------------------------------------------------------
\\
arXiv:2002.02729
Date: Fri, 7 Feb 2020 12:06:41 GMT   (22kb)

Title: On List k-Coloring Convex Bipartite Graphs
Authors: Josep D\'iaz, \"Oznur Ya\c{s}ar Diner, Maria Serna, Oriol Serra
Categories: cs.CC cs.DM math.CO
\\
  List k-Coloring (Li k-Col) is the decision problem asking if a given graph
admits a proper coloring compatible with a given list assignment to its
vertices with colors in {1,2,..,k}. The problem is known to be NP-hard even for
k=3 within the class of 3-regular planar bipartite graphs and for k=4 within
the class of chordal bipartite graphs. In 2015, Huang, Johnson and Paulusma
asked for the complexity of Li 3-Col in the class of chordal bipartite graphs.
In this paper we give a partial answer to this question by showing that Li
k-Col is polynomial in the class of convex bipartite graphs. We show first that
biconvex bipartite graphs admit a multichain ordering, extending the classes of
graphs where a polynomial algorithm of Enright, Stewart and Tardos (2014) can
be applied to the problem. We provide a dynamic programming algorithm to solve
the Li k-Col in the calss of convex bipartite graphs. Finally we show how our
algorithm can be modified to solve the more general Li H-Col problem on convex
bipartite graphs.
\\ ( https://arxiv.org/abs/2002.02729 ,  22kb)
------------------------------------------------------------------------------
\\
arXiv:2002.02450
Date: Wed, 5 Feb 2020 22:56:12 GMT   (196kb,D)

Title: Goal-Oriented Multi-Task BERT-Based Dialogue State Tracker
Authors: Pavel Gulyaev, Eugenia Elistratova, Vasily Konovalov, Yuri Kuratov,
  Leonid Pugachev, Mikhail Burtsev
Categories: cs.CL cs.LG stat.ML
\\
  Dialogue State Tracking (DST) is a core component of virtual assistants such
as Alexa or Siri. To accomplish various tasks, these assistants need to support
an increasing number of services and APIs. The Schema-Guided State Tracking
track of the 8th Dialogue System Technology Challenge highlighted the DST
problem for unseen services. The organizers introduced the Schema-Guided
Dialogue (SGD) dataset with multi-domain conversations and released a zero-shot
dialogue state tracking model. In this work, we propose a GOaL-Oriented
Multi-task BERT-based dialogue state tracker (GOLOMB) inspired by architectures
for reading comprehension question answering systems. The model "queries"
dialogue history with descriptions of slots and services as well as possible
values of slots. This allows to transfer slot values in multi-domain dialogues
and have a capability to scale to unseen slot types. Our model achieves a joint
goal accuracy of 53.97% on the SGD dataset, outperforming the baseline model.
\\ ( https://arxiv.org/abs/2002.02450 ,  196kb)
------------------------------------------------------------------------------
\\
arXiv:2002.02511
Date: Thu, 6 Feb 2020 20:44:12 GMT   (191kb,D)

Title: Introducing Aspects of Creativity in Automatic Poetry Generation
Authors: Brendan Bena and Jugal Kalita
Categories: cs.CL cs.AI cs.LG
Comments: 10 pages, 10 figures, 4 tables, ICON-2019
\\
  Poetry Generation involves teaching systems to automatically generate text
that resembles poetic work. A deep learning system can learn to generate poetry
on its own by training on a corpus of poems and modeling the particular style
of language. In this paper, we propose taking an approach that fine-tunes
GPT-2, a pre-trained language model, to our downstream task of poetry
generation. We extend prior work on poetry generation by introducing creative
elements. Specifically, we generate poems that express emotion and elicit the
same in readers, and poems that use the language of dreams---called dream
poetry. We are able to produce poems that correctly elicit the emotions of
sadness and joy 87.5 and 85 percent, respectively, of the time. We produce
dreamlike poetry by training on a corpus of texts that describe dreams. Poems
from this model are shown to capture elements of dream poetry with scores of no
less than 3.2 on the Likert scale. We perform crowdsourced human-evaluation for
all our poems. We also make use of the Coh-Metrix tool, outlining metrics we
use to gauge the quality of text generated.
\\ ( https://arxiv.org/abs/2002.02511 ,  191kb)
------------------------------------------------------------------------------
\\
arXiv:2002.02631
Date: Fri, 7 Feb 2020 05:52:06 GMT   (213kb,D)

Title: Translating Web Search Queries into Natural Language Questions
Authors: Adarsh Kumar, Sandipan Dandapat, Sushil Chordia
Categories: cs.CL cs.AI
Comments: Eleventh International Conference on Language Resources and
  Evaluation, LREC 2018
\\
  Users often query a search engine with a specific question in mind and often
these queries are keywords or sub-sentential fragments. For example, if the
users want to know the answer for "What's the capital of USA", they will most
probably query "capital of USA" or "USA capital" or some keyword-based
variation of this. For example, for the user entered query "capital of USA",
the most probable question intent is "What's the capital of USA?". In this
paper, we are proposing a method to generate well-formed natural language
question from a given keyword-based query, which has the same question intent
as the query. Conversion of keyword-based web query into a well-formed question
has lots of applications, with some of them being in search engines, Community
Question Answering (CQA) website and bots communication. We found a synergy
between query-to-question problem with standard machine translation(MT) task.
We have used both Statistical MT (SMT) and Neural MT (NMT) models to generate
the questions from the query. We have observed that MT models perform well in
terms of both automatic and human evaluation.
\\ ( https://arxiv.org/abs/2002.02631 ,  213kb)
------------------------------------------------------------------------------
\\
arXiv:2002.02649
Date: Fri, 7 Feb 2020 07:19:15 GMT   (7327kb,D)

Title: Multimodal Matching Transformer for Live Commenting
Authors: Chaoqun Duan and Lei Cui and Shuming Ma and Furu Wei and Conghui Zhu
  and Tiejun Zhao
Categories: cs.CL
\\
  Automatic live commenting aims to provide real-time comments on videos for
viewers. It encourages users engagement on online video sites, and is also a
good benchmark for video-to-text generation. Recent work on this task adopts
encoder-decoder models to generate comments. However, these methods do not
model the interaction between videos and comments explicitly, so they tend to
generate popular comments that are often irrelevant to the videos. In this
work, we aim to improve the relevance between live comments and videos by
modeling the cross-modal interactions among different modalities. To this end,
we propose a multimodal matching transformer to capture the relationships among
comments, vision, and audio. The proposed model is based on the transformer
framework and can iteratively learn the attention-aware representations for
each modality. We evaluate the model on a publicly available live commenting
dataset. Experiments show that the multimodal matching transformer model
outperforms the state-of-the-art methods.
\\ ( https://arxiv.org/abs/2002.02649 ,  7327kb)
------------------------------------------------------------------------------
\\
arXiv:2002.02734
Date: Fri, 7 Feb 2020 12:26:41 GMT   (3248kb,D)

Title: Incorporating Visual Semantics into Sentence Representations within a
  Grounded Space
Authors: Patrick Bordes, Eloi Zablocki, Laure Soulier, Benjamin Piwowarski,
  Patrick Gallinari
Categories: cs.CL
\\
  Language grounding is an active field aiming at enriching textual
representations with visual information. Generally, textual and visual elements
are embedded in the same representation space, which implicitly assumes a
one-to-one correspondence between modalities. This hypothesis does not hold
when representing words, and becomes problematic when used to learn sentence
representations --- the focus of this paper --- as a visual scene can be
described by a wide variety of sentences. To overcome this limitation, we
propose to transfer visual information to textual representations by learning
an intermediate representation space: the grounded space. We further propose
two new complementary objectives ensuring that (1) sentences associated with
the same visual content are close in the grounded space and (2) similarities
between related elements are preserved across modalities. We show that this
model outperforms the previous state-of-the-art on classification and semantic
relatedness tasks.
\\ ( https://arxiv.org/abs/2002.02734 ,  3248kb)
------------------------------------------------------------------------------
\\
arXiv:2002.02755
Date: Mon, 3 Feb 2020 09:24:45 GMT   (663kb,D)

Title: On-Device Information Extraction from SMS using Hybrid Hierarchical
  Classification
Authors: Shubham Vatsal, Naresh Purre, Sukumar Moharana, Gopi Ramena, Debi
  Prasanna Mohanty
Categories: cs.CL cs.IR cs.LG
Comments: to be published in IEEE ICSC 2020 proceedings
\\
  Cluttering of SMS inbox is one of the serious problems that users today face
in the digital world where every online login, transaction, along with
promotions generate multiple SMS. This problem not only prevents users from
searching and navigating messages efficiently but often results in users
missing out the relevant information associated with the corresponding SMS like
offer codes, payment reminders etc. In this paper, we propose a unique
architecture to organize and extract the appropriate information from SMS and
further display it in an intuitive template. In the proposed architecture, we
use a Hybrid Hierarchical Long Short Term Memory (LSTM)-Convolutional Neural
Network (CNN) to categorize SMS into multiple classes followed by a set of
entity parsers used to extract the relevant information from the classified
message. The architecture using its preprocessing techniques not only takes
into account the enormous variations observed in SMS data but also makes it
efficient for its on-device (mobile phone) functionalities in terms of
inference timing and size.
\\ ( https://arxiv.org/abs/2002.02755 ,  663kb)
------------------------------------------------------------------------------
\\
arXiv:2002.02758
Date: Sun, 2 Feb 2020 07:15:18 GMT   (1695kb,D)

Title: Neural Machine Translation System of Indic Languages -- An Attention
  based Approach
Authors: Parth Shah, Vishvajit Bakrola
Categories: cs.CL cs.LG stat.ML
Journal-ref: 2019 Second International Conference on Advanced Computational and
  Communication Paradigms (ICACCP), Gangtok, India, 2019, pp. 1-5
DOI: 10.1109/ICACCP.2019.8882969
\\
  Neural machine translation (NMT) is a recent and effective technique which
led to remarkable improvements in comparison of conventional machine
translation techniques. Proposed neural machine translation model developed for
the Gujarati language contains encoder-decoder with attention mechanism. In
India, almost all the languages are originated from their ancestral language -
Sanskrit. They are having inevitable similarities including lexical and named
entity similarity. Translating into Indic languages is always be a challenging
task. In this paper, we have presented the neural machine translation system
(NMT) that can efficiently translate Indic languages like Hindi and Gujarati
that together covers more than 58.49 percentage of total speakers in the
country. We have compared the performance of our NMT model with automatic
evaluation matrices such as BLEU, perplexity and TER matrix. The comparison of
our network with Google translate is also presented where it outperformed with
a margin of 6 BLEU score on English-Gujarati translation.
\\ ( https://arxiv.org/abs/2002.02758 ,  1695kb)
------------------------------------------------------------------------------
\\
arXiv:2002.02925
Date: Fri, 7 Feb 2020 17:52:16 GMT   (1208kb,D)

Title: BERT-of-Theseus: Compressing BERT by Progressive Module Replacing
Authors: Canwen Xu and Wangchunshu Zhou and Tao Ge and Furu Wei and Ming Zhou
Categories: cs.CL cs.LG
Comments: 11 pages
\\
  In this paper, we propose a novel model compression approach to effectively
compress BERT by progressive module replacing. Our approach first divides the
original BERT into several modules and builds their compact substitutes. Then,
we randomly replace the original modules with their substitutes to train the
compact modules to mimic the behavior of the original modules. We progressively
increase the probability of replacement through the training. In this way, our
approach brings a deeper level of interaction between the original and compact
models, and smooths the training process. Compared to the previous knowledge
distillation approaches for BERT compression, our approach leverages only one
loss function and one hyper-parameter, liberating human effort from
hyper-parameter tuning. Our approach outperforms existing knowledge
distillation approaches on GLUE benchmark, showing a new perspective of model
compression.
\\ ( https://arxiv.org/abs/2002.02925 ,  1208kb)
------------------------------------------------------------------------------
\\
arXiv:2002.02955
Date: Fri, 7 Feb 2020 18:50:21 GMT   (151kb)

Title: A Multilingual View of Unsupervised Machine Translation
Authors: Xavier Garcia, Pierre Foret, Thibault Sellam, Ankur P. Parikh
Categories: cs.CL
\\
  We present a probabilistic framework for multilingual neural machine
translation that encompasses supervised and unsupervised setups, focusing on
unsupervised translation. In addition to studying the vanilla case where there
is only monolingual data available, we propose a novel setup where one language
in the (source, target) pair is not associated with any parallel data, but
there may exist auxiliary parallel data that contains the other. This auxiliary
data can naturally be utilized in our probabilistic framework via a novel
cross-translation loss term. Empirically, we show that our approach results in
higher BLEU scores over state-of-the-art unsupervised models on the WMT'14
English-French, WMT'16 English-German, and WMT'16 English-Romanian datasets in
most directions. In particular, we obtain a +1.65 BLEU advantage over the
best-performing unsupervised model in the Romanian-English direction.
\\ ( https://arxiv.org/abs/2002.02955 ,  151kb)
------------------------------------------------------------------------------
\\
arXiv:2002.02516
Date: Thu, 6 Feb 2020 21:19:32 GMT   (84kb)

Title: Succinctly Reconstructed Distributed Signatures and Balanced Byzantine
  Agreement
Authors: Elette Boyle and Ran Cohen and Aarushi Goel
Categories: cs.CR cs.DC
\\
  Byzantine agreement (BA), the task of $n$ parties to agree on one of their
input bits in the face of malicious agents, is a powerful primitive that lies
at the core of virtually every multi-party cryptographic protocol.
Interestingly, in protocols with the best overall communication complexity, the
communication demands of the parties are highly unbalanced: the amortized cost
is $\tilde O(1)$ bits per party, but some parties must send $\Omega(n)$ bits.
In best known balanced protocols, the overall communication is sub-optimal,
with each party communicating $\tilde O(\sqrt{n})$. In this work, we ask
whether asymmetry is inherent for optimizing total communication. Our
contributions in this line are as follows:
  1) We identify a cryptographic primitive, succinctly reconstructed
distributed signatures (SRDS), that suffices for constructing $\tilde O(1)$
balanced BA. We provide two constructions of SRDS from different cryptographic
and Public-Key Infrastructure (PKI) assumptions.
  2) The SRDS-based BA follows a paradigm of boosting from "almost-everywhere"
agreement to full agreement, and does so in a single round. We prove that PKI
setup and cryptographic assumptions are necessary for such protocols in which
every party sends $o(n)$ messages.
  3) We further explore connections between a natural approach toward attaining
SRDS and average-case succinct non-interactive argument systems for a
particular type of "Subset-$f$" problems (generalizing Subset-Sum and
Subset-Product).
  Collectively, our results provide an initial mapping for the feasibility
landscape of $\tilde O(1)$ balanced BA, including new approaches forward, as
well as limitations and barriers. Our approach yields the first two BA
protocols with $\tilde O(1)$ balanced communication, offering a tradeoff
between setup and cryptographic assumptions, and answering an open question
presented by King and Saia (DISC'09).
\\ ( https://arxiv.org/abs/2002.02516 ,  84kb)
------------------------------------------------------------------------------
\\
arXiv:2002.02519
Date: Thu, 6 Feb 2020 21:45:42 GMT   (829kb,D)

Title: Data-Driven False Data Injection Attacks Against Power Grid: A Random
  Matrix Approach
Authors: Subhash Lakshminarayana, Abla Kammoun, Merouane Debbah and H. Vincent
  Poor
Categories: cs.CR cs.IT cs.SY eess.SP eess.SY math.IT
\\
  We address the problem of constructing false data injection (FDI) attacks
that can bypass the bad data detector (BDD) of a power grid. The attacker is
assumed to have access to only power flow measurement data traces (collected
over a limited period of time) and no other prior knowledge about the grid.
Existing related algorithms are formulated under the assumption that the
attacker has access to measurements collected over a long (asymptotically
infinite) time period, which may not be realistic. We show that these
approaches do not perform well when the attacker has a limited number of data
samples only. We design an enhanced algorithm to construct FDI attack vectors
in the face of limited measurements that can nevertheless bypass the BDD with
high probability. The algorithm design is guided by results from random matrix
theory. Furthermore, we characterize an important trade-off between the
attack's BDD-bypass probability and its sparsity, which affects the spatial
extent of the attack that must be achieved. Extensive simulations using data
traces collected from the MATPOWER simulator and benchmark IEEE bus systems
validate our findings.
\\ ( https://arxiv.org/abs/2002.02519 ,  829kb)
------------------------------------------------------------------------------
\\
arXiv:2002.02696
Date: Fri, 7 Feb 2020 10:06:44 GMT   (216kb,D)

Title: Protograph-Based Decoding of LDPC Codes with Hamming Weight Amplifiers
Authors: Hannes Bartz, Emna Ben Yacoub, Lorenza Bertarelli, Gianluigi Liva
Categories: cs.CR cs.IT math.IT
\\
  A new protograph-based framework for message passing (MP) decoding of low
density parity-check (LDPC) codes with Hamming weight amplifiers (HWAs), which
are used e.g. in the NIST post-quantum crypto candidate LEDAcrypt, is proposed.
The scheme exploits the correlations in the error patterns introduced by the
HWA using a turbo-like decoding approach where messages between the decoders
for the outer code given by the HWA and the inner LDPC code are exchanged.
Decoding thresholds for the proposed scheme are computed using density
evolution (DE) analysis for belief propagation (BP) and ternary message passing
(TMP) decoding and compared to existing decoding approaches. The proposed
scheme improves upon the basic approach of decoding LDPC code from the
amplified error and has a similar performance as decoding the corresponding
moderate-density parity-check (MDPC) code but with a significantly lower
computational complexity.
\\ ( https://arxiv.org/abs/2002.02696 ,  216kb)
------------------------------------------------------------------------------
\\
arXiv:2002.02780
Date: Fri, 7 Feb 2020 13:38:30 GMT   (84kb,D)

Title: Assuring Automotive Data and Software Integrity Employing Distributed
  Hash Tables and Blockchain
Authors: Gregory Falco, Joshua E. Siegel
Categories: cs.CR cs.DC
Comments: 9 pages, 1 figure
\\
  Automotive software is increasingly complex and critical to safe vehicle
operation, and related embedded systems must remain up-to-date to ensure
long-term system performance. Update mechanisms introduce opportunities for
malicious actors to compromise these cyber-physical systems, and for trusted
actors to accidentally install incompatible software versions. An automotive
software and data provenance mechanism is proposed to assure users, service
providers, and original equipment manufacturers (OEMs) of vehicular software
integrity and reliability. The proposed approach employs the use of distributed
hash tables (DHT) and a public blockchain to provide high assurance,
scalability, and efficiency.
\\ ( https://arxiv.org/abs/2002.02780 ,  84kb)
------------------------------------------------------------------------------
\\
arXiv:2002.02831
Date: Fri, 7 Feb 2020 15:07:00 GMT   (400kb,D)

Title: SMA: Eliminate Memory Spatial Errors via Saturation Memory Access
Authors: Dongwei Chen, Daliang Xu, Dong Tong, Kang Sun, Xuetao Guan, Chun Yang,
  Xu Cheng
Categories: cs.CR
\\
  Memory spatial error, i.e., buffer overflow, has been a well-known issue in
computer security for a long time and remains one of the root causes of
exploitable vulnerabilities. Existing tools focus on the detection of memory
spatial errors and prevent intrusion by terminating the execution of the victim
program. However, such tools cannot eliminate the vulnerabilities without
patching the program. Unfortunately, in the increasingly popular embedded
environment, deploying patches becomes harder because of the enormous number of
devices. The limited resource in the embedded environment also prevents many
existing tools to be used in the real world.
  This paper proposes the Saturation Memory Access (SMA), a memory spatial
error elimination tool that prevents out-of-bound access without terminating
the execution of a program. We use the tagged pointer scheme to store the
boundary metadata of a memory object in the pointer itself, and correct the
address to the object boundary upon detecting out-of-bound access. This method
is based on a key observation that developers generally do not rely on
out-of-bounds access to implement the program logic, so the correction of the
address does not interfere with the execution of a program.
  We have implemented the prototype of SMA on LLVM 4.0.1 with two pointer
encoding schemes designed for different tradeoff decisions between performance
and memory usage. Experiments show that our prototype can stop nearly all
attack forms in the RIPE benchmark and incurs 64\%-84\% overhead on SPEC
CPU2017.
\\ ( https://arxiv.org/abs/2002.02831 ,  400kb)
------------------------------------------------------------------------------
\\
arXiv:2002.02855
Date: Fri, 7 Feb 2020 15:47:50 GMT   (3843kb,D)

Title: Security Certification in Payment Card Industry: Testbeds, Measurements,
  and Recommendations
Authors: Sazzadur Rahaman and Gang Wang and Danfeng (Daphne) Yao
Categories: cs.CR
Comments: In Proceedings of the 2019 ACM Conference on Computer and
  Communications Security (CCS)
DOI: 10.1145/3319535.3363195
\\
  The massive payment card industry (PCI) involves various entities such as
merchants, issuer banks, acquirer banks, and card brands. Ensuring security for
all entities that process payment card information is a challenging task. The
PCI Security Standards Council requires all entities to be compliant with the
PCI Data Security Standard (DSS), which specifies a series of security
requirements. However, little is known regarding how well PCI DSS is enforced
in practice. In this paper, we take a measurement approach to systematically
evaluate the PCI DSS certification process for e-commerce websites. We develop
an e-commerce web application testbed, BuggyCart, which can flexibly add or
remove 35 PCI DSS related vulnerabilities. Then we use the testbed to examine
the capability and limitations of PCI scanners and the rigor of the
certification process. We find that there is an alarming gap between the
security standard and its real-world enforcement. None of the 6 PCI scanners we
tested are fully compliant with the PCI scanning guidelines, issuing
certificates to merchants that still have major vulnerabilities. To further
examine the compliance status of real-world e-commerce websites, we build a new
lightweight scanning tool named PciCheckerLite and scan 1,203 e-commerce
websites across various business sectors. The results confirm that 86% of the
websites have at least one PCI DSS violation that should have disqualified them
as non-compliant. Our in-depth accuracy analysis also shows that
PciCheckerLite's output is more precise than w3af. We reached out to the PCI
Security Council to share our research results to improve the enforcement in
practice.
\\ ( https://arxiv.org/abs/2002.02855 ,  3843kb)
------------------------------------------------------------------------------
\\
arXiv:2002.02506
Date: Thu, 6 Feb 2020 20:37:31 GMT   (5630kb,D)

Title: Continuous Geodesic Convolutions for Learning on 3D Shapes
Authors: Zhangsihao Yang, Or Litany, Tolga Birdal, Srinath Sridhar, Leonidas
  Guibas
Categories: cs.CV cs.CG
\\
  The majority of descriptor-based methods for geometric processing of
non-rigid shape rely on hand-crafted descriptors. Recently, learning-based
techniques have been shown effective, achieving state-of-the-art results in a
variety of tasks. Yet, even though these methods can in principle work directly
on raw data, most methods still rely on hand-crafted descriptors at the input
layer. In this work, we wish to challenge this practice and use a neural
network to learn descriptors directly from the raw mesh. To this end, we
introduce two modules into our neural architecture. The first is a local
reference frame (LRF) used to explicitly make the features invariant to rigid
transformations. The second is continuous convolution kernels that provide
robustness to sampling. We show the efficacy of our proposed network in
learning on raw meshes using two cornerstone tasks: shape matching, and human
body parts segmentation. Our results show superior results over baseline
methods that use hand-crafted descriptors.
\\ ( https://arxiv.org/abs/2002.02506 ,  5630kb)
------------------------------------------------------------------------------
\\
arXiv:2002.02545
Date: Thu, 6 Feb 2020 22:58:20 GMT   (980kb,D)

Title: Opposite Structure Learning for Semi-supervised Domain Adaptation
Authors: Can Qin, Lichen Wang, Qianqian Ma, Yu Yin, Huan Wang, Yun Fu
Categories: cs.CV
Comments: 8 pages without citations
\\
  Current adversarial adaptation methods attempt to align the cross-domain
features whereas two challenges remain unsolved: 1) conditional distribution
mismatch between different domains and 2) the bias of decision boundary towards
the source domain. To solve these challenges, we propose a novel framework for
semi-supervised domain adaptation by unifying the learning of opposite
structures (UODA). UODA consists of a generator and two classifiers (i.e., the
source-based and the target-based classifiers respectively) which are trained
with opposite forms of losses for a unified object. The target-based classifier
attempts to cluster the target features to improve intra-class density and
enlarge inter-class divergence. Meanwhile, the source-based classifier is
designed to scatter the source features to enhance the smoothness of decision
boundary. Through the alternation of source-feature expansion and
target-feature clustering procedures, the target features are well-enclosed
within the dilated boundary of the corresponding source features. This strategy
effectively makes the cross-domain features precisely aligned. To overcome the
model collapse through training, we progressively update the measurement of
distance and the feature representation on both domains via an adversarial
training paradigm. Extensive experiments on the benchmarks of DomainNet and
Office-home datasets demonstrate the effectiveness of our approach over the
state-of-the-art method.
\\ ( https://arxiv.org/abs/2002.02545 ,  980kb)
------------------------------------------------------------------------------
\\
arXiv:2002.02559
Date: Thu, 6 Feb 2020 23:58:23 GMT   (1985kb,D)

Title: Impact of ImageNet Model Selection on Domain Adaptation
Authors: Youshan Zhang and Brian D. Davison
Categories: cs.CV
Journal-ref: In 2020 IEEE Winter Applications of Computer Vision Workshops
  (WACVW)
\\
  Deep neural networks are widely used in image classification problems.
However, little work addresses how features from different deep neural networks
affect the domain adaptation problem. Existing methods often extract deep
features from one ImageNet model, without exploring other neural networks. In
this paper, we investigate how different ImageNet models affect transfer
accuracy on domain adaptation problems. We extract features from sixteen
distinct pre-trained ImageNet models and examine the performance of twelve
benchmarking methods when using the features. Extensive experimental results
show that a higher accuracy ImageNet model produces better features, and leads
to higher accuracy on domain adaptation problems (with a correlation
coefficient of up to 0.95). We also examine the architecture of each neural
network to find the best layer for feature extraction. Together, performance
from our features exceeds that of the state-of-the-art in three benchmark
datasets.
\\ ( https://arxiv.org/abs/2002.02559 ,  1985kb)
------------------------------------------------------------------------------
\\
arXiv:2002.02585
Date: Fri, 7 Feb 2020 01:54:15 GMT   (1311kb)

Title: Learning Hyperspectral Feature Extraction and Classification with
  ResNeXt Network
Authors: Divinah Nyasaka, Jing Wang, Haron Tinega
Categories: cs.CV cs.LG eess.IV
\\
  The Hyperspectral image (HSI) classification is a standard remote sensing
task, in which each image pixel is given a label indicating the physical
land-cover on the earth's surface. The achievements of image semantic
segmentation and deep learning approaches on ordinary images have accelerated
the research on hyperspectral image classification. Moreover, the utilization
of both the spectral and spatial cues in hyperspectral images has shown
improved classification accuracy in hyperspectral image classification. The use
of only 3D Convolutional Neural Networks (3D-CNN) to extract both spatial and
spectral cues from Hyperspectral images results in an explosion of parameters
hence high computational cost. We propose network architecture called the
MixedSN that utilizes the 3D convolutions to modeling spectral-spatial
information in the early layers of the architecture and the 2D convolutions at
the top layers which majorly deal with semantic abstraction. We constrain our
architecture to ResNeXt block because of their performance and simplicity. Our
model drastically reduced the number of parameters and achieved comparable
classification performance with state-of-the-art methods on Indian Pine (IP)
scene dataset, Pavia University scene (PU) dataset, Salinas (SA) Scene dataset,
and Botswana (BW) dataset.
\\ ( https://arxiv.org/abs/2002.02585 ,  1311kb)
------------------------------------------------------------------------------
\\
arXiv:2002.02589
Date: Fri, 7 Feb 2020 02:25:11 GMT   (603kb)

Title: Poisson Kernel Avoiding Self-Smoothing in Graph Convolutional Networks
Authors: Ziqing Yang, Shoudong Han and Jun Zhao
Categories: cs.CV cs.LG
Comments: 7 pages, 3 figures, submitted to IJCAI2020
\\
  Graph convolutional network (GCN) is now an effective tool to deal with
non-Euclidean data, such as social networks in social behavior analysis,
molecular structure analysis in the field of chemistry, and skeleton-based
action recognition. Graph convolutional kernel is one of the most significant
factors in GCN to extract nodes' feature, and some improvements of it have
reached promising performance theoretically and experimentally. However, there
is limited research about how exactly different data types and graph structures
influence the performance of these kernels. Most existing methods used an
adaptive convolutional kernel to deal with a given graph structure, which still
not reveals the internal reasons. In this paper, we started from theoretical
analysis of the spectral graph and studied the properties of existing graph
convolutional kernels. While taking some designed datasets with specific
parameters into consideration, we revealed the self-smoothing phenomenon of
convolutional kernels. After that, we proposed the Poisson kernel that can
avoid self-smoothing without training any adaptive kernel. Experimental results
demonstrate that our Poisson kernel not only works well on the benchmark
dataset where state-of-the-art methods work fine, but also is evidently
superior to them in synthetic datasets.
\\ ( https://arxiv.org/abs/2002.02589 ,  603kb)
------------------------------------------------------------------------------
\\
arXiv:2002.02598
Date: Fri, 7 Feb 2020 03:06:07 GMT   (5632kb,D)

Title: Object-Adaptive LSTM Network for Real-time Visual Tracking with
  Adversarial Data Augmentation
Authors: Yihan Du, Yan Yan, Si Chen, Yang Hua
Categories: cs.CV
\\
  In recent years, deep learning based visual tracking methods have obtained
great success owing to the powerful feature representation ability of
Convolutional Neural Networks (CNNs). Among these methods, classification-based
tracking methods exhibit excellent performance while their speeds are heavily
limited by the expensive computation for massive proposal feature extraction.
In contrast, matching-based tracking methods (such as Siamese networks) possess
remarkable speed superiority. However, the absence of online updating renders
these methods unadaptable to significant object appearance variations. In this
paper, we propose a novel real-time visual tracking method, which adopts an
object-adaptive LSTM network to effectively capture the video sequential
dependencies and adaptively learn the object appearance variations. For high
computational efficiency, we also present a fast proposal selection strategy,
which utilizes the matching-based tracking method to pre-estimate dense
proposals and selects high-quality ones to feed to the LSTM network for
classification. This strategy efficiently filters out some irrelevant proposals
and avoids the redundant computation for feature extraction, which enables our
method to operate faster than conventional classification-based tracking
methods. In addition, to handle the problems of sample inadequacy and class
imbalance during online tracking, we adopt a data augmentation technique based
on the Generative Adversarial Network (GAN) to facilitate the training of the
LSTM network. Extensive experiments on four visual tracking benchmarks
demonstrate the state-of-the-art performance of our method in terms of both
tracking accuracy and speed, which exhibits great potentials of recurrent
structures for visual tracking.
\\ ( https://arxiv.org/abs/2002.02598 ,  5632kb)
------------------------------------------------------------------------------
\\
arXiv:2002.02603
Date: Fri, 7 Feb 2020 03:18:10 GMT   (76kb,D)

Title: Adaptive Deep Metric Embeddings for Person Re-Identification under
  Occlusions
Authors: Wanxiang Yang, Yan Yan, Si Chen
Categories: cs.CV
Comments: 6 pages, 3 figures
\\
  Person re-identification (ReID) under occlusions is a challenging problem in
video surveillance. Most of existing person ReID methods take advantage of
local features to deal with occlusions. However, these methods usually
independently extract features from the local regions of an image without
considering the relationship among different local regions. In this paper, we
propose a novel person ReID method, which learns the spatial dependencies
between the local regions and extracts the discriminative feature
representation of the pedestrian image based on Long Short-Term Memory (LSTM),
dealing with the problem of occlusions. In particular, we propose a novel loss
(termed the adaptive nearest neighbor loss) based on the classification
uncertainty to effectively reduce intra-class variations while enlarging
inter-class differences within the adaptive neighborhood of the sample. The
proposed loss enables the deep neural network to adaptively learn
discriminative metric embeddings, which significantly improve the
generalization capability of recognizing unseen person identities. Extensive
comparative evaluations on challenging person ReID datasets demonstrate the
significantly improved performance of the proposed method compared with several
state-of-the-art methods.
\\ ( https://arxiv.org/abs/2002.02603 ,  76kb)
------------------------------------------------------------------------------
\\
arXiv:2002.02609
Date: Fri, 7 Feb 2020 03:45:25 GMT   (3984kb,D)

Title: Image Fine-grained Inpainting
Authors: Zheng Hui, Jie Li, Xiumei Wang, Xinbo Gao
Categories: cs.CV cs.MM
\\
  Image inpainting techniques have shown promising improvement with the
assistance of generative adversarial networks (GANs) recently. However, most of
them often suffered from completed results with unreasonable structure or
blurriness. To mitigate this problem, in this paper, we present a one-stage
model that utilizes dense combinations of dilated convolutions to obtain larger
and more effective receptive fields. Benefited from the property of this
network, we can more easily recover large regions in an incomplete image. To
better train this efficient generator, except for frequently-used VGG feature
matching loss, we design a novel self-guided regression loss for concentrating
on uncertain areas and enhancing the semantic details. Besides, we devise a
geometrical alignment constraint item to compensate for the pixel-based
distance between prediction features and ground-truth ones. We also employ a
discriminator with local and global branches to ensure local-global contents
consistency. To further improve the quality of generated images, discriminator
feature matching on the local branch is introduced, which dynamically minimizes
the similarity of intermediate features between synthetic and ground-truth
patches. Extensive experiments on several public datasets demonstrate that our
approach outperforms current state-of-the-art methods. Code is available
at~\url{https://github.com/Zheng222/DMFN}.
\\ ( https://arxiv.org/abs/2002.02609 ,  3984kb)
------------------------------------------------------------------------------
\\
arXiv:2002.02624
Date: Fri, 7 Feb 2020 04:59:50 GMT   (8377kb,D)

Title: Visual search over billions of aerial and satellite images
Authors: Ryan Keisler, Samuel W. Skillman, Sunny Gonnabathula, Justin Poehnelt,
  Xander Rudelis, Michael S. Warren
Categories: cs.CV
DOI: 10.1016/j.cviu.2019.07.010
\\
  We present a system for performing visual search over billions of aerial and
satellite images. The purpose of visual search is to find images that are
visually similar to a query image. We define visual similarity using 512
abstract visual features generated by a convolutional neural network that has
been trained on aerial and satellite imagery. The features are converted to
binary values to reduce data and compute requirements. We employ a hash-based
search using Bigtable, a scalable database service from Google Cloud. Searching
the continental United States at 1-meter pixel resolution, corresponding to
approximately 2 billion images, takes approximately 0.1 seconds. This system
enables real-time visual search over the surface of the earth, and an
interactive demo is available at https://search.descarteslabs.com.
\\ ( https://arxiv.org/abs/2002.02624 ,  8377kb)
------------------------------------------------------------------------------
\\
arXiv:2002.02634
Date: Fri, 7 Feb 2020 06:10:54 GMT   (7822kb,D)

Title: SideInfNet: A Deep Neural Network for Semi-Automatic Semantic
  Segmentation with Side Information
Authors: Jing Yu Koh, Duc Thanh Nguyen, Quang-Trung Truong, Sai-Kit Yeung,
  Alexander Binder
Categories: cs.CV
\\
  Fully-automatic execution is the ultimate goal for many Computer Vision
applications. However, this objective is not always realistic in tasks
associated with high failure costs, such as medical applications. For these
tasks, a compromise between fully-automatic execution and user interactions is
often preferred due to desirable accuracy and performance. Semi-automatic
methods require minimal effort from experts by allowing them to provide cues
that guide computer algorithms. Inspired by the practicality and applicability
of the semi-automatic approach, this paper proposes a novel deep neural network
architecture, namely SideInfNet that effectively integrates features learnt
from images with side information extracted from user annotations to produce
high quality semantic segmentation results. To evaluate our method, we applied
the proposed network to three semantic segmentation tasks and conducted
extensive experiments on benchmark datasets. Experimental results and
comparison with prior work have verified the superiority of our model,
suggesting the generality and effectiveness of the model in semi-automatic
semantic segmentation.
\\ ( https://arxiv.org/abs/2002.02634 ,  7822kb)
------------------------------------------------------------------------------
\\
arXiv:2002.02638
Date: Fri, 7 Feb 2020 06:34:44 GMT   (1776kb,D)

Title: Statistical Outlier Identification in Multi-robot Visual SLAM using
  Expectation Maximization
Authors: Arman Karimian, Ziqi Yang, Roberto Tron
Categories: cs.CV
\\
  This paper introduces a novel and distributed method for detecting inter-map
loop closure outliers in simultaneous localization and mapping (SLAM). The
proposed algorithm does not rely on a good initialization and can handle more
than two maps at a time. In multi-robot SLAM applications, maps made by
different agents have nonidentical spatial frames of reference which makes
initialization very difficult in the presence of outliers. This paper presents
a probabilistic approach for detecting incorrect orientation measurements prior
to pose graph optimization by checking the geometric consistency of rotation
measurements. Expectation-Maximization is used to fine-tune the model
parameters. As ancillary contributions, a new approximate discrete inference
procedure is presented which uses evidence on loops in a graph and is based on
optimization (Alternate Direction Method of Multipliers). This method yields
superior results compared to Belief Propagation and has convergence guarantees.
Simulation and experimental results are presented that evaluate the performance
of the outlier detection method and the inference algorithm on synthetic and
real-world data.
\\ ( https://arxiv.org/abs/2002.02638 ,  1776kb)
------------------------------------------------------------------------------
\\
arXiv:2002.02651
Date: Fri, 7 Feb 2020 07:27:49 GMT   (2769kb,D)

Title: Learning Class Regularized Features for Action Recognition
Authors: Alexandros Stergiou, Ronald Poppe, and Remco C. Veltkamp
Categories: cs.CV cs.LG
\\
  Training Deep Convolutional Neural Networks (CNNs) is based on the notion of
using multiple kernels and non-linearities in their subsequent activations to
extract useful features. The kernels are used as general feature extractors
without specific correspondence to the target class. As a result, the extracted
features do not correspond to specific classes. Subtle differences between
similar classes are modeled in the same way as large differences between
dissimilar classes. To overcome the class-agnostic use of kernels in CNNs, we
introduce a novel method named Class Regularization that performs class-based
regularization of layer activations. We demonstrate that this not only improves
feature search during training, but also allows an explicit assignment of
features per class during each stage of the feature extraction process. We show
that using Class Regularization blocks in state-of-the-art CNN architectures
for action recognition leads to systematic improvement gains of 1.8%, 1.2% and
1.4% on the Kinetics, UCF-101 and HMDB-51 datasets, respectively.
\\ ( https://arxiv.org/abs/2002.02651 ,  2769kb)
------------------------------------------------------------------------------
\\
arXiv:2002.02698
Date: Fri, 7 Feb 2020 10:08:21 GMT   (2473kb,D)

Title: Deep Robust Multilevel Semantic Cross-Modal Hashing
Authors: Ge Song, Jun Zhao, Xiaoyang Tan
Categories: cs.CV
Comments: 7 pages, 6 figures, submitted to a conference
\\
  Hashing based cross-modal retrieval has recently made significant progress.
But straightforward embedding data from different modalities into a joint
Hamming space will inevitably produce false codes due to the intrinsic modality
discrepancy and noises. We present a novel Robust Multilevel Semantic Hashing
(RMSH) for more accurate cross-modal retrieval. It seeks to preserve
fine-grained similarity among data with rich semantics, while explicitly
require distances between dissimilar points to be larger than a specific value
for strong robustness. For this, we give an effective bound of this value based
on the information coding-theoretic analysis, and the above goals are embodied
into a margin-adaptive triplet loss. Furthermore, we introduce pseudo-codes via
fusing multiple hash codes to explore seldom-seen semantics, alleviating the
sparsity problem of similarity information. Experiments on three benchmarks
show the validity of the derived bounds, and our method achieves
state-of-the-art performance.
\\ ( https://arxiv.org/abs/2002.02698 ,  2473kb)
------------------------------------------------------------------------------
\\
arXiv:2002.02709
Date: Fri, 7 Feb 2020 10:54:54 GMT   (1749kb,D)

Title: FourierNet: Compact mask representation for instance segmentation using
  differentiable shape decoders
Authors: Nuri Benbarka, Hamd ul Moqeet Riaz and Andreas Zell
Categories: cs.CV eess.IV
\\
  We present FourierNet a single shot, anchor-free, fully convolutional
instance segmentation method, which predicts a shape vector that is converted
into contour points using a numerical transformation. Compared to previous
methods, we introduce a new training technique, where we utilize a
differentiable shape decoder, which achieves automatic weight balancing of the
shape vector's coefficients. Fourier series was utilized as a shape encoder
because of its coefficient interpretability and fast implementation. By using
its lower frequencies we were able to retrieve smooth and compact masks.
FourierNet shows promising results compared to polygon representation methods,
achieving 30.6 mAP on the MS COCO 2017 benchmark. At lower image resolutions,
it runs at 26.6 FPS with 24.3 mAP. It achieves 23.3 mAP using just 8 parameters
to represent the mask, which is double the amount of parameters to predict a
bounding box. Code will be available at:
github.com/cogsys-tuebingen/FourierNet.
\\ ( https://arxiv.org/abs/2002.02709 ,  1749kb)
------------------------------------------------------------------------------
\\
arXiv:2002.02814
Date: Fri, 7 Feb 2020 14:42:26 GMT   (7762kb,D)

Title: Fine-Grained Fashion Similarity Learning by Attribute-Specific Embedding
  Network
Authors: Zhe Ma, Jianfeng Dong, Yao Zhang, Zhongzi Long, Yuan He, Hui Xue,
  Shouling Ji
Categories: cs.CV cs.LG
Comments: 16 pages, 13 figutes. Accepted by AAAI 2020. Code and data are
  available at https://github.com/Maryeon/asen
\\
  This paper strives to learn fine-grained fashion similarity. In this
similarity paradigm, one should pay more attention to the similarity in terms
of a specific design/attribute among fashion items, which has potential values
in many fashion related applications such as fashion copyright protection. To
this end, we propose an Attribute-Specific Embedding Network (ASEN) to jointly
learn multiple attribute-specific embeddings in an end-to-end manner, thus
measure the fine-grained similarity in the corresponding space. With two
attention modules, i.e., Attribute-aware Spatial Attention and Attribute-aware
Channel Attention, ASEN is able to locate the related regions and capture the
essential patterns under the guidance of the specified attribute, thus make the
learned attribute-specific embeddings better reflect the fine-grained
similarity. Extensive experiments on four fashion-related datasets show the
effectiveness of ASEN for fine-grained fashion similarity learning and its
potential for fashion reranking.
\\ ( https://arxiv.org/abs/2002.02814 ,  7762kb)
------------------------------------------------------------------------------
\\
arXiv:2002.02815
Date: Fri, 7 Feb 2020 14:43:44 GMT   (375kb,D)

Title: Switchable Precision Neural Networks
Authors: Luis Guerra, Bohan Zhuang, Ian Reid, Tom Drummond
Categories: cs.CV
\\
  Instantaneous and on demand accuracy-efficiency trade-off has been recently
explored in the context of neural networks slimming. In this paper, we propose
a flexible quantization strategy, termed Switchable Precision neural Networks
(SP-Nets), to train a shared network capable of operating at multiple
quantization levels. At runtime, the network can adjust its precision on the
fly according to instant memory, latency, power consumption and accuracy
demands. For example, by constraining the network weights to 1-bit with
switchable precision activations, our shared network spans from BinaryConnect
to Binarized Neural Network, allowing to perform dot-products using only
summations or bit operations. In addition, a self-distillation scheme is
proposed to increase the performance of the quantized switches. We tested our
approach with three different quantizers and demonstrate the performance of
SP-Nets against independently trained quantized models in classification
accuracy for Tiny ImageNet and ImageNet datasets using ResNet-18 and MobileNet
architectures.
\\ ( https://arxiv.org/abs/2002.02815 ,  375kb)
------------------------------------------------------------------------------
\\
arXiv:2002.02852
Date: Fri, 7 Feb 2020 15:39:34 GMT   (7209kb,D)

Title: Input Dropout for Spatially Aligned Modalities
Authors: S\'ebastien de Blois, Mathieu Garon, Christian Gagn\'e,
  Jean-Fran\c{c}ois Lalonde
Categories: cs.CV cs.LG eess.IV
Comments: 2020 IEEE. Personal use of this material is permitted. Permission
  from IEEE must be obtained for all other uses, in any current or future
  media, including reprinting/republishing this material for advertising or
  promotional purposes, creating new collective works, for resale or
  redistribution to servers or lists, or reuse of any copyrighted component of
  this work in other works
\\
  Computer vision datasets containing multiple modalities such as color, depth,
and thermal properties are now commonly accessible and useful for solving a
wide array of challenging tasks. However, deploying multi-sensor heads is not
possible in many scenarios. As such many practical solutions tend to be based
on simpler sensors, mostly for cost, simplicity and robustness considerations.
In this work, we propose a training methodology to take advantage of these
additional modalities available in datasets, even if they are not available at
test time. By assuming that the modalities have a strong spatial correlation,
we propose Input Dropout, a simple technique that consists in stochastic hiding
of one or many input modalities at training time, while using only the
canonical (e.g. RGB) modalities at test time. We demonstrate that Input Dropout
trivially combines with existing deep convolutional architectures, and improves
their performance on a wide range of computer vision tasks such as dehazing,
6-DOF object tracking, pedestrian detection and object classification.
\\ ( https://arxiv.org/abs/2002.02852 ,  7209kb)
------------------------------------------------------------------------------
\\
arXiv:2002.02857
Date: Fri, 7 Feb 2020 15:47:55 GMT   (2603kb,D)

Title: An Auxiliary Task for Learning Nuclei Segmentation in 3D Microscopy
  Images
Authors: Peter Hirsch, Dagmar Kainmueller
Categories: cs.CV
Comments: code available at: https://github.com/Kainmueller-Lab/aux_cpv_loss
\\
  Segmentation of cell nuclei in microscopy images is a prevalent necessity in
cell biology. Especially for three-dimensional datasets, manual segmentation is
prohibitively time-consuming, motivating the need for automated methods.
Learning-based methods trained on pixel-wise ground-truth segmentations have
been shown to yield state-of-the-art results on 2d benchmark image data of
nuclei, yet a respective benchmark is missing for 3d image data. In this work,
we perform a comparative evaluation of nuclei segmentation algorithms on a
database of manually segmented 3d light microscopy volumes. We propose a novel
learning strategy that boosts segmentation accuracy by means of a simple
auxiliary task, thereby robustly outperforming each of our baselines.
Furthermore, we show that one of our baselines, the popular three-label model,
when trained with our proposed auxiliary task, outperforms the recent
StarDist-3D. As an additional, practical contribution, we benchmark nuclei
segmentation against nuclei detection, i.e. the task of merely pinpointing
individual nuclei without generating respective pixel-accurate segmentations.
For learning nuclei detection, large 3d training datasets of manually annotated
nuclei center points are available. However, the impact on detection accuracy
caused by training on such sparse ground truth as opposed to dense pixel-wise
ground truth has not yet been quantified. To this end, we compare nuclei
detection accuracy yielded by training on dense vs. sparse ground truth. Our
results suggest that training on sparse ground truth yields competitive nuclei
detection rates.
\\ ( https://arxiv.org/abs/2002.02857 ,  2603kb)
------------------------------------------------------------------------------
\\
arXiv:2002.02909
Date: Wed, 5 Feb 2020 17:36:13 GMT   (5120kb,D)

Title: Domain Embedded Multi-model Generative Adversarial Networks for
  Image-based Face Inpainting
Authors: Xian Zhang, Xin Wang, Bin Kong, Youbing Yin, Qi Song, Siwei Lyu,
  Jiancheng Lv, Canghong Shi, Xiaojie Li
Categories: cs.CV cs.LG eess.IV
\\
  Prior knowledge of face shape and location plays an important role in face
inpainting. However, traditional facing inpainting methods mainly focus on the
generated image resolution of the missing portion but without consideration of
the special particularities of the human face explicitly and generally produce
discordant facial parts. To solve this problem, we present a stable variational
latent generative model for large inpainting of face images. We firstly
represent only face regions with the latent variable space but simultaneously
constraint the random vectors to offer control over the distribution of latent
variables, and combine with the non-face parts textures to generate a face
image with plausible contents. Two adversarial discriminators are finally used
to judge whether the generated distribution is close to the real distribution
or not. It can not only synthesize novel image structures but also explicitly
utilize the latent space with Eigenfaces to make better predictions.
Furthermore, our work better evaluates the side face impainting problem.
Experiments on both CelebA and CelebA-HQ face datasets demonstrate that our
proposed approach generates higher quality inpainting results than existing
ones.
\\ ( https://arxiv.org/abs/2002.02909 ,  5120kb)
------------------------------------------------------------------------------
\\
arXiv:2002.02917
Date: Fri, 7 Feb 2020 17:45:39 GMT   (2389kb,D)

Title: Data augmentation with M\"obius transformations
Authors: Sharon Zhou, Jiequan Zhang, Hang Jiang, Torbj\"orn Lundh, Andrew Y. Ng
Categories: cs.CV cs.LG
\\
  Data augmentation has led to substantial improvements in the performance and
generalization of deep models, and remain a highly adaptable method to evolving
model architectures and varying amounts of data---in particular, extremely
scarce amounts of available training data. In this paper, we present a novel
method of applying M\"obius transformations to augment input images during
training. M\"obius transformations are bijective conformal maps that generalize
image translation to operate over complex inversion in pixel space. As a
result, M\"obius transformations can operate on the sample level and preserve
data labels. We show that the inclusion of M\"obius transformations during
training enables improved generalization over prior sample-level data
augmentation techniques such as cutout and standard crop-and-flip
transformations, most notably in low data regimes.
\\ ( https://arxiv.org/abs/2002.02917 ,  2389kb)
------------------------------------------------------------------------------
\\
arXiv:2002.02918
Date: Fri, 7 Feb 2020 17:46:38 GMT   (513kb)

Title: iqiyi Submission to ActivityNet Challenge 2019 Kinetics-700 challenge:
  Hierarchical Group-wise Attention
Authors: Qian Liu, Dongyang Cai, Jie Liu, Nan Ding, Tao Wang
Categories: cs.CV
Comments: Tech report
\\
  In this report, the method for the iqiyi submission to the task of
ActivityNet 2019 Kinetics-700 challenge is described. Three models are involved
in the model ensemble stage: TSN, HG-NL and StNet. We propose the hierarchical
group-wise non-local (HG-NL) module for frame-level features aggregation for
video classification. The standard non-local (NL) module is effective in
aggregating frame-level features on the task of video classification but
presents low parameters efficiency and high computational cost. The HG-NL
method involves a hierarchical group-wise structure and generates multiple
attention maps to enhance performance. Basing on this hierarchical group-wise
structure, the proposed method has competitive accuracy, fewer parameters and
smaller computational cost than the standard NL. For the task of ActivityNet
2019 Kinetics-700 challenge, after model ensemble, we finally obtain an
averaged top-1 and top-5 error percentage 28.444% on the test set.
\\ ( https://arxiv.org/abs/2002.02918 ,  513kb)
------------------------------------------------------------------------------
\\
arXiv:2002.02921
Date: Fri, 7 Feb 2020 17:49:08 GMT   (1721kb,D)

Title: Temporal Segmentation of Surgical Sub-tasks through Deep Learning with
  Multiple Data Sources
Authors: Yidan Qin, Sahba Aghajani Pedram, Seyedshams Feyzabadi, Max Allan, A.
  Jonathan McLeod, Joel W. Burdick, Mahdi Azizian
Categories: cs.CV cs.LG cs.RO eess.IV
Comments: Accepted to ICRA 2020
\\
  Many tasks in robot-assisted surgeries (RAS) can be represented by
finite-state machines (FSMs), where each state represents either an action
(such as picking up a needle) or an observation (such as bleeding). A crucial
step towards the automation of such surgical tasks is the temporal perception
of the current surgical scene, which requires a real-time estimation of the
states in the FSMs. The objective of this work is to estimate the current state
of the surgical task based on the actions performed or events occurred as the
task progresses. We propose Fusion-KVE, a unified surgical state estimation
model that incorporates multiple data sources including the Kinematics, Vision,
and system Events. Additionally, we examine the strengths and weaknesses of
different state estimation models in segmenting states with different
representative features or levels of granularity. We evaluate our model on the
JHU-ISI Gesture and Skill Assessment Working Set (JIGSAWS), as well as a more
complex dataset involving robotic intra-operative ultrasound (RIOUS) imaging,
created using the da Vinci Xi surgical system. Our model achieves a superior
frame-wise state estimation accuracy up to 89.4%, which improves the
state-of-the-art surgical state estimation models in both JIGSAWS suturing
dataset and our RIOUS dataset.
\\ ( https://arxiv.org/abs/2002.02921 ,  1721kb)
------------------------------------------------------------------------------
\\
arXiv:2002.02924
Date: Fri, 7 Feb 2020 17:51:56 GMT   (3014kb,D)

Title: Subspace Capsule Network
Authors: Marzieh Edraki, Nazanin Rahnavard, Mubarak Shah
Categories: cs.CV
\\
  Convolutional neural networks (CNNs) have become a key asset to most of
fields in AI. Despite their successful performance, CNNs suffer from a major
drawback. They fail to capture the hierarchy of spatial relation among
different parts of an entity. As a remedy to this problem, the idea of capsules
was proposed by Hinton. In this paper, we propose the SubSpace Capsule Network
(SCN) that exploits the idea of capsule networks to model possible variations
in the appearance or implicitly defined properties of an entity through a group
of capsule subspaces instead of simply grouping neurons to create capsules. A
capsule is created by projecting an input feature vector from a lower layer
onto the capsule subspace using a learnable transformation. This transformation
finds the degree of alignment of the input with the properties modeled by the
capsule subspace. We show that SCN is a general capsule network that can
successfully be applied to both discriminative and generative models without
incurring computational overhead compared to CNN during test time.
Effectiveness of SCN is evaluated through a comprehensive set of experiments on
supervised image classification, semi-supervised image classification and
high-resolution image generation tasks using the generative adversarial network
(GAN) framework. SCN significantly improves the performance of the baseline
models in all 3 tasks.
\\ ( https://arxiv.org/abs/2002.02924 ,  3014kb)
------------------------------------------------------------------------------
\\
arXiv:2002.02927
Date: Fri, 7 Feb 2020 17:55:28 GMT   (1634kb,D)

Title: SPN-CNN: Boosting Sensor-Based Source Camera Attribution With Deep
  Learning
Authors: Matthias Kirchner and Cameron Johnson
Categories: cs.CV cs.MM eess.IV
Comments: Presented at the IEEE International Workshop on Information Forensics
  and Security (WIFS) 2019
\\
  We explore means to advance source camera identification based on sensor
noise in a data-driven framework. Our focus is on improving the sensor pattern
noise (SPN) extraction from a single image at test time. Where existing works
suppress nuisance content with denoising filters that are largely agnostic to
the specific SPN signal of interest, we demonstrate that a~deep learning
approach can yield a more suitable extractor that leads to improved source
attribution. A series of extensive experiments on various public datasets
confirms the feasibility of our approach and its applicability to image
manipulation localization and video source attribution. A critical discussion
of potential pitfalls completes the text.
\\ ( https://arxiv.org/abs/2002.02927 ,  1634kb)
------------------------------------------------------------------------------
\\
arXiv:2002.02934
Date: Fri, 7 Feb 2020 18:11:01 GMT   (3270kb,D)

Title: How Does Gender Balance In Training Data Affect Face Recognition
  Accuracy?
Authors: V\'itor Albiero, Kai Zhang, and Kevin W. Bowyer
Categories: cs.CV
\\
  Even though deep learning methods have greatly increased the overall accuracy
of face recognition, an old problem still persists: accuracy is higher for men
than for women. Previous researchers have speculated that the difference could
be due to cosmetics, head pose, or hair covering the face. It is also often
speculated that the lower accuracy for women is caused by women being
under-represented in the training data. This work aims to investigate if gender
imbalance in the training data is actually the cause of lower accuracy for
females. Using a state-of-the-art deep CNN, three different loss functions, and
two training datasets, we train each on seven subsets with different
male/female ratios, totaling forty two train-ings. The trained face matchers
are then tested on three different testing datasets. Results show that
gender-balancing the dataset has an overall positive effect, with higher
accuracy for most of the combinations of loss functions and datasets when a
balanced subset is used. However, for the best combination of loss function and
dataset, the original training dataset shows better accuracy on 3 out of 4
times. We observe that test accuracy for males is higher when the training data
is all male. However, test accuracy for females is not maximized when the
training data is all female. Fora number of combinations of loss function and
test dataset, accuracy for females is higher when only 75% of the train-ing
data is female than when 100% of the training data is female. This suggests
that lower accuracy for females is nota simple result of the fraction of female
training data. By clustering face features, we show that in general, male faces
are closer to other male faces than female faces, and female faces are closer
to other female faces than male faces
\\ ( https://arxiv.org/abs/2002.02934 ,  3270kb)
------------------------------------------------------------------------------
\\
arXiv:2002.02942
Date: Fri, 7 Feb 2020 18:21:59 GMT   (571kb,D)

Title: On the Robustness of Face Recognition Algorithms Against Attacks and
  Bias
Authors: Richa Singh, Akshay Agarwal, Maneet Singh, Shruti Nagpal, Mayank Vatsa
Categories: cs.CV
Comments: Accepted in Senior Member Track, AAAI2020
\\
  Face recognition algorithms have demonstrated very high recognition
performance, suggesting suitability for real world applications. Despite the
enhanced accuracies, robustness of these algorithms against attacks and bias
has been challenged. This paper summarizes different ways in which the
robustness of a face recognition algorithm is challenged, which can severely
affect its intended working. Different types of attacks such as physical
presentation attacks, disguise/makeup, digital adversarial attacks, and
morphing/tampering using GANs have been discussed. We also present a discussion
on the effect of bias on face recognition models and showcase that factors such
as age and gender variations affect the performance of modern algorithms. The
paper also presents the potential reasons for these challenges and some of the
future research directions for increasing the robustness of face recognition
models.
\\ ( https://arxiv.org/abs/2002.02942 ,  571kb)
------------------------------------------------------------------------------
\\
arXiv:2002.02957
Date: Fri, 7 Feb 2020 18:53:13 GMT   (1022kb,D)

Title: $M^3$T: Multi-Modal Continuous Valence-Arousal Estimation in the Wild
Authors: Yuan-Hang Zhang, Rulin Huang, Jiabei Zeng, Shiguang Shan and Xilin
  Chen
Categories: cs.CV cs.SD eess.AS eess.IV
Comments: 6 pages, technical report; submission to ABAW Challenge at FG 2020
\\
  This report describes a multi-modal multi-task ($M^3$T) approach underlying
our submission to the valence-arousal estimation track of the Affective
Behavior Analysis in-the-wild (ABAW) Challenge, held in conjunction with the
IEEE International Conference on Automatic Face and Gesture Recognition (FG)
2020. In the proposed $M^3$T framework, we fuse both visual features from
videos and acoustic features from the audio tracks to estimate the valence and
arousal. The spatio-temporal visual features are extracted with a 3D
convolutional network and a bidirectional recurrent neural network. Considering
the correlations between valence / arousal, emotions, and facial actions, we
also explores mechanisms to benefit from other tasks. We evaluated the $M^3$T
framework on the validation set provided by ABAW and it significantly
outperforms the baseline method.
\\ ( https://arxiv.org/abs/2002.02957 ,  1022kb)
------------------------------------------------------------------------------
\\
arXiv:2002.02959
Date: Fri, 7 Feb 2020 18:56:37 GMT   (722kb,D)

Title: Revisiting Spatial Invariance with Low-Rank Local Connectivity
Authors: Gamaleldin F. Elsayed, Prajit Ramachandran, Jonathon Shlens, Simon
  Kornblith
Categories: cs.CV cs.LG stat.ML
\\
  Convolutional neural networks are among the most successful architectures in
deep learning. This success is at least partially attributable to the efficacy
of spatial invariance as an inductive bias. Locally connected layers, which
differ from convolutional layers in their lack of spatial invariance, usually
perform poorly in practice. However, these observations still leave open the
possibility that some degree of relaxation of spatial invariance may yield a
better inductive bias than either convolution or local connectivity. To test
this hypothesis, we design a method to relax the spatial invariance of a
network layer in a controlled manner. In particular, we create a
\textit{low-rank} locally connected layer, where the filter bank applied at
each position is constructed as a linear combination of basis set of filter
banks. By varying the number of filter banks in the basis set, we can control
the degree of departure from spatial invariance. In our experiments, we find
that relaxing spatial invariance improves classification accuracy over both
convolution and locally connected layers across MNIST, CIFAR-10, and CelebA
datasets. These results suggest that spatial invariance in convolution layers
may be overly restrictive.
\\ ( https://arxiv.org/abs/2002.02959 ,  722kb)
------------------------------------------------------------------------------
\\
arXiv:2002.02552
Date: Thu, 6 Feb 2020 23:21:15 GMT   (1004kb,D)

Title: Progressive Cleaning and Mining of Uncertain Smart Water Meter Data
Authors: Milad Khaki
Categories: cs.DB
Comments: 12 pages, 6 figures
\\
  Several municipalities have recently installed wireless 'smart' water meters
that allow functionalities such as demand response, leak alerts, identification
of characteristic demand patterns, and detailed consumption analysis. To
achieve these benefits, the meter data needs to be error-free, which is not
necessarily available in practice, due to 'dirtiness' or 'uncertainty' of data,
which is mostly unavoidable.
  The focus of this paper is to investigate practical solutions to mine
uncertain data for reliable results and to evaluate the impact of dirty data on
filters. This evaluation would eventually lead to valuable information, which
can be used for educated decision making on water planning strategies. We
perform a systematic study of the errors existing in a large-scale smart water
meter deployments, which is helpful to better understand the nature of errors.
  Identifying customers contributing to a load peak is used as the main filter.
The filter outputs are then combined with the domain expert knowledge to
evaluate their accuracy and validity and also to look for potential errors.
After discovering each error, we analyze its trails in the data and track back
its source, which would eventually lead to the removal of the error or dealing
with it accordingly. This procedure is applied progressively to ensure that all
detectable errors are discovered and characterized in the data model.
  We evaluate the performance of the proposed approach using the smart water
meter consumption data obtained from the City of Abbotsford, British Columbia,
Canada. We present the results of both unprocessed and cleaned data and
analyze, in detail, the sensitivity of the selected filter to the errors.
\\ ( https://arxiv.org/abs/2002.02552 ,  1004kb)
------------------------------------------------------------------------------
\\
arXiv:2002.02481
Date: Thu, 6 Feb 2020 19:27:44 GMT   (647kb,D)

Title: Sensitivity Analysis in the Dupire Local Volatility Model with
  Tensorflow
Authors: Francois Belletti, Davis King, James Lottes, Yi-Fan Chen, John
  Anderson
Categories: cs.DC cs.CE q-fin.CP stat.CO
\\
  In a recent paper, we have demonstrated how the affinity between TPUs and
multi-dimensional financial simulation resulted in fast Monte Carlo simulations
that could be setup in a few lines of python Tensorflow code. We also presented
a major benefit from writing high performance simulations in an automated
differentiation language such as Tensorflow: a single line of code enabled us
to estimate sensitivities, i.e. the rate of change in price of financial
instrument with respect to another input such as the interest rate, the current
price of the underlying, or volatility. Such sensitivities (otherwise known as
the famous financial "Greeks") are fundamental for risk assessment and risk
mitigation. In the present follow-up short paper, we extend the developments
exposed in our previous work about the use of Tensor Processing Units and
Tensorflow for TPUs.
\\ ( https://arxiv.org/abs/2002.02481 ,  647kb)
------------------------------------------------------------------------------
\\
arXiv:2002.02509
Date: Thu, 6 Feb 2020 20:41:37 GMT   (3190kb,D)

Title: Scalable Communication Endpoints for MPI+Threads Applications
Authors: Rohit Zambre, Aparna Chandramowlishwaran, Pavan Balaji
Categories: cs.DC
Comments: In Proceedings of the 24th IEEE International Conference on Parallel
  and Distributed Systems (ICPADS), Sentosa, Singapore, December 2018. Best
  Poster Award
Journal-ref: In 2018 IEEE 24th International Conference on Parallel and
  Distributed Systems (ICPADS), pp. 803-812. IEEE, 2018
DOI: 10.1109/PADSW.2018.8645059
\\
  Hybrid MPI+threads programming is gaining prominence as an alternative to the
traditional "MPI everywhere'" model to better handle the disproportionate
increase in the number of cores compared with other on-node resources. Current
implementations of these two models represent the two extreme cases of
communication resource sharing in modern MPI implementations. In the
MPI-everywhere model, each MPI process has a dedicated set of communication
resources (also known as endpoints), which is ideal for performance but is
resource wasteful. With MPI+threads, current MPI implementations share a single
communication endpoint for all threads, which is ideal for resource usage but
is hurtful for performance.
  In this paper, we explore the tradeoff space between performance and
communication resource usage in MPI+threads environments. We first demonstrate
the two extreme cases---one where all threads share a single communication
endpoint and another where each thread gets its own dedicated communication
endpoint (similar to the MPI-everywhere model) and showcase the inefficiencies
in both these cases. Next, we perform a thorough analysis of the different
levels of resource sharing in the context of Mellanox InfiniBand. Using the
lessons learned from this analysis, we design an improved resource-sharing
model to produce \emph{scalable communication endpoints} that can achieve the
same performance as with dedicated communication resources per thread but using
just a third of the resources.
\\ ( https://arxiv.org/abs/2002.02509 ,  3190kb)
------------------------------------------------------------------------------
\\
arXiv:2002.02563
Date: Fri, 7 Feb 2020 00:15:49 GMT   (3129kb,D)

Title: Breaking Band: A Breakdown of High-performance Communication
Authors: Rohit Zambre, Megan Grodowitz, Aparna Chandramowlishwaran, Pavel
  Shamis
Categories: cs.DC
Comments: In Proceedings of the 48th ACM International Conference on Parallel
  Processing (ICPP), Kyoto, Japan, August 2019
ACM-class: C.2.4
Journal-ref: In Proceedings of the 48th International Conference on Parallel
  Processing, pp. 1-10. 2019
DOI: 10.1145/3337821
\\
  The critical path of internode communication on large-scale systems is
composed of multiple components. When a supercomputing application initiates
the transfer of a message using a high-level communication routine such as an
MPI_Send, the payload of the message traverses multiple software stacks, the
I/O subsystem on both the host and target nodes, and network components such as
the switch. In this paper, we analyze where, why, and how much time is spent on
the critical path of communication by modeling the overall injection overhead
and end-to-end latency of a system. We focus our analysis on the performance of
small messages since fine-grained communication is becoming increasingly
important with the growing trend of an increasing number of cores per node. The
analytical models present an accurate and detailed breakdown of time spent in
internode communication. We validate the models on Arm ThunderX2-based servers
connected with Mellanox InfiniBand. This is the first work of this kind on Arm.
Alongside our breakdown, we describe the methodology to measure the time spent
in each component so that readers with access to precise CPU timers and a PCIe
analyzer can measure breakdowns on systems of their interest. Such a breakdown
is crucial for software developers, system architects, and researchers to guide
their optimization efforts. As researchers ourselves, we use the breakdown to
simulate the impacts and discuss the likelihoods of a set of optimizations that
target the bottlenecks in today's high-performance communication.
\\ ( https://arxiv.org/abs/2002.02563 ,  3129kb)
------------------------------------------------------------------------------
\\
arXiv:2002.02567
Date: Fri, 7 Feb 2020 00:36:29 GMT   (214kb,D)

Title: Stability and Scalability of Blockchain Systems
Authors: Aditya Gopalan, Abishek Sankararaman, Anwar Walid, Sriram Vishwanath
Categories: cs.DC cs.IT cs.SI math.IT
Comments: 27 pages, 8 figures
MSC-class: 94A06 (Primary), 60H06 (Secondary)
ACM-class: C.4; G.3; H.4.3
\\
  The blockchain paradigm provides a mechanism for content dissemination and
distributed consensus on Peer-to-Peer (P2P) networks. While this paradigm has
been widely adopted in industry, it has not been carefully analyzed in terms of
its network scaling with respect to the number of peers. Applications for
blockchain systems, such as cryptocurrencies and IoT, require this form of
network scaling.
  In this paper, we propose a new stochastic network model for a blockchain
system. We identify a structural property called \emph{one-endedness}, which is
desirable in any blockchain system. We prove that whenever the blockchain
network model is stochastically stable, then a blockchain is one-ended. We
further establish that our model is monotone separable and use this result to
establish upper and lower bounds on the stability region. The bounds on
stability depend on the conductance of the P2P network and allow us to analyze
the scalability of blockchain systems on large P2P networks. We verify our
theoretical insights using both synthetic data and real data from the Bitcoin
network.
\\ ( https://arxiv.org/abs/2002.02567 ,  214kb)
------------------------------------------------------------------------------
\\
arXiv:2002.02641
Date: Fri, 7 Feb 2020 06:43:30 GMT   (38kb)

Title: Deterministic Leader Election in Anonymous Radio Networks
Authors: Avery Miller, Andrzej Pelc, Ram Narayan Yadav
Categories: cs.DC cs.DS
Comments: 33 pages
\\
  We consider leader election in anonymous radio networks modeled as simple
undirected connected graphs. Nodes communicate in synchronous rounds. Nodes are
anonymous and execute the same deterministic algorithm, so symmetry can be
broken only in one way: by different wake-up times of the nodes. In which
situations is it possible to break symmetry and elect a leader using time as
symmetry breaker? To answer this question, we consider configurations. A
configuration is the underlying graph with nodes tagged by non-negative
integers with the following meaning. A node can either wake up spontaneously in
the round shown on its tag, according to some global clock, or can be woken up
hearing a message sent by one of its already awoken neighbours. The local clock
of a node starts at its wakeup and nodes do not have access to the global clock
determining their tags. A configuration is feasible if there exists a
distributed algorithm that elects a leader for this configuration.
  Our main result is a complete algorithmic characterization of feasible
configurations: we design a centralized decision algorithm, working in
polynomial time, whose input is a configuration and which decides if the
configuration is feasible. We also provide a dedicated deterministic
distributed leader election algorithm for each feasible configuration that
elects a leader for this configuration in time $O(n^2\sigma)$, where $n$ is the
number of nodes and $\sigma$ is the difference between the largest and smallest
tag of the configuration. We then prove that there cannot exist a universal
deterministic distributed algorithm electing a leader for all feasible
configurations. In fact, we show that such a universal algorithm cannot exist
even for the class of 4-node feasible configurations. We also prove that a
distributed version of our decision algorithm cannot exist.
\\ ( https://arxiv.org/abs/2002.02641 ,  38kb)
------------------------------------------------------------------------------
\\
arXiv:2002.02806
Date: Fri, 7 Feb 2020 14:24:49 GMT   (5376kb)

Title: A Comprehensive Feature Comparison Study of Open-Source Container
  Orchestration Frameworks
Authors: Eddy Truyen, Dimitri Van Landuyt, Davy Preuveneers, Bert Lagaisse,
  Wouter Joosen
Categories: cs.DC
Comments: Technical report
\\
  (1) Background: Container orchestration frameworks provide support for
management of complex distributed applications. Different frameworks have
emerged only recently, and they have been in constant evolution as new features
are being introduced. This reality makes it difficult for practitioners and
researchers to maintain a clear view of the technology space. (2) Methods: we
present a descriptive feature comparison study of the three most prominent
orchestration frameworks: Docker Swarm, Kubernetes, and Mesos, which can be
combined with Marathon, Aurora or DC/OS. This study aims at (i) identifying the
common and unique features of all frameworks, (ii) comparing these frameworks
qualitatively and quantitatively with respect to genericity in terms of
supported features, and (iii) investigating the maturity and stability of the
frameworks as well as the pioneering nature of each framework by studying the
historical evolution of the frameworks on GitHub. (3) Results: (i) we have
identified 124 common features and 54 unique features that we divided into a
taxonomy of 9 functional aspects and 27 functional sub-aspects. (ii) Kubernetes
supports the highest number of accumulated common and unique features for all 9
functional aspects; however, no evidence has been found for significant
differences in genericity with Docker Swarm and DC/OS. (iii) Very little
feature deprecations have been found and 15 out of 27 sub-aspects have been
identified as mature and stable. These are pioneered in descending order by
Kubernetes, Mesos, and Marathon. (4) Conclusion: there is a broad and mature
foundation that underpins all container orchestration frameworks. Likely areas
for further evolution and innovation include system support for improved
cluster security and container security, performance isolation of GPU, disk and
network resources, and network plugin architectures.
\\ ( https://arxiv.org/abs/2002.02806 ,  5376kb)
------------------------------------------------------------------------------
\\
arXiv:2002.02608
Date: Fri, 7 Feb 2020 03:38:39 GMT   (601kb)

Title: A tale of two databases: The use of Web of Science and Scopus in
  academic papers
Authors: Junwen Zhu and Weishu Liu
Categories: cs.DL
Comments: Forthcoming in Scientometrics
\\
  Web of Science and Scopus are two world-leading and competing citation
databases. By using the Science Citation Index Expanded and Social Sciences
Citation Index, this paper conducts a comparative, dynamic, and empirical study
focusing on the use of Web of Science (WoS) and Scopus in academic papers
published during 2004 and 2018. This brief communication reveals that although
both Web of Science and Scopus are increasingly used in academic papers, Scopus
as a new-comer is really challenging the dominating role of WoS. Researchers
from more and more countries/regions and knowledge domains are involved in the
use of these two databases. Even though the main producers of related papers
are developed economies, some developing economies such as China, Brazil and
Iran also act important roles but with different patterns in the use of these
two databases. Both two databases are widely used in meta-analysis related
studies especially for researchers in China. Health/medical science related
domains and the traditional Information Science & Library Science field stand
out in the use of citation databases.
\\ ( https://arxiv.org/abs/2002.02608 ,  601kb)
------------------------------------------------------------------------------
\\
arXiv:2002.02712
Date: Fri, 7 Feb 2020 10:57:00 GMT   (1242kb,D)

Title: Discovering Mathematical Objects of Interest -- A Study of Mathematical
  Notations
Authors: Andre Greiner-Petter, Moritz Schubotz, Fabian Mueller, Corinna
  Breitinger, Howard S. Cohl, Akiko Aizawa, Bela Gipp
Categories: cs.DL cs.IR
Comments: Proceedings of The Web Conference 2020 (WWW'20), April 20--24, 2020,
  Taipei, Taiwan
DOI: 10.1145/3366423.3380218
\\
  Mathematical notation, i.e., the writing system used to communicate concepts
in mathematics, encodes valuable information for a variety of information
search and retrieval systems. Yet, mathematical notations remain mostly
unutilized by today's systems. In this paper, we present the first in-depth
study on the distributions of mathematical notation in two large scientific
corpora: the open access arXiv (2.5B mathematical objects) and the mathematical
reviewing service for pure and applied mathematics zbMATH (61M mathematical
objects). Our study lays a foundation for future research projects on
mathematical information retrieval for large scientific corpora. Further, we
demonstrate the relevance of our results to a variety of use-cases. For
example, to assist semantic extraction systems, to improve scientific search
engines, and to facilitate specialized math recommendation systems. The
contributions of our presented research are as follows: (1) we present the
first distributional analysis of mathematical formulae on arXiv and zbMATH; (2)
we retrieve relevant mathematical objects for given textual search queries
(e.g., linking $P_{n}^{(\alpha, \beta)}\!\left(x\right)$ with `Jacobi
polynomial'); (3) we extend zbMATH's search engine by providing relevant
mathematical formulae; and (4) we exemplify the applicability of the results by
presenting auto-completion for math inputs as the first contribution to math
recommendation systems. To expedite future research projects, we have made
available our source code and data.
\\ ( https://arxiv.org/abs/2002.02712 ,  1242kb)
------------------------------------------------------------------------------
\\
arXiv:2002.02476
Date: Thu, 6 Feb 2020 19:17:49 GMT   (1516kb,D)

Title: The Sum Composition Problem
Authors: Mario Pennacchioni, Emanuele Munarini, Marco Mesiti
Categories: cs.DS
\\
  In this paper, we study the "sum composition problem" between two lists $A$
and $B$ of positive integers. We start by saying that $B$ is "sum composition"
of $A$ when there exists an ordered $m$-partition $[A_1,\ldots,A_m]$ of $A$
where $m$ is the length of $B$ and the sum of each part $A_k$ is equal to the
corresponding part of $B$. Then, we consider the following two problems: $i)$
the "exhaustive problem", consisting in the generation of all partitions of $A$
for which $B$ is sum composition of $A$, and $ii)$ the "existential problem",
consisting in the verification of the existence of a partition of $A$ for which
$B$ is sum composition of $A$. Starting from some general properties of the sum
compositions, we present a first algorithm solving the exhaustive problem and
then a second algorithm solving the existential problem. We also provide proofs
of correctness and experimental analysis for assessing the quality of the
proposed solutions along with a comparison with related works.
\\ ( https://arxiv.org/abs/2002.02476 ,  1516kb)
------------------------------------------------------------------------------
\\
arXiv:2002.02487
Date: Thu, 6 Feb 2020 19:49:54 GMT   (300kb,D)

Title: Efficient Algorithms for Generating Provably Near-Optimal Cluster
  Descriptors for Explainability
Authors: Prathyush Sambaturu, Aparna Gupta, Ian Davidson, S. S. Ravi, Anil
  Vullikanti, Andrew Warren
Categories: cs.DS cs.AI cs.DM math.OC
MSC-class: 68W25, 68T01, 68R05
ACM-class: G.2; I.2; F.2
\\
  Improving the explainability of the results from machine learning methods has
become an important research goal. Here, we study the problem of making
clusters more interpretable by extending a recent approach of [Davidson et al.,
NeurIPS 2018] for constructing succinct representations for clusters. Given a
set of objects $S$, a partition $\pi$ of $S$ (into clusters), and a universe
$T$ of tags such that each element in $S$ is associated with a subset of tags,
the goal is to find a representative set of tags for each cluster such that
those sets are pairwise-disjoint and the total size of all the representatives
is minimized. Since this problem is NP-hard in general, we develop
approximation algorithms with provable performance guarantees for the problem.
We also show applications to explain clusters from datasets, including clusters
of genomic sequences that represent different threat levels.
\\ ( https://arxiv.org/abs/2002.02487 ,  300kb)
------------------------------------------------------------------------------
\\
arXiv:2002.02731
Date: Fri, 7 Feb 2020 12:17:41 GMT   (889kb,D)

Title: Computational Aspects of Sturdy and Flimsy Numbers
Authors: Trevor Clokie, Thomas F. Lidbetter, Antonio Molina Lovett, Jeffrey
  Shallit, Leon Witzman
Categories: cs.DS cs.DM cs.FL math.CO math.NT
\\
  Following Stolarsky, we say that a natural number n is flimsy in base b if
some positive multiple of n has smaller digit sum in base b than n does;
otherwise it is sturdy. We develop algorithmic methods for the study of sturdy
and flimsy numbers.
  We provide some criteria for determining whether a number is sturdy. Focusing
on the case of base b = 2, we study the computational problem of checking
whether a given number is sturdy, giving several algorithms for the problem. We
find two additional, previously unknown sturdy primes. We develop a method for
determining which numbers with a fixed number of 0's in binary are flimsy.
Finally, we develop a method that allows us to estimate the number of k-flimsy
numbers with n bits, and we provide explicit results for k = 3 and k = 5. Our
results demonstrate the utility (and fun) of creating algorithms for number
theory problems, based on methods of automata theory.
\\ ( https://arxiv.org/abs/2002.02731 ,  889kb)
------------------------------------------------------------------------------
\\
arXiv:2002.02809
Date: Fri, 7 Feb 2020 14:33:07 GMT   (204kb)

Title: Recursive PGFs for BSTs and DSTs
Authors: Steven Finch
Categories: cs.DS math.HO math.PR
Comments: 16 pages, 6 figures
MSC-class: 68Q87 (Primary) 68Q25, 68P10, 05A15, 05C05, 05C30, 97K50, 97N60
  (Secondary)
\\
  We review fundamentals underlying binary search trees and digital search
trees, with (atypical) emphasis on recursive formulas for associated
probability generating functions. Other topics include higher moments of BST
search costs and combinatorics for a certain finite-key analog of DSTs.
\\ ( https://arxiv.org/abs/2002.02809 ,  204kb)
------------------------------------------------------------------------------
\\
arXiv:2002.02818
Date: Fri, 7 Feb 2020 14:44:45 GMT   (7kb)

Title: Nonparametric Regression Quantum Neural Networks
Authors: Do Ngoc Diep, Koji Nagata, and Tadao Nakamura
Categories: cs.ET cs.LG quant-ph
Comments: 4 pages, no figure, LaTeX2e
\\
  In two pervious papers \cite{dndiep3}, \cite{dndiep4}, the first author
constructed the least square quantum neural networks (LS-QNN), and ploynomial
interpolation quantum neural networks ( PI-QNN), parametrico-stattistical QNN
like: leanr regrassion quantum neural networks (LR-QNN), polynomial regression
quantum neural networks (PR-QNN), chi-squared quantum neural netowrks
($\chi^2$-QNN). We observed that the method works also in the cases by using
nonparametric statistics. In this paper we analyze and implement the
nonparametric tests on QNN such as: linear nonparametric regression quantum
neural networks (LNR-QNN), polynomial nonparametric regression quantum neural
networks (PNR-QNN). The implementation is constructed through the Gauss-Jordan
Elimination quantum neural networks (GJE-QNN).The training rule is to use the
high probability confidence regions or intervals.
\\ ( https://arxiv.org/abs/2002.02818 ,  7kb)
------------------------------------------------------------------------------
\\
arXiv:2002.02671
Date: Fri, 7 Feb 2020 08:59:41 GMT   (5820kb,D)

Title: Audio-Visual-Olfactory Resource Allocation for Tri-modal Virtual
  Environments
Authors: Efstratios Doukakis, Kurt Debattista, Thomas Bashford-Rogers, Amar
  Dhokia, Ali Asadipour, Alan Chalmers and Carlo Harvey
Categories: cs.GR cs.HC cs.NE
ACM-class: I.3; I.4
DOI: 10.1109/TVCG.2019.2898823
\\
  Virtual Environments (VEs) provide the opportunity to simulate a wide range
of applications, from training to entertainment, in a safe and controlled
manner. For applications which require realistic representations of real world
environments, the VEs need to provide multiple, physically accurate sensory
stimuli. However, simulating all the senses that comprise the human sensory
system (HSS) is a task that requires significant computational resources. Since
it is intractable to deliver all senses at the highest quality, we propose a
resource distribution scheme in order to achieve an optimal perceptual
experience within the given computational budgets. This paper investigates
resource balancing for multi-modal scenarios composed of aural, visual and
olfactory stimuli. Three experimental studies were conducted. The first
experiment identified perceptual boundaries for olfactory computation. In the
second experiment, participants (N=25) were asked, across a fixed number of
budgets (M=5), to identify what they perceived to be the best visual, acoustic
and olfactory stimulus quality for a given computational budget. Results
demonstrate that participants tend to prioritise visual quality compared to
other sensory stimuli. However, as the budget size is increased, users prefer a
balanced distribution of resources with an increased preference for having
smell impulses in the VE. Based on the collected data, a quality prediction
model is proposed and its accuracy is validated against previously unused
budgets and an untested scenario in a third and final experiment.
\\ ( https://arxiv.org/abs/2002.02671 ,  5820kb)
------------------------------------------------------------------------------
\\
arXiv:2002.02792
Date: Thu, 6 Feb 2020 11:11:56 GMT   (5695kb,D)

Title: AnimePose: Multi-person 3D pose estimation and animation
Authors: Laxman Kumarapu and Prerana Mukherjee
Categories: cs.GR cs.CV
Comments: arXiv admin note: text overlap with arXiv:1907.11346 by other authors
\\
  3D animation of humans in action is quite challenging as it involves using a
huge setup with several motion trackers all over the person's body to track the
movements of every limb. This is time-consuming and may cause the person
discomfort in wearing exoskeleton body suits with motion sensors. In this work,
we present a trivial yet effective solution to generate 3D animation of
multiple persons from a 2D video using deep learning. Although significant
improvement has been achieved recently in 3D human pose estimation, most of the
prior works work well in case of single person pose estimation and multi-person
pose estimation is still a challenging problem. In this work, we firstly
propose a supervised multi-person 3D pose estimation and animation framework
namely AnimePose for a given input RGB video sequence. The pipeline of the
proposed system consists of various modules: i) Person detection and
segmentation, ii) Depth Map estimation, iii) Lifting 2D to 3D information for
person localization iv) Person trajectory prediction and human pose tracking.
Our proposed system produces comparable results on previous state-of-the-art 3D
multi-person pose estimation methods on publicly available datasets MuCo-3DHP
and MuPoTS-3D datasets and it also outperforms previous state-of-the-art human
pose tracking methods by a significant margin of 11.7% performance gain on MOTA
score on Posetrack 2018 dataset.
\\ ( https://arxiv.org/abs/2002.02792 ,  5695kb)
------------------------------------------------------------------------------
\\
arXiv:2002.02749
Date: Fri, 17 Jan 2020 22:41:33 GMT   (27kb)

Title: A note on the rationing of divisible and indivisible goods in a general
  network
Authors: Shyam Chandramouli, Jay Sethuraman
Categories: cs.GT math.CO
\\
  The study of matching theory has gained importance recently with applications
in Kidney Exchange, House Allocation, School Choice etc. The general theme of
these problems is to allocate goods in a fair manner amongst participating
agents. The agents generally have a unit supply/demand of a good that they want
to exchange with other agents. On the other hand, Bochet et al. study a more
general version of the problem where they allow for agents to have arbitrary
number of divisible goods to be rationed to other agents in the network. In
this current work, our main focus is on non-bipartite networks where agents
have arbitrary units of a homogeneous indivisible good that they want to
exchange with their neighbors. Our aim is to develop mechanisms that would
identify a fair and strategyproof allocation for the agents in the network.
Thus, we generalize the kidney exchange problem to that of a network with
arbitrary capacity of available goods. Our main idea is that this problem and a
couple of other related versions of non-bipartite fair allocation problem can
be suitably transformed to one of fair allocations on bipartite networks for
which we know of well studied fair allocation mechanisms.
\\ ( https://arxiv.org/abs/2002.02749 ,  27kb)
------------------------------------------------------------------------------
\\
arXiv:2002.02789
Date: Thu, 6 Feb 2020 11:57:59 GMT   (17kb)

Title: Computing envy-freeable allocations with limited subsidies
Authors: Ioannis Caragiannis, Stavros Ioannidis
Categories: cs.GT cs.CC
ACM-class: F.2.2; I.2.11
\\
  Fair division has emerged as a very hot topic in AI, and envy-freeness is
arguably the most compelling fairness concept. An allocation of indivisible
items to agents is envy-free if no agent prefers the bundle of any other agent
to his own in terms of value. As envy-freeness is rarely a feasible goal, there
is a recent focus on relaxations of its definition. An approach in this
direction is to complement allocations with payments (or subsidies) to the
agents. A feasible goal then is to achieve envy-freeness in terms of the total
value an agent gets from the allocation and the subsidies.
  We consider the natural optimization problem of computing allocations that
are {\em envy-freeable} using the minimum amount of subsidies. As the problem
is NP-hard, we focus on the design of approximation algorithms. On the positive
side, we present an algorithm which, for a constant number of agents,
approximates the minimum amount of subsidies within any required accuracy, at
the expense of a graceful increase in the running time. On the negative side,
we show that, for a superconstant number of agents, the problem of minimizing
subsidies for envy-freeness is not only hard to compute exactly (as a folklore
argument shows) but also, more importantly, hard to approximate.
\\ ( https://arxiv.org/abs/2002.02789 ,  17kb)
------------------------------------------------------------------------------
\\
arXiv:2002.02824
Date: Fri, 7 Feb 2020 14:52:28 GMT   (21kb,D)

Title: Population Monotonic Allocation Schemes for Vertex Cover Games
Authors: Han Xiao, Qizhi Fang, Ding-Zhu Du
Categories: cs.GT cs.DM
MSC-class: 05C57, 91A12, 91A43, 91A46
\\
  For the class of vertex cover games (introduced by Deng et al., Math. Oper.
Res., 24:751-766, 1999), we investigate the population monotonic allocation
schemes (introduced by Sprumont, Games Econ. Behav., 2: 378-394, 1990). We
present a complete characterization for the class of vertex cover games
admitting a population monotonic allocation scheme (PMAS for short), i.e., a
vertex cover game has a PMAS if and only if the underlying graph is
($K_3$,$C_4$,$P_5$)-free. Our characterization implies that the existence of a
PMAS can be determined efficiently for vertex cover games. We also propose an
alternative description for PMAS-es in vertex cover games based on the dual
linear program of the vertex cover problem, which reveals the dual-based
allocation scheme nature of PMAS-es. Moreover, we give a complete
characterization for integral PMAS-es in vertex cover games via stable
matchings and show that the celebrated Gale-Shapley algorithm (introduced by
Gale and Shapley, Amer. Math. Monthly, 69:9-15, 1962) can be used to produce
all integral PMAS-es in vertex cover games.
\\ ( https://arxiv.org/abs/2002.02824 ,  21kb)
------------------------------------------------------------------------------
\\
arXiv:2002.02453
Date: Thu, 6 Feb 2020 18:26:11 GMT   (6150kb,D)

Title: Modeling Engagement in Long-Term, In-Home Socially Assistive Robot
  Interventions for Children with Autism Spectrum Disorders
Authors: Shomik Jain, Balasubramanian Thiagarajan, Zhonghao Shi, Caitlyn
  Clabaugh, Maja J. Matari\'c
Categories: cs.HC cs.LG cs.RO
Comments: This manuscript has been accepted for publication in Science Robotics
  (February 2020)
ACM-class: I.2.9
\\
  Socially assistive robotics (SAR) has great potential to provide accessible,
affordable, and personalized therapeutic interventions for children with autism
spectrum disorders (ASD). However, human-robot interaction (HRI) methods are
still limited in their ability to autonomously recognize and respond to
behavioral cues, especially in atypical users and everyday settings. This work
applies supervised machine learning algorithms to model user engagement in the
context of long-term, in-home SAR interventions for children with ASD.
Specifically, two types of engagement models are presented for each user: 1)
generalized models trained on data from different users; and 2) individualized
models trained on an early subset of the user's data. The models achieved
approximately 90% accuracy (AUROC) for post hoc binary classification of
engagement, despite the high variance in data observed across users, sessions,
and engagement states. Moreover, temporal patterns in model predictions could
be used to reliably initiate re-engagement actions at appropriate times. These
results validate the feasibility and challenges of recognition and response to
user disengagement in long-term, real-world HRI settings. The contributions of
this work also inform the design of engaging and personalized HRI, especially
for the ASD community.
\\ ( https://arxiv.org/abs/2002.02453 ,  6150kb)
------------------------------------------------------------------------------
\\
arXiv:2002.02526
Date: Sat, 11 Jan 2020 17:15:58 GMT   (202kb)

Title: How to Answer Why -- Evaluating the Explanations of AI Through Mental
  Model Analysis
Authors: Tim Schrills, Thomas Franke
Categories: cs.HC cs.AI
Comments: 2 pages
\\
  To achieve optimal human-system integration in the context of user-AI
interaction it is important that users develop a valid representation of how AI
works. In most of the everyday interaction with technical systems users
construct mental models (i.e., an abstraction of the anticipated mechanisms a
system uses to perform a given task). If no explicit explanations are provided
by a system (e.g. by a self-explaining AI) or other sources (e.g. an
instructor), the mental model is typically formed based on experiences, i.e.
the observations of the user during the interaction. The congruence of this
mental model and the actual systems functioning is vital, as it is used for
assumptions, predictions and consequently for decisions regarding system use. A
key question for human-centered AI research is therefore how to validly survey
users' mental models. The objective of the present research is to identify
suitable elicitation methods for mental model analysis. We evaluated whether
mental models are suitable as an empirical research method. Additionally,
methods of cognitive tutoring are integrated. We propose an exemplary method to
evaluate explainable AI approaches in a human-centered way.
\\ ( https://arxiv.org/abs/2002.02526 ,  202kb)
------------------------------------------------------------------------------
\\
arXiv:2002.02591
Date: Fri, 7 Feb 2020 02:29:38 GMT   (819kb,D)

Title: Long-Range Gesture Recognition Using Millimeter Wave Radar
Authors: Yu Liu, Yuheng Wang, Haipeng Liu, Anfu Zhou, Jianhua Liu, and Ning
  Yang
Categories: cs.HC eess.SP
Comments: 15pages,16 figures
\\
  Millimeter wave (mmWave) based gesture recognition technology provides a good
human computer interaction (HCI) experience. Prior works focus on the
close-range gesture recognition, but fall short in range extension, i.e., they
are unable to recognize gestures more than one meter away from considerable
noise motions. In this paper, we design a long-range gesture recognition model
which utilizes a novel data processing method and a customized artificial
Convolutional Neural Network (CNN). Firstly, we break down gestures into
multiple reflection points and extract their spatial-temporal features which
depict gesture details. Secondly, we design a CNN to learn changing patterns of
extracted features respectively and output the recognition result. We
thoroughly evaluate our proposed system by implementing on a commodity mmWave
radar. Besides, we also provide more extensive assessments to demonstrate that
the proposed system is practical in several real-world scenarios.
\\ ( https://arxiv.org/abs/2002.02591 ,  819kb)
------------------------------------------------------------------------------
\\
arXiv:2002.02635
Date: Fri, 7 Feb 2020 06:32:05 GMT   (3102kb,D)

Title: Noncontact Thermal and Vibrotactile Display Using Focused Airborne
  Ultrasound
Authors: Takaaki Kamigaki, Shun Suzuki, and Hiroyuki Shinoda
Categories: cs.HC
Comments: 6 pages
\\
  In a typical mid-air haptics system, focused airborne ultrasound provides
vibrotactile sensations to localized areas on a bare skin. Herein, a method for
displaying thermal sensations to hands where mesh fabric gloves are worn is
proposed. The gloves employed in this study are commercially available mesh
fabric gloves with sound absorption characteristics, such as cotton work gloves
without any additional devices such as Peltier elements. The method proposed in
this study can also provide vibrotactile sensations by changing the ultrasonic
irradiation pattern. In this paper, we report basic experimental investigations
on the proposed method. By performing thermal measurements, we evaluate the
local heat generation on the surfaces of both the glove and the skin by focused
airborne ultrasound irradiation. In addition, we performed perceptual
experiments, thereby confirming that the proposed method produced both thermal
and vibrotactile sensations. Furthermore, these sensations were selectively
provided to a certain extent by changing the ultrasonic irradiation pattern.
These results validate the effectiveness of our method and its feasibility in
mid-air haptics applications.
\\ ( https://arxiv.org/abs/2002.02635 ,  3102kb)
------------------------------------------------------------------------------
\\
arXiv:2002.02595
Date: Fri, 7 Feb 2020 02:42:07 GMT   (233kb)

Title: ML Estimation and MAP Estimation for Device Activities in Grant-Free
  Random Access with Interference
Authors: Dongdong Jiang and Ying Cui
Categories: cs.IT eess.SP math.IT
Comments: 6 pages, 5 figures, to be publised in IEEE WCNC 2020
\\
  Device activity detection is one main challenge in grant-free random access,
which is recently proposed to support massive access for massive machine-type
communications (mMTC). Existing solutions fail to consider interference
generated by massive Internet of Things (IoT) devices, or important prior
information on device activities and interference. In this paper, we consider
device activity detection at an access point (AP) in the presence of
interference generated by massive devices from other cells. We consider the
joint maximum likelihood (ML) estimation and the joint maximum a posterior
probability (MAP) estimation of both the device activities and interference
powers, jointly utilizing tools from probability, stochastic geometry and
optimization. Each estimation problem is a difference of convex (DC)
programming problem, and a coordinate descent algorithm is proposed to obtain a
stationary point. The proposed ML estimation extends the existing ML estimation
by considering the estimation of interference powers together with the
estimation of device activities. The proposed MAP estimation further enhances
the proposed ML estimation by exploiting prior distributions of device
activities and interference powers. Numerical results show the substantial
gains of the proposed joint estimation designs, and reveal the importance of
explicit consideration of interference and the value of prior information in
device activity detection.
\\ ( https://arxiv.org/abs/2002.02595 ,  233kb)
------------------------------------------------------------------------------
\\
arXiv:2002.02617
Date: Fri, 7 Feb 2020 04:37:01 GMT   (1011kb)

Title: Compressive Massive Access for Internet of Things: Cloud Computing or
  Fog Computing?
Authors: Malong Ke, Zhen Gao, and Yongpeng Wu
Categories: cs.IT eess.SP math.IT
Comments: 7 pages, 7 figures, accepted by IEEE International Conference on
  Communications (ICC) 2020, Dublin, Ireland
\\
  This paper considers the support of grant-free massive access and solves the
challenge of active user detection and channel estimation in the case of a
massive number of users. By exploiting the sparsity of user activities, the
concerned problems are formulated as a compressive sensing problem, whose
solution is acquired by approximate message passing (AMP) algorithm.
Considering the cooperation of multiple access points, for the deployment of
AMP algorithm, we compare two processing paradigms, cloud computing and fog
computing, in terms of their effectiveness in guaranteeing ultra reliable
low-latency access. For cloud computing, the access points are connected in a
cloud radio access network (C-RAN) manner, and the signals received at all
access points are concentrated and jointly processed in the cloud baseband
unit. While for fog computing, based on fog radio access network (F-RAN), the
estimation of user activity and corresponding channels for the whole network is
split, and the related processing tasks are performed at the access points and
fog processing units in proximity to users. Compared to the cloud computing
paradigm based on traditional C-RAN, simulation results demonstrate the
superiority of the proposed fog computing deployment based on F-RAN.
\\ ( https://arxiv.org/abs/2002.02617 ,  1011kb)
------------------------------------------------------------------------------
\\
arXiv:2002.02628
Date: Fri, 7 Feb 2020 05:25:53 GMT   (378kb)

Title: Jointly Sparse Signal Recovery via Deep Auto-Encoder and Parallel
  Coordinate Descent Unrolling
Authors: Shuaichao Li, Wanqing Zhang, Ying Cui
Categories: cs.IT eess.SP math.IT
Comments: 6 pages, 13 figures, to be published in IEEE WCNC 2020
\\
  In this paper, utilizing techniques in compressed sensing, parallel
optimization and deep learning, we propose a model-driven approach to jointly
design the common measurement matrix and GROUP LASSO-based jointly sparse
signal recovery method for complex sparse signals, based on the standard
auto-encoder structure for real numbers. The encoder achieves noisy linear
compression for jointly sparse signals, with a common measurement matrix. The
GROUP LASSO-based decoder realizes jointly sparse signal recovery based on an
iterative parallel-coordinate descent (PCD) algorithm which is proposed to
solve GROUP LASSO in a parallel manner. In particular, the decoder consists of
an approximation part which unfolds (several iterations of) the proposed
iterative algorithm to obtain an approximate solution of GROUP LASSO and a
correction part which reduces the difference between the approximate solution
and the actual jointly sparse signals. The proposed model-driven approach
achieves higher recovery accuracy with less computation time than the classic
GROUP LASSO method, and the gain significantly increases in the presence of
extra structures in sparse patterns. The common measurement matrix obtained by
the proposed model-driven approach is also suitable for the classic GROUP LASSO
method. We consider an application example, i.e., channel estimation in
Multiple-Input Multiple-Output (MIMO)-based grant-free random access which is
proposed to support massive machine-type communications (mMTC) for Internet of
Things (IoT). By numerical results, we demonstrate the substantial gains of the
proposed model-driven approach over GROUP LASSO and AMP when the number of
jointly sparse signals is not very large.
\\ ( https://arxiv.org/abs/2002.02628 ,  378kb)
------------------------------------------------------------------------------
\\
arXiv:2002.02716
Date: Fri, 7 Feb 2020 11:11:09 GMT   (4kb)

Title: On Sampling Continuous-Time Gaussian Channels
Authors: Guangyue Han and Shlomo Shamai
Categories: cs.IT math.IT
\\
  For a continuous-time Gaussian channel, it has been shown that as sampling
gets infinitesimally fine, the mutual information of the corresponding
discrete-time counterparts converges to that of the original continuous-time
channel. We give in this paper more quantitative strengthenings of this result,
which, among other implications, characterize how over-sampling approaches the
true mutual information of a continuous-time Gaussian channel with bandwidth
limit. Compared to the Shannon-Nyquist sampling theorem, a widely used tool to
connect continuous-time Gaussian channels to their discrete-time counterparts
that requires the band-limitedness of the channel input, our results only
require some integrability conditions on the power spectral density function of
the input.
\\ ( https://arxiv.org/abs/2002.02716 ,  4kb)
------------------------------------------------------------------------------
\\
arXiv:2002.02750
Date: Fri, 7 Feb 2020 13:03:22 GMT   (471kb,D)

Title: Deep HyperNetwork-Based MIMO Detection
Authors: Mathieu Goutay, Fay\c{c}al Ait Aoudia, Jakob Hoydis
Categories: cs.IT cs.LG eess.SP math.IT
\\
  Optimal symbol detection for multiple-input multiple-output (MIMO) systems is
known to be an NP-hard problem. Conventional heuristic algorithms are either
too complex to be practical or suffer from poor performance. Recently, several
approaches tried to address those challenges by implementing the detector as a
deep neural network. However, they either still achieve unsatisfying
performance on practical spatially correlated channels, or are computationally
demanding since they require retraining for each channel realization. In this
work, we address both issues by training an additional neural network (NN),
referred to as the hypernetwork, which takes as input the channel matrix and
generates the weights of the neural NN-based detector. Results show that the
proposed approach achieves near state-of-the-art performance without the need
of re-training.
\\ ( https://arxiv.org/abs/2002.02750 ,  471kb)
------------------------------------------------------------------------------
\\
arXiv:2002.02817
Date: Fri, 7 Feb 2020 14:44:40 GMT   (172kb,D)

Title: Timely Updates By Multiple Sources: The M/M/1 Queue Revisited
Authors: Sanjit K. Kaul and Roy D. Yates
Categories: cs.IT math.IT
\\
  Multiple sources submit updates to a monitor through an M/M/1 queue. A
stochastic hybrid system (SHS) approach is used to derive the average age of
information (AoI) for an individual source as a function of the offered load of
that source and the competing update traffic offered by other sources. This
work corrects an error in a prior analysis. By numerical evaluation, this error
is observed to be small and qualitatively insignificant.
\\ ( https://arxiv.org/abs/2002.02817 ,  172kb)
------------------------------------------------------------------------------
\\
arXiv:2002.02851
Date: Fri, 7 Feb 2020 15:36:10 GMT   (23kb)

Title: On the Estimation of Information Measures of Continuous Distributions
Authors: Georg Pichler and Pablo Piantanida and G\"unther Koliander
Categories: cs.IT cs.LG math.IT math.ST stat.TH
Comments: 19 pages
\\
  The estimation of information measures of continuous distributions based on
samples is a fundamental problem in statistics and machine learning. In this
paper, we analyze estimates of differential entropy in $K$-dimensional
Euclidean space, computed from a finite number of samples, when the probability
density function belongs to a predetermined convex family $\mathcal{P}$. First,
estimating differential entropy to any accuracy is shown to be infeasible if
the differential entropy of densities in $\mathcal{P}$ is unbounded, clearly
showing the necessity of additional assumptions. Subsequently, we investigate
sufficient conditions that enable confidence bounds for the estimation of
differential entropy. In particular, we provide confidence bounds for simple
histogram based estimation of differential entropy from a fixed number of
samples, assuming that the probability density function is Lipschitz continuous
with known Lipschitz constant and known, bounded support. Our focus is on
differential entropy, but we provide examples that show that similar results
hold for mutual information and relative entropy as well.
\\ ( https://arxiv.org/abs/2002.02851 ,  23kb)
------------------------------------------------------------------------------
\\
arXiv:2002.02460
Date: Thu, 6 Feb 2020 19:00:02 GMT   (1145kb,D)

Title: Intelligent Arxiv: Sort daily papers by learning users topics preference
Authors: Ezequiel Alvarez (ICAS), Federico Lamagna (CAB), Cesar Miquel
  (Easytech) and Manuel Szewc (ICAS)
Categories: cs.LG astro-ph.HE gr-qc hep-ph hep-th stat.ML
Comments: We are open to new ideas and to scientists and institutions wishing
  to collaborate and/or partner in further improvements for this service. With
  this tool the time a paper is sent is irrelevant for its order of appearance
Report-no: ICAS 047/20
\\
  Current daily paper releases are becoming increasingly large and areas of
research are growing in diversity. This makes it harder for scientists to keep
up to date with current state of the art and identify relevant work within
their lines of interest. The goal of this article is to address this problem
using Machine Learning techniques. We model a scientific paper to be built as a
combination of different scientific knowledge from diverse topics into a new
problem. In light of this, we implement the unsupervised Machine Learning
technique of Latent Dirichlet Allocation (LDA) on the corpus of papers in a
given field to: i) define and extract underlying topics in the corpus; ii) get
the topics weight vector for each paper in the corpus; and iii) get the topics
weight vector for new papers. By registering papers preferred by a user, we
build a user vector of weights using the information of the vectors of the
selected papers. Hence, by performing an inner product between the user vector
and each paper in the daily Arxiv release, we can sort the papers according to
the user preference on the underlying topics.
  We have created the website IArxiv.org where users can read sorted daily
Arxiv releases (and more) while the algorithm learns each users preference,
yielding a more accurate sorting every day. Current IArxiv.org version runs on
Arxiv categories astro-ph, gr-qc, hep-ph and hep-th and we plan to extend to
others. We propose several new useful and relevant implementations to be
additionally developed as well as new Machine Learning techniques beyond LDA to
further improve the accuracy of this new tool.
\\ ( https://arxiv.org/abs/2002.02460 ,  1145kb)
------------------------------------------------------------------------------
\\
arXiv:2002.02492
Date: Thu, 6 Feb 2020 19:56:15 GMT   (48kb,D)

Title: Consistency of a Recurrent Language Model With Respect to Incomplete
  Decoding
Authors: Sean Welleck, Ilia Kulikov, Jaedeok Kim, Richard Yuanzhe Pang,
  Kyunghyun Cho
Categories: cs.LG cs.CL stat.ML
\\
  Despite strong performance on a variety of tasks, neural sequence models
trained with maximum likelihood have been shown to exhibit issues such as
length bias and degenerate repetition. We study the related issue of receiving
infinite-length sequences from a recurrent language model when using common
decoding algorithms. To analyze this issue, we first define inconsistency of a
decoding algorithm, meaning that the algorithm can yield an infinite-length
sequence that has zero probability under the model. We prove that commonly used
incomplete decoding algorithms - greedy search, beam search, top-k sampling,
and nucleus sampling - are inconsistent, despite the fact that recurrent
language models are trained to produce sequences of finite length. Based on
these insights, we propose two remedies which address inconsistency: consistent
variants of top-k and nucleus sampling, and a self-terminating recurrent
language model. Empirical results show that inconsistency occurs in practice,
and that the proposed methods prevent inconsistency.
\\ ( https://arxiv.org/abs/2002.02492 ,  48kb)
------------------------------------------------------------------------------
\\
arXiv:2002.02508
Date: Thu, 6 Feb 2020 20:40:53 GMT   (222kb,D)

Title: Achieving the fundamental convergence-communication tradeoff with
  Differentially Quantized Gradient Descent
Authors: Chung-Yi Lin, Victoria Kostina, and Babak Hassibi
Categories: cs.LG cs.IT math.IT stat.ML
\\
  The problem of reducing the communication cost in distributed training
through gradient quantization is considered. For the class of smooth and
strongly convex objective functions, we characterize the minimum achievable
linear convergence rate for a given number of bits per problem dimension $n$.
We propose Differentially Quantized Gradient Descent, a quantization algorithm
with error compensation, and prove that it achieves the fundamental tradeoff
between communication rate and convergence rate as $n$ goes to infinity. In
contrast, the naive quantizer that compresses the current gradient directly
fails to achieve that optimal tradeoff. Experimental results on both simulated
and real-world least-squares problems confirm our theoretical analysis.
\\ ( https://arxiv.org/abs/2002.02508 ,  222kb)
------------------------------------------------------------------------------
\\
arXiv:2002.02515
Date: Thu, 6 Feb 2020 21:17:32 GMT   (1176kb,D)

Title: Duality of Width and Depth of Neural Networks
Authors: Fenglei-Lei Fan, Ge Wang
Categories: cs.LG stat.ML
\\
  Here, we report that the depth and the width of a neural network are dual
from two perspectives. First, we employ the partially separable representation
to determine the width and depth. Second, we use the De Morgan law to guide the
conversion between a deep network and a wide network. Furthermore, we suggest
the generalized De Morgan law to promote duality to network equivalency.
\\ ( https://arxiv.org/abs/2002.02515 ,  1176kb)
------------------------------------------------------------------------------
\\
arXiv:2002.02518
Date: Thu, 6 Feb 2020 21:27:04 GMT   (1547kb,D)

Title: One-Shot Bayes Opt with Probabilistic Population Based Training
Authors: Jack Parker-Holder and Vu Nguyen and Stephen Roberts
Categories: cs.LG stat.ML
\\
  Selecting optimal hyperparameters is a key challenge in machine learning. An
exciting recent result showed it is possible to learn high-performing
hyperparameter schedules on the fly in a single training run through methods
inspired by Evolutionary Algorithms. These approaches have been shown to
increase performance across a wide variety of machine learning tasks, ranging
from supervised (SL) to reinforcement learning (RL). However, since they remain
primarily evolutionary, they act in a greedy fashion, thus require a
combination of vast computational resources and carefully selected
meta-parameters to effectively explore the hyperparameter space. To address
these shortcomings we look to Bayesian Optimization (BO), where a Gaussian
Process surrogate model is combined with an acquisition function to produce a
principled mechanism to trade off exploration vs exploitation. Our approach,
which we call Probabilistic Population-Based Training ($\mathrm{P2BT}$), is
able to transfer sample efficiency of BO to the online setting, making it
possible to achieve these traits in a single training run. We show that
$\mathrm{P2BT}$ is able to achieve high performance with only a small
population size, making it useful for all researchers regardless of their
computational resources.
\\ ( https://arxiv.org/abs/2002.02518 ,  1547kb)
------------------------------------------------------------------------------
\\
arXiv:2002.02528
Date: Thu, 23 Jan 2020 01:50:22 GMT   (3866kb)

Title: On generalized residue network for deep learning of unknown dynamical
  systems
Authors: Zhen Chen and Dongbin Xiu
Categories: cs.LG cs.NA math.DS math.NA stat.ML
\\
  We present a general numerical approach for learning unknown dynamical
systems using deep neural networks (DNNs). Our method is built upon recent
studies that identified the residue network (ResNet) as an effective neural
network structure. In this paper, we present a generalized ResNet framework and
broadly define residue as the discrepancy between observation data and
prediction made by another model, which can be an existing coarse model or
reduced-order model. In this case, the generalized ResNet serves as a model
correction to the existing model and recovers the unresolved dynamics. When an
existing coarse model is not available, we present numerical strategies for
fast creation of coarse models, to be used in conjunction with the generalized
ResNet. These coarse models are constructed using the same data set and thus do
not require additional resources. The generalized ResNet is capable of learning
the underlying unknown equations and producing predictions with accuracy higher
than the standard ResNet structure. This is demonstrated via several numerical
examples, including long-term prediction of a chaotic system.
\\ ( https://arxiv.org/abs/2002.02528 ,  3866kb)
------------------------------------------------------------------------------
\\
arXiv:2002.02547
Date: Thu, 6 Feb 2020 22:58:51 GMT   (1089kb,D)

Title: Closing the Dequantization Gap: PixelCNN as a Single-Layer Flow
Authors: Didrik Nielsen, Ole Winther
Categories: cs.LG cs.CV stat.ML
\\
  Flow models have recently made great progress at modeling quantized sensor
data such as images and audio. Due to the continuous nature of flow models,
dequantization is typically applied when using them for such quantized data. In
this paper, we propose subset flows, a class of flows which can tractably
transform subsets of the input space in one pass. As a result, they can be
applied directly to quantized data without the need for dequantization. Based
on this class of flows, we present a novel interpretation of several existing
autoregressive models, including WaveNet and PixelCNN, as single-layer flow
models defined through an invertible transformation between uniform noise and
data samples. This interpretation suggests that these existing models, 1) admit
a latent representation of data and 2) can be stacked in multiple flow layers.
We demonstrate this by exploring the latent space of a PixelCNN and by stacking
PixelCNNs in multiple flow layers.
\\ ( https://arxiv.org/abs/2002.02547 ,  1089kb)
------------------------------------------------------------------------------
\\
arXiv:2002.02557
Date: Thu, 6 Feb 2020 23:56:46 GMT   (132kb,D)

Title: JPLink: On Linking Jobs to Vocational Interest Types
Authors: Amila Silva and Pei-Chi Lo and Ee-Peng Lim
Categories: cs.LG cs.IR stat.ML
\\
  Linking job seekers with relevant jobs requires matching based on not only
skills, but also personality types. Although the Holland Code also known as
RIASEC has frequently been used to group people by their suitability for six
different categories of occupations, the RIASEC category labels of individual
jobs are often not found in job posts. This is attributed to significant manual
efforts required for assigning job posts with RIASEC labels. To cope with
assigning massive number of jobs with RIASEC labels, we propose JPLink, a
machine learning approach using the text content in job titles and job
descriptions. JPLink exploits domain knowledge available in an
occupation-specific knowledge base known as O*NET to improve feature
representation of job posts. To incorporate relative ranking of RIASEC labels
of each job, JPLink proposes a listwise loss function inspired by learning to
rank. Both our quantitative and qualitative evaluations show that JPLink
outperforms conventional baselines. We conduct an error analysis on JPLink's
predictions to show that it can uncover label errors in existing job posts.
\\ ( https://arxiv.org/abs/2002.02557 ,  132kb)
------------------------------------------------------------------------------
\\
arXiv:2002.02561
Date: Fri, 7 Feb 2020 00:03:40 GMT   (519kb,D)

Title: Spectrum Dependent Learning Curves in Kernel Regression and Wide Neural
  Networks
Authors: Blake Bordelon, Abdulkadir Canatar, Cengiz Pehlevan
Categories: cs.LG stat.ML
\\
  A fundamental question in modern machine learning is how deep neural networks
can generalize. We address this question using 1) an equivalence between
training infinitely wide neural networks and performing kernel regression with
a deterministic kernel called the Neural Tangent Kernel (NTK) (Jacot et al.
2018), and 2) theoretical tools from statistical physics. We derive analytical
expressions for learning curves for kernel regression, and use them to evaluate
how the test loss of a trained neural network depends on the number of samples.
Our approach allows us not only to compute the total test risk but also the
decomposition of the risk due to different spectral components of the kernel.
Complementary to recent results showing that during gradient descent, neural
networks fit low frequency components first, we identify a new type of
frequency principle: as the size of the training set size grows, kernel
machines and neural networks begin to fit successively higher frequency modes
of the target function. We verify our theory with simulations of kernel
regression and training wide artificial neural networks.
\\ ( https://arxiv.org/abs/2002.02561 ,  519kb)
------------------------------------------------------------------------------
\\
arXiv:2002.02572
Date: Fri, 7 Feb 2020 00:55:10 GMT   (9148kb,D)

Title: Multimodal Controller for Generative Models
Authors: Enmao Diao, Jie Ding, Vahid Tarokh
Categories: cs.LG stat.ML
\\
  Class-conditional generative models are crucial tools for data generation
from user-specified class labels. A number of existing approaches for
class-conditional generative models require nontrivial modifications of
existing architectures, in order to model conditional information fed into the
model. In this paper, we introduce a new method called multimodal controller to
generate multimodal data without introducing additional model parameters. With
the proposed technique, the model can be trained easily from non-conditional
generative models by simply attaching controllers at each layer. Each
controller grants label-specific model parameters. Thus the proposed method
does not require additional model complexity. In the absence of the
controllers, our model reduces to non-conditional generative models. Numerical
experiments demonstrate the effectiveness of our proposed method in comparison
with those of the existing non-conditional and conditional generative models.
Additionally, our numerical results demonstrate that a small portion (10%) of
label-specific model parameters is required to generate class-conditional MNIST
and FashionMNIST images.
\\ ( https://arxiv.org/abs/2002.02572 ,  9148kb)
------------------------------------------------------------------------------
\\
arXiv:2002.02581
Date: Fri, 7 Feb 2020 01:44:18 GMT   (555kb,D)

Title: Dynamic Energy Dispatch in Isolated Microgrids Based on Deep
  Reinforcement Learning
Authors: Lei Lei, Yue Tan, Glenn Dahlenburg, Wei Xiang, Kan Zheng
Categories: cs.LG eess.SP stat.ML
\\
  This paper focuses on deep reinforcement learning (DRL)-based energy dispatch
for isolated microgrids (MGs) with diesel generators (DGs), photovoltaic (PV)
panels, and a battery. A finite-horizon Partial Observable Markov Decision
Process (POMDP) model is formulated and solved by learning from historical data
to capture the uncertainty in future electricity consumption and renewable
power generation. In order to deal with the instability problem of DRL
algorithms and unique characteristics of finite-horizon models, two novel DRL
algorithms, namely, FH-DDPG and FH-RDPG, are proposed to derive energy dispatch
policies with and without fully observable state information. A case study
using real isolated microgrid data is performed, where the performance of the
proposed algorithms are compared with the myopic algorithm as well as other
baseline DRL algorithms. Moreover, the impact of uncertainties on MG
performance is decoupled into two levels and evaluated respectively.
\\ ( https://arxiv.org/abs/2002.02581 ,  555kb)
------------------------------------------------------------------------------
\\
arXiv:2002.02600
Date: Fri, 7 Feb 2020 03:08:31 GMT   (639kb,D)

Title: Solving high-dimensional eigenvalue problems using deep neural networks:
  A diffusion Monte Carlo like approach
Authors: Jiequn Han, Jianfeng Lu, Mo Zhou
Categories: cs.LG cs.NA math.NA physics.comp-ph stat.ML
Comments: 15 pages, 4 figures, 3 tables
\\
  We propose a new method to solve eigenvalue problems for linear and
semilinear second order differential operators in high dimensions based on deep
neural networks. The eigenvalue problem is reformulated as a fixed point
problem of the semigroup flow induced by the operator, whose solution can be
represented by Feynman-Kac formula in terms of forward-backward stochastic
differential equations. The method shares a similar spirit with diffusion Monte
Carlo but augments a direct approximation to the eigenfunction through
neural-network ansatz. The criterion of fixed point provides a natural loss
function to search for parameters via optimization. Our approach is able to
provide accurate eigenvalue and eigenfunction approximations in several
numerical examples, including Fokker-Planck operator, linear and nonlinear
Schr\"odinger operators in high dimensions.
\\ ( https://arxiv.org/abs/2002.02600 ,  639kb)
------------------------------------------------------------------------------
\\
arXiv:2002.02644
Date: Fri, 7 Feb 2020 06:59:05 GMT   (49kb,D)

Title: Temporal Probability Calibration
Authors: Tim Leathart and Maksymilian Polaczuk
Categories: cs.LG stat.ML
\\
  In many applications, accurate class probability estimates are required, but
many types of models produce poor quality probability estimates despite
achieving acceptable classification accuracy. Even though probability
calibration has been a hot topic of research in recent times, the majority of
this has investigated non-sequential data. In this paper, we consider
calibrating models that produce class probability estimates from sequences of
data, focusing on the case where predictions are obtained from incomplete
sequences. We show that traditional calibration techniques are not sufficiently
expressive for this task, and propose methods that adapt calibration schemes
depending on the length of an input sequence. Experimental evaluation shows
that the proposed methods are often substantially more effective at calibrating
probability estimates from modern sequential architectures for incomplete
sequences across a range of application domains.
\\ ( https://arxiv.org/abs/2002.02644 ,  49kb)
------------------------------------------------------------------------------
\\
arXiv:2002.02645
Date: Fri, 7 Feb 2020 07:03:58 GMT   (646kb,D)

Title: Accelerating Deep Learning Inference via Freezing
Authors: Adarsh Kumar, Arjun Balasubramanian, Shivaram Venkataraman, Aditya
  Akella
Categories: cs.LG stat.ML
Comments: 11th USENIX Workshop on Hot Topics in Cloud Computing, HotCloud 2019
\\
  Over the last few years, Deep Neural Networks (DNNs) have become ubiquitous
owing to their high accuracy on real-world tasks. However, this increase in
accuracy comes at the cost of computationally expensive models leading to
higher prediction latencies. Prior efforts to reduce this latency such as
quantization, model distillation, and any-time prediction models typically
trade-off accuracy for performance. In this work, we observe that caching
intermediate layer outputs can help us avoid running all the layers of a DNN
for a sizeable fraction of inference requests. We find that this can
potentially reduce the number of effective layers by half for 91.58% of
CIFAR-10 requests run on ResNet-18. We present Freeze Inference, a system that
introduces approximate caching at each intermediate layer and we discuss
techniques to reduce the cache size and improve the cache hit rate. Finally, we
discuss some of the open research challenges in realizing such a design.
\\ ( https://arxiv.org/abs/2002.02645 ,  646kb)
------------------------------------------------------------------------------
\\
arXiv:2002.02655
Date: Fri, 7 Feb 2020 07:33:15 GMT   (453kb,D)

Title: The k-tied Normal Distribution: A Compact Parameterization of Gaussian
  Mean Field Posteriors in Bayesian Neural Networks
Authors: Jakub Swiatkowski, Kevin Roth, Bastiaan S. Veeling, Linh Tran, Joshua
  V. Dillon, Stephan Mandt, Jasper Snoek, Tim Salimans, Rodolphe Jenatton,
  Sebastian Nowozin
Categories: cs.LG stat.ML
\\
  Variational Bayesian Inference is a popular methodology for approximating
posterior distributions over Bayesian neural network weights. Recent work
developing this class of methods has explored ever richer parameterizations of
the approximate posterior in the hope of improving performance. In contrast,
here we share a curious experimental finding that suggests instead restricting
the variational distribution to a more compact parameterization. For a variety
of deep Bayesian neural networks trained using Gaussian mean-field variational
inference, we find that the posterior standard deviations consistently exhibit
strong low-rank structure after convergence. This means that by decomposing
these variational parameters into a low-rank factorization, we can make our
variational approximation more compact without decreasing the models'
performance. Furthermore, we find that such factorized parameterizations
improve the signal-to-noise ratio of stochastic gradient estimates of the
variational lower bound, resulting in faster convergence.
\\ ( https://arxiv.org/abs/2002.02655 ,  453kb)
------------------------------------------------------------------------------
\\
arXiv:2002.02664
Date: Fri, 7 Feb 2020 08:33:07 GMT   (1895kb,D)

Title: Short sighted deep learning
Authors: Ellen de Melllo Koch, Anita de Mello Koch, Nicholas Kastanos, Ling
  Cheng
Categories: cs.LG cond-mat.stat-mech physics.comp-ph stat.ML
\\
  A theory explaining how deep learning works is yet to be developed. Previous
work suggests that deep learning performs a coarse graining, similar in spirit
to the renormalization group (RG). This idea has been explored in the setting
of a local (nearest neighbor interactions) Ising spin lattice. We extend the
discussion to the setting of a long range spin lattice. Markov Chain Monte
Carlo (MCMC) simulations determine both the critical temperature and scaling
dimensions of the system. The model is used to train both a single RBM
(restricted Boltzmann machine) network, as well as a stacked RBM network.
Following earlier Ising model studies, the trained weights of a single layer
RBM network define a flow of lattice models. In contrast to results for nearest
neighbor Ising, the RBM flow for the long ranged model does not converge to the
correct values for the spin and energy scaling dimension. Further, correlation
functions between visible and hidden nodes exhibit key differences between the
stacked RBM and RG flows. The stacked RBM flow appears to move towards low
temperatures whereas the RG flow moves towards high temperature. This again
differs from results obtained for nearest neighbor Ising.
\\ ( https://arxiv.org/abs/2002.02664 ,  1895kb)
------------------------------------------------------------------------------
\\
arXiv:2002.02667
Date: Fri, 7 Feb 2020 08:43:34 GMT   (1458kb,D)

Title: Automated Lane Change Strategy using Proximal Policy Optimization-based
  Deep Reinforcement Learning
Authors: Fei Ye, Xuxin Cheng, Pin Wang and Ching-Yao Chan
Categories: cs.LG cs.AI cs.RO eess.SP
\\
  Lane-change maneuvers are commonly executed by drivers to follow a certain
routing plan, overtake a slower vehicle, adapt to a merging lane ahead, etc.
However, improper lane change behaviors can be a major cause of traffic flow
disruptions and even crashes. While many rule-based methods have been proposed
to solve lane change problems for autonomous driving, they tend to exhibit
limited performance due to the uncertainty and complexity of the driving
environment. Machine learning-based methods offer an alternative approach, as
Deep reinforcement learning (DRL) has shown promising success in many
application domains including robotic manipulation, navigation, and playing
video games. However, applying DRL for autonomous driving still faces many
practical challenges in terms of slow learning rates, sample inefficiency, and
non-stationary trajectories. In this study, we propose an automated lane change
strategy using proximal policy optimization-based deep reinforcement learning,
which shows great advantage in learning efficiency while maintaining stable
performance. The trained agent is able to learn a smooth, safe, and efficient
driving policy to determine lane-change decisions (i.e. when and how) even in
dense traffic scenarios. The effectiveness of the proposed policy is validated
using task success rate and collision rate, which demonstrates the lane change
maneuvers can be efficiently learned and executed in a safe, smooth and
efficient manner.
\\ ( https://arxiv.org/abs/2002.02667 ,  1458kb)
------------------------------------------------------------------------------
\\
arXiv:2002.02669
Date: Fri, 7 Feb 2020 08:46:26 GMT   (1456kb,D)

Title: Memory Augmented Generative Adversarial Networks for Anomaly Detection
Authors: Ziyi Yang, Teng Zhang, Iman Soltani Bozchalooi, Eric Darve
Categories: cs.LG stat.ML
\\
  In this paper, we present a memory-augmented algorithm for anomaly detection.
Classical anomaly detection algorithms focus on learning to model and generate
normal data, but typically guarantees for detecting anomalous data are weak.
The proposed Memory Augmented Generative Adversarial Networks (MEMGAN)
interacts with a memory module for both the encoding and generation processes.
Our algorithm is such that most of the \textit{encoded} normal data are inside
the convex hull of the memory units, while the abnormal data are isolated
outside. Such a remarkable property leads to good (resp.\ poor) reconstruction
for normal (resp.\ abnormal) data and therefore provides a strong guarantee for
anomaly detection. Decoded memory units in MEMGAN are more interpretable and
disentangled than previous methods, which further demonstrates the
effectiveness of the memory mechanism. Experimental results on twenty anomaly
detection datasets of CIFAR-10 and MNIST show that MEMGAN demonstrates
significant improvements over previous anomaly detection methods.
\\ ( https://arxiv.org/abs/2002.02669 ,  1456kb)
------------------------------------------------------------------------------
\\
arXiv:2002.02675
Date: Fri, 7 Feb 2020 09:11:29 GMT   (1276kb,D)

Title: Discretization and Machine Learning Approximation of BSDEs with a
  Constraint on the Gains-Process
Authors: Idris Kharroubi (LPSM UMR 8001), Thomas Lim (LaMME, ENSIIE), Xavier
  Warin (EDF)
Categories: cs.LG math.OC q-fin.RM stat.ML
\\
  We study the approximation of backward stochastic differential equations
(BSDEs for short) with a constraint on the gains process. We first discretize
the constraint by applying a so-called facelift operator at times of a grid. We
show that this discretely constrained BSDE converges to the continuously
constrained one as the mesh grid converges to zero. We then focus on the
approximation of the discretely constrained BSDE. For that we adopt a machine
learning approach. We show that the facelift can be approximated by an
optimization problem over a class of neural networks under constraints on the
neural network and its derivative. We then derive an algorithm converging to
the discretely constrained BSDE as the number of neurons goes to infinity. We
end by numerical experiments. Mathematics Subject Classification (2010): 65C30,
65M75, 60H35, 93E20, 49L25.
\\ ( https://arxiv.org/abs/2002.02675 ,  1276kb)
------------------------------------------------------------------------------
\\
arXiv:2002.02693
Date: Fri, 7 Feb 2020 09:57:53 GMT   (534kb,D)

Title: Ready Policy One: World Building Through Active Learning
Authors: Philip Ball and Jack Parker-Holder and Aldo Pacchiano and Krzysztof
  Choromanski and Stephen Roberts
Categories: cs.LG stat.ML
\\
  Model-Based Reinforcement Learning (MBRL) offers a promising direction for
sample efficient learning, often achieving state of the art results for
continuous control tasks. However, many existing MBRL methods rely on combining
greedy policies with exploration heuristics, and even those which utilize
principled exploration bonuses construct dual objectives in an ad hoc fashion.
In this paper we introduce Ready Policy One (RP1), a framework that views MBRL
as an active learning problem, where we aim to improve the world model in the
fewest samples possible. RP1 achieves this by utilizing a hybrid objective
function, which crucially adapts during optimization, allowing the algorithm to
trade off reward v.s. exploration at different stages of learning. In addition,
we introduce a principled mechanism to terminate sample collection once we have
a rich enough trajectory batch to improve the model. We rigorously evaluate our
method on a variety of continuous control tasks, and demonstrate statistically
significant gains over existing approaches.
\\ ( https://arxiv.org/abs/2002.02693 ,  534kb)
------------------------------------------------------------------------------
\\
arXiv:2002.02701
Date: Fri, 7 Feb 2020 10:20:49 GMT   (224kb,D)

Title: A novel initialisation based on hospital-resident assignment for the
  k-modes algorithm
Authors: Henry Wilde, Vincent Knight, Jonathan Gillard
Categories: cs.LG cs.GT stat.ML
Comments: 23 pages, 11 figures (31 panels)
\\
  This paper presents a new way of selecting an initial solution for the
k-modes algorithm that allows for a notion of mathematical fairness and a
leverage of the data that the common initialisations from literature do not.
The method, which utilises the Hospital-Resident Assignment Problem to find the
set of initial cluster centroids, is compared with the current initialisations
on both benchmark datasets and a body of newly generated artificial datasets.
Based on this analysis, the proposed method is shown to outperform the other
initialisations in the majority of cases, especially when the number of
clusters is optimised. In addition, we find that our method outperforms the
leading established method specifically for low-density data.
\\ ( https://arxiv.org/abs/2002.02701 ,  224kb)
------------------------------------------------------------------------------
\\
arXiv:2002.02702
Date: Fri, 7 Feb 2020 10:21:49 GMT   (95kb)

Title: DynamicPPL: Stan-like Speed for Dynamic Probabilistic Models
Authors: Mohamed Tarek, Kai Xu, Martin Trapp, Hong Ge, Zoubin Ghahramani
Categories: cs.LG cs.PL stat.ML
\\
  We present the preliminary high-level design and features of DynamicPPL.jl, a
modular library providing a lightning-fast infrastructure for probabilistic
programming. Besides a computational performance that is often close to or
better than Stan, DynamicPPL provides an intuitive DSL that allows the rapid
development of complex dynamic probabilistic programs. Being entirely written
in Julia, a high-level dynamic programming language for numerical computing,
DynamicPPL inherits a rich set of features available through the Julia
ecosystem. Since DynamicPPL is a modular, stand-alone library, any
probabilistic programming system written in Julia, such as Turing.jl, can use
DynamicPPL to specify models and trace their model parameters. The main
features of DynamicPPL are: 1) a meta-programming based DSL for specifying
dynamic models using an intuitive tilde-based notation; 2) a tracing
data-structure for tracking RVs in dynamic probabilistic models; 3) a rich
contextual dispatch system allowing tailored behaviour during model execution;
and 4) a user-friendly syntax for probabilistic queries. Finally, we show in a
variety of experiments that DynamicPPL, in combination with Turing.jl, achieves
computational performance that is often close to or better than Stan.
\\ ( https://arxiv.org/abs/2002.02702 ,  95kb)
------------------------------------------------------------------------------
\\
arXiv:2002.02705
Date: Fri, 7 Feb 2020 10:42:26 GMT   (2023kb,D)

Title: Trust Your Model: Iterative Label Improvement and Robust Training by
  Confidence Based Filtering and Dataset Partitioning
Authors: Christian Haase-Sch\"utz, Rainer Stal, Heinz Hertlein and Bernhard
  Sick
Categories: cs.LG cs.CV stat.ML
\\
  State-of-the-art, high capacity deep neural networks not only require large
amounts of labelled training data, they are also highly susceptible to label
errors in this data, typically resulting in large efforts and costs and
therefore limiting the applicability of deep learning. To alleviate this issue,
we propose a novel meta training and labelling scheme that is able to use
inexpensive unlabelled data by taking advantage of the generalization power of
deep neural networks. We show experimentally that by solely relying on one
network architecture and our proposed scheme of iterative training and
prediction steps, both label quality and resulting model accuracy can be
improved significantly. Our method achieves state-of-the-art results, while
being architecture agnostic and therefore broadly applicable. Compared to other
methods dealing with erroneous labels, our approach does neither require
another network to be trained, nor does it necessarily need an additional,
highly accurate reference label set. Instead of removing samples from a
labelled set, our technique uses additional sensor data without the need for
manual labelling.
\\ ( https://arxiv.org/abs/2002.02705 ,  2023kb)
------------------------------------------------------------------------------
\\
arXiv:2002.02717
Date: Fri, 7 Feb 2020 11:24:50 GMT   (1468kb,D)

Title: Unsupervised non-parametric change point detection in quasi-periodic
  signals
Authors: Nikolay Shvetsov and Nazar Buzun and Dmitry V. Dylov
Categories: cs.LG math.ST stat.ML stat.TH
Comments: 8 pages, 7 figures, 1 table
\\
  We propose a new unsupervised and non-parametric method to detect change
points in intricate quasi-periodic signals. The detection relies on optimal
transport theory combined with topological analysis and the bootstrap
procedure. The algorithm is designed to detect changes in virtually any
harmonic or a partially harmonic signal and is verified on three different
sources of physiological data streams. We successfully find abnormal or
irregular cardiac cycles in the waveforms for the six of the most frequent
types of clinical arrhythmias using a single algorithm. The validation and the
efficiency of the method are shown both on synthetic and on real time series.
Our unsupervised approach reaches the level of performance of the supervised
state-of-the-art techniques. We provide conceptual justification for the
efficiency of the method and prove the convergence of the bootstrap procedure
theoretically.
\\ ( https://arxiv.org/abs/2002.02717 ,  1468kb)
------------------------------------------------------------------------------
\\
arXiv:2002.02730
Date: Fri, 7 Feb 2020 12:16:06 GMT   (252kb,D)

Title: Machine Unlearning: Linear Filtration for Logit-based Classifiers
Authors: Thomas Baumhauer and Pascal Sch\"ottle and Matthias Zeppelzauer
Categories: cs.LG stat.ML
\\
  Recently enacted legislation grants individuals certain rights to decide in
what fashion their personal data may be used, and in particular a "right to be
forgotten". This poses a challenge to machine learning: how to proceed when an
individual retracts permission to use data which has been part of the training
process of a model? From this question emerges the field of machine unlearning,
which could be broadly described as the investigation of how to "delete
training data from models". Our work complements this direction of research for
the specific setting of class-wide deletion requests for classification models
(e.g. deep neural networks). As a first step, we propose linear filtration as a
computationally efficient sanitization method. Our experiments demonstrate
benefits in an adversarial setting over naive deletion schemes.
\\ ( https://arxiv.org/abs/2002.02730 ,  252kb)
------------------------------------------------------------------------------
\\
arXiv:2002.02741
Date: Fri, 7 Feb 2020 12:41:28 GMT   (679kb,D)

Title: Can't Boil This Frog: Robustness of Online-Trained Autoencoder-Based
  Anomaly Detectors to Adversarial Poisoning Attacks
Authors: Moshe Kravchik, Asaf Shabtai
Categories: cs.LG cs.CR stat.ML
\\
  In recent years, a variety of effective neural network-based methods for
anomaly and cyber attack detection in industrial control systems (ICSs) have
been demonstrated in the literature. Given their successful implementation and
widespread use, there is a need to study adversarial attacks on such detection
methods to better protect the systems that depend upon them. The extensive
research performed on adversarial attacks on image and malware classification
has little relevance to the physical system state prediction domain, which most
of the ICS attack detection systems belong to. Moreover, such detection systems
are typically retrained using new data collected from the monitored system,
thus the threat of adversarial data poisoning is significant, however this
threat has not yet been addressed by the research community. In this paper, we
present the first study focused on poisoning attacks on online-trained
autoencoder-based attack detectors. We propose two algorithms for generating
poison samples, an interpolation-based algorithm and a back-gradient
optimization-based algorithm, which we evaluate on both synthetic and
real-world ICS data. We demonstrate that the proposed algorithms can generate
poison samples that cause the target attack to go undetected by the autoencoder
detector, however the ability to poison the detector is limited to a small set
of attack types and magnitudes. When the poison-generating algorithms are
applied to the popular SWaT dataset, we show that the autoencoder detector
trained on the physical system state data is resilient to poisoning in the face
of all ten of the relevant attacks in the dataset. This finding suggests that
neural network-based attack detectors used in the cyber-physical domain are
more robust to poisoning than in other problem domains, such as malware
detection and image processing.
\\ ( https://arxiv.org/abs/2002.02741 ,  679kb)
------------------------------------------------------------------------------
\\
arXiv:2002.02753
Date: Fri, 7 Feb 2020 13:07:34 GMT   (198kb)

Title: Translating Diffusion, Wavelets, and Regularisation into Residual
  Networks
Authors: Tobias Alt, Joachim Weickert, Pascal Peter
Categories: cs.LG cs.NA math.NA stat.ML
\\
  Convolutional neural networks (CNNs) often perform well, but their stability
is poorly understood. To address this problem, we consider the simple
prototypical problem of signal denoising, where classical approaches such as
nonlinear diffusion, wavelet-based methods and regularisation offer provable
stability guarantees. To transfer such guarantees to CNNs, we interpret
numerical approximations of these classical methods as a specific residual
network (ResNet) architecture. This leads to a dictionary which allows to
translate diffusivities, shrinkage functions, and regularisers into activation
functions, and enables a direct communication between the four research
communities. On the CNN side, it does not only inspire new families of
nonmonotone activation functions, but also introduces intrinsically stable
architectures for an arbitrary number of layers.
\\ ( https://arxiv.org/abs/2002.02753 ,  198kb)
------------------------------------------------------------------------------
\\
arXiv:2002.02775
Date: Thu, 6 Feb 2020 16:57:05 GMT   (1319kb)

Title: Context Aware Image Annotation in Active Learning
Authors: Yingcheng Sun and Kenneth Loparo
Categories: cs.LG cs.IR
Comments: arXiv admin note: text overlap with arXiv:1508.07647, arXiv:1207.3809
  by other authors
Journal-ref: 2019 19th Industrial Conference on Data Mining
\\
  Image annotation for active learning is labor-intensive. Various automatic
and semi-automatic labeling methods are proposed to save the labeling cost, but
a reduction in the number of labeled instances does not guarantee a reduction
in cost because the queries that are most valuable to the learner may be the
most difficult or ambiguous cases, and therefore the most expensive for an
oracle to label accurately. In this paper, we try to solve this problem by
using image metadata to offer the oracle more clues about the image during
annotation process. We propose a Context Aware Image Annotation Framework
(CAIAF) that uses image metadata as similarity metric to cluster images into
groups for annotation. We also present useful metadata information as context
for each image on the annotation interface. Experiments show that it reduces
that annotation cost with CAIAF compared to the conventional framework, while
maintaining a high classification performance.
\\ ( https://arxiv.org/abs/2002.02775 ,  1319kb)
------------------------------------------------------------------------------
\\
arXiv:2002.02776
Date: Fri, 7 Feb 2020 13:27:29 GMT   (226kb,D)

Title: RAID: Randomized Adversarial-Input Detection for Neural Networks
Authors: Hasan Ferit Eniser, Maria Christakis, Valentin W\"ustholz
Categories: cs.LG cs.CR
Comments: 10 pages of content plus 2 pages of bibliography. Submitted to ISSTA
\\
  In recent years, neural networks have become the default choice for image
classification and many other learning tasks, even though they are vulnerable
to so-called adversarial attacks. To increase their robustness against these
attacks, there have emerged numerous detection mechanisms that aim to
automatically determine if an input is adversarial. However, state-of-the-art
detection mechanisms either rely on being tuned for each type of attack, or
they do not generalize across different attack types. To alleviate these
issues, we propose a novel technique for adversarial-image detection, RAID,
that trains a secondary classifier to identify differences in neuron activation
values between benign and adversarial inputs. Our technique is both more
reliable and more effective than the state of the art when evaluated against
six popular attacks. Moreover, a straightforward extension of RAID increases
its robustness against detection-aware adversaries without affecting its
effectiveness.
\\ ( https://arxiv.org/abs/2002.02776 ,  226kb)
------------------------------------------------------------------------------
\\
arXiv:2002.02778
Date: Fri, 7 Feb 2020 13:34:22 GMT   (4765kb,D)

Title: Efficient Topological Layer based on Persistent Landscapes
Authors: Kwangho Kim, Jisu Kim, Joon Sik Kim, Frederic Chazal, and Larry
  Wasserman
Categories: cs.LG cs.CG stat.ML
\\
  We propose a novel topological layer for general deep learning models based
on persistent landscapes, in which we can efficiently exploit underlying
topological features of the input data structure. We use the robust DTM
function and show differentiability with respect to layer inputs, for a general
persistent homology with arbitrary filtration. Thus, our proposed layer can be
placed anywhere in the network architecture and feed critical information on
the topological features of input data into subsequent layers to improve the
learnability of the networks toward a given task. A task-optimal structure of
the topological layer is learned during training via backpropagation, without
requiring any input featurization or data preprocessing. We provide a tight
stability theorem, and show that the proposed layer is robust towards noise and
outliers. We demonstrate the effectiveness of our approach by classification
experiments on various datasets.
\\ ( https://arxiv.org/abs/2002.02778 ,  4765kb)
------------------------------------------------------------------------------
\\
arXiv:2002.02782
Date: Fri, 7 Feb 2020 13:48:52 GMT   (508kb,D)

Title: Inverse Learning of Symmetry Transformations
Authors: Mario Wieser, Sonali Parbhoo, Aleksander Wieczorek, Volker Roth
Categories: cs.LG stat.ML
\\
  Symmetry transformations induce invariances and are a crucial building block
of modern machine learning algorithms. Some transformations can be described
analytically, e.g. geometric invariances. However, in many complex domains,
such as the chemical space, invariances can be observed yet the corresponding
symmetry transformation cannot be formulated analytically. Thus, the goal of
our work is to learn the symmetry transformation that induced this invariance.
To address this task, we propose learning two latent subspaces, where the first
subspace captures the property and the second subspace the remaining invariant
information. Our approach is based on the deep information bottleneck principle
in combination with a mutual information regulariser. Unlike previous methods
however, we focus on estimating mutual information in continuous rather than
binary settings. This poses many challenges as mutual information cannot be
meaningfully minimised in continuous domains. Therefore, we base the
calculation of mutual information on correlation matrices in combination with a
bijective variable transformation. Extensive experiments demonstrate that our
model outperforms state-of-the-art methods on artificial and molecular
datasets.
\\ ( https://arxiv.org/abs/2002.02782 ,  508kb)
------------------------------------------------------------------------------
\\
arXiv:2002.02794
Date: Fri, 7 Feb 2020 14:03:38 GMT   (51kb)

Title: Reward-Free Exploration for Reinforcement Learning
Authors: Chi Jin, Akshay Krishnamurthy, Max Simchowitz, Tiancheng Yu
Categories: cs.LG stat.ML
\\
  Exploration is widely regarded as one of the most challenging aspects of
reinforcement learning (RL), with many naive approaches succumbing to
exponential sample complexity. To isolate the challenges of exploration, we
propose a new "reward-free RL" framework. In the exploration phase, the agent
first collects trajectories from an MDP $\mathcal{M}$ without a pre-specified
reward function. After exploration, it is tasked with computing near-optimal
policies under for $\mathcal{M}$ for a collection of given reward functions.
This framework is particularly suitable when there are many reward functions of
interest, or when the reward function is shaped by an external agent to elicit
desired behavior.
  We give an efficient algorithm that conducts
$\tilde{\mathcal{O}}(S^2A\mathrm{poly}(H)/\epsilon^2)$ episodes of exploration
and returns $\epsilon$-suboptimal policies for an arbitrary number of reward
functions. We achieve this by finding exploratory policies that visit each
"significant" state with probability proportional to its maximum visitation
probability under any possible policy. Moreover, our planning procedure can be
instantiated by any black-box approximate planner, such as value iteration or
natural policy gradient. We also give a nearly-matching
$\Omega(S^2AH^2/\epsilon^2)$ lower bound, demonstrating the near-optimality of
our algorithm in this setting.
\\ ( https://arxiv.org/abs/2002.02794 ,  51kb)
------------------------------------------------------------------------------
\\
arXiv:2002.02826
Date: Fri, 7 Feb 2020 14:56:11 GMT   (602kb,D)

Title: Multi-source Deep Gaussian Process Kernel Learning
Authors: Chi-Ken Lu, Patrick Shafto
Categories: cs.LG stat.ML
Comments: 13 pages in current format
\\
  For many problems, relevant data are plentiful but explicit knowledge is not.
Predictions about target variables may be informed by data sources that are
noisy but plentiful, or data which the target variable is merely some function
of. Intrepretable and flexible machine learning methods capable of fusing data
across sources are lacking. We generalize the Deep Gaussian Processes so that
GPs in intermediate layers can represent the posterior distribution summarizing
the data from a related source. We model the prior-posterior stacking DGP with
a single GP. The exact second moment of DGP is calculated analytically, and is
taken as the kernel function for GP. The result is a kernel that captures
effective correlation through function composition, reflects the structure of
the observations from other data sources, and can be used to inform prediction
based on limited direct observations. Therefore, the approximation of
prior-posterior DGP can be considered a novel kernel composition which blends
the kernels in different layers and have explicit dependence on the data. We
consider two synthetic multi-source prediction problems: a) predicting a target
variable that is merely a function of the source data and b) predicting
noise-free data using a kernel trained on noisy data. Our method produces
better prediction and tighter uncertainty on the synthetic data when comparing
with standard GP and other DGP method, suggesting that our data-informed
approximate DGPs are a powerful tool for integrating data across sources.
\\ ( https://arxiv.org/abs/2002.02826 ,  602kb)
------------------------------------------------------------------------------
\\
arXiv:2002.02829
Date: Fri, 7 Feb 2020 15:01:20 GMT   (2605kb,D)

Title: Off-policy Maximum Entropy Reinforcement Learning : Soft Actor-Critic
  with Advantage Weighted Mixture Policy(SAC-AWMP)
Authors: Zhimin Hou and Kuangen Zhang and Yi Wan and Dongyu Li and Chenglong Fu
  and Haoyong Yu
Categories: cs.LG cs.AI stat.ML
\\
  The optimal policy of a reinforcement learning problem is often discontinuous
and non-smooth. I.e., for two states with similar representations, their
optimal policies can be significantly different. In this case, representing the
entire policy with a function approximator (FA) with shared parameters for all
states maybe not desirable, as the generalization ability of parameters sharing
makes representing discontinuous, non-smooth policies difficult. A common way
to solve this problem, known as Mixture-of-Experts, is to represent the policy
as the weighted sum of multiple components, where different components perform
well on different parts of the state space. Following this idea and inspired by
a recent work called advantage-weighted information maximization, we propose to
learn for each state weights of these components, so that they entail the
information of the state itself and also the preferred action learned so far
for the state. The action preference is characterized via the advantage
function. In this case, the weight of each component would only be large for
certain groups of states whose representations are similar and preferred action
representations are also similar. Therefore each component is easy to be
represented. We call a policy parameterized in this way an Advantage Weighted
Mixture Policy (AWMP) and apply this idea to improve soft-actor-critic (SAC),
one of the most competitive continuous control algorithm. Experimental results
demonstrate that SAC with AWMP clearly outperforms SAC in four commonly used
continuous control tasks and achieve stable performance across different random
seeds.
\\ ( https://arxiv.org/abs/2002.02829 ,  2605kb)
------------------------------------------------------------------------------
\\
arXiv:2002.02835
Date: Fri, 7 Feb 2020 15:18:04 GMT   (308kb)

Title: On the Effectiveness of Richardson Extrapolation in Machine Learning
Authors: Francis Bach (LIENS, SIERRA)
Categories: cs.LG cs.NA math.NA math.OC
\\
  Richardson extrapolation is a classical technique from numerical analysis
that can improve the approximation error of an estimation method by combining
linearly several estimates obtained from different values of one of its
hyperparameters, without the need to know in details the inner structure of the
original estimation method. The main goal of this paper is to study when
Richardson extrapolation can be used within machine learning, beyond the
existing applications to step-size adaptations in stochastic gradient descent.
We identify two situations where Richardson interpolation can be useful: (1)
when the hyperparameter is the number of iterations of an existing iterative
optimization algorithm, with applications to averaged gradient descent and
Frank-Wolfe algorithms (where we obtain asymptotically rates of $O(1/k^2)$ on
polytopes, where $k$ is the number of iterations), and (2) when it is a
regularization parameter, with applications to Nesterov smoothing techniques
for minimizing non-smooth functions (where we obtain asymptotically rates close
to $O(1/k^2)$ for non-smooth functions), and ridge regression. In all these
cases, we show that extrapolation techniques come with no significant loss in
performance, but with sometimes strong gains, and we provide theoretical
justifications based on asymptotic developments for such gains, as well as
empirical illustrations on classical problems from machine learning.
\\ ( https://arxiv.org/abs/2002.02835 ,  308kb)
------------------------------------------------------------------------------
\\
arXiv:2002.02836
Date: Fri, 7 Feb 2020 15:18:15 GMT   (9258kb,D)

Title: Causally Correct Partial Models for Reinforcement Learning
Authors: Danilo J. Rezende, Ivo Danihelka, George Papamakarios, Nan Rosemary
  Ke, Ray Jiang, Theophane Weber, Karol Gregor, Hamza Merzic, Fabio Viola, Jane
  Wang, Jovana Mitrovic, Frederic Besse, Ioannis Antonoglou, Lars Buesing
Categories: cs.LG cs.AI stat.ML
\\
  In reinforcement learning, we can learn a model of future observations and
rewards, and use it to plan the agent's next actions. However, jointly modeling
future observations can be computationally expensive or even intractable if the
observations are high-dimensional (e.g. images). For this reason, previous
works have considered partial models, which model only part of the observation.
In this paper, we show that partial models can be causally incorrect: they are
confounded by the observations they don't model, and can therefore lead to
incorrect planning. To address this, we introduce a general family of partial
models that are provably causally correct, yet remain fast because they do not
need to fully model future observations.
\\ ( https://arxiv.org/abs/2002.02836 ,  9258kb)
------------------------------------------------------------------------------
\\
arXiv:2002.02842
Date: Fri, 7 Feb 2020 15:29:22 GMT   (56kb,D)

Title: Assessing the Adversarial Robustness of Monte Carlo and Distillation
  Methods for Deep Bayesian Neural Network Classification
Authors: Meet P. Vadera, Satya Narayan Shukla, Brian Jalaian and Benjamin M.
  Marlin
Categories: cs.LG stat.ML
Comments: Presented at SafeAI Workshop, AAAI 2020
\\
  In this paper, we consider the problem of assessing the adversarial
robustness of deep neural network models under both Markov chain Monte Carlo
(MCMC) and Bayesian Dark Knowledge (BDK) inference approximations. We
characterize the robustness of each method to two types of adversarial attacks:
the fast gradient sign method (FGSM) and projected gradient descent (PGD). We
show that full MCMC-based inference has excellent robustness, significantly
outperforming standard point estimation-based learning. On the other hand, BDK
provides marginal improvements. As an additional contribution, we present a
storage-efficient approach to computing adversarial examples for large Monte
Carlo ensembles using both the FGSM and PGD attacks.
\\ ( https://arxiv.org/abs/2002.02842 ,  56kb)
------------------------------------------------------------------------------
\\
arXiv:2002.02844
Date: Fri, 7 Feb 2020 15:30:22 GMT   (1365kb,D)

Title: Stable Sparse Subspace Embedding for Dimensionality Reduction
Authors: Li Chen, Shuizheng Zhou, Jiajun Ma
Categories: cs.LG stat.ML
\\
  Sparse random projection (RP) is a popular tool for dimensionality reduction
that shows promising performance with low computational complexity. However, in
the existing sparse RP matrices, the positions of non-zero entries are usually
randomly selected. Although they adopt uniform sampling with replacement, due
to large sampling variance, the number of non-zeros is uneven among rows of the
projection matrix which is generated in one trial, and more data information
may be lost after dimension reduction. To break this bottleneck, based on
random sampling without replacement in statistics, this paper builds a stable
sparse subspace embedded matrix (S-SSE), in which non-zeros are uniformly
distributed. It is proved that the S-SSE is stabler than the existing matrix,
and it can maintain Euclidean distance between points well after dimension
reduction. Our empirical studies corroborate our theoretical findings and
demonstrate that our approach can indeed achieve satisfactory performance.
\\ ( https://arxiv.org/abs/2002.02844 ,  1365kb)
------------------------------------------------------------------------------
\\
arXiv:2002.02846
Date: Fri, 7 Feb 2020 15:32:14 GMT   (922kb,D)

Title: Fast Kernel k-means Clustering Using Incomplete Cholesky Factorization
Authors: Li Chen, Shuisheng Zhou, Jiajun Ma
Categories: cs.LG stat.ML
\\
  Kernel-based clustering algorithm can identify and capture the non-linear
structure in datasets, and thereby it can achieve better performance than
linear clustering. However, computing and storing the entire kernel matrix
occupy so large memory that it is difficult for kernel-based clustering to deal
with large-scale datasets. In this paper, we employ incomplete Cholesky
factorization to accelerate kernel clustering and save memory space. The key
idea of the proposed kernel $k$-means clustering using incomplete Cholesky
factorization is that we approximate the entire kernel matrix by the product of
a low-rank matrix and its transposition. Then linear $k$-means clustering is
applied to columns of the transpose of the low-rank matrix. We show both
analytically and empirically that the performance of the proposed algorithm is
similar to that of the kernel $k$-means clustering algorithm, but our method
can deal with large-scale datasets.
\\ ( https://arxiv.org/abs/2002.02846 ,  922kb)
------------------------------------------------------------------------------
\\
arXiv:2002.02862
Date: Fri, 7 Feb 2020 15:55:48 GMT   (1965kb,D)

Title: Learning Implicit Generative Models with Theoretical Guarantees
Authors: Yuan Gao and Jian Huang and Yuling Jiao and Jin Liu
Categories: cs.LG stat.ML
\\
  We propose a \textbf{uni}fied \textbf{f}ramework for \textbf{i}mplicit
\textbf{ge}nerative \textbf{m}odeling (UnifiGem) with theoretical guarantees by
integrating approaches from optimal transport, numerical ODE, density-ratio
(density-difference) estimation and deep neural networks. First, the problem of
implicit generative learning is formulated as that of finding the optimal
transport map between the reference distribution and the target distribution,
which is characterized by a totally nonlinear Monge-Amp\`{e}re equation.
Interpreting the infinitesimal linearization of the Monge-Amp\`{e}re equation
from the perspective of gradient flows in measure spaces leads to the
continuity equation or the McKean-Vlasov equation. We then solve the
McKean-Vlasov equation numerically using the forward Euler iteration, where the
forward Euler map depends on the density ratio (density difference) between the
distribution at current iteration and the underlying target distribution. We
further estimate the density ratio (density difference) via deep density-ratio
(density-difference) fitting and derive explicit upper bounds on the estimation
error. Experimental results on both synthetic datasets and real benchmark
datasets support our theoretical findings and demonstrate the effectiveness of
UnifiGem.
\\ ( https://arxiv.org/abs/2002.02862 ,  1965kb)
------------------------------------------------------------------------------
\\
arXiv:2002.02863
Date: Fri, 7 Feb 2020 15:57:57 GMT   (9100kb,D)

Title: Provably efficient reconstruction of policy networks
Authors: Bogdan Mazoure, Thang Doan, Tianyu Li, Vladimir Makarenkov, Joelle
  Pineau, Doina Precup, Guillaume Rabusseau
Categories: cs.LG stat.ML
\\
  Recent research has shown that learning poli-cies parametrized by large
neural networks can achieve significant success on challenging reinforcement
learning problems. However, when memory is limited, it is not always possible
to store such models exactly for inference, and com-pressing the policy into a
compact representation might be necessary. We propose a general framework for
policy representation, which reduces this problem to finding a low-dimensional
embedding of a given density function in a separable inner product space. Our
framework allows us to de-rive strong theoretical guarantees, controlling the
error of the reconstructed policies. Such guaran-tees are typically lacking in
black-box models, but are very desirable in risk-sensitive tasks. Our
experimental results suggest that the reconstructed policies can use less than
10%of the number of parameters in the original networks, while incurring almost
no decrease in rewards.
\\ ( https://arxiv.org/abs/2002.02863 ,  9100kb)
------------------------------------------------------------------------------
\\
arXiv:2002.02868
Date: Fri, 7 Feb 2020 16:02:44 GMT   (757kb)

Title: Differentiable Fixed-Point Iteration Layer
Authors: Younahan Jeon, Minsik Lee, Jin Young Choi
Categories: cs.LG math.OC stat.ML
\\
  Recently, several studies proposed methods to utilize some restricted classes
of optimization problems as layers of deep neural networks. However, these
methods are still in their infancy and require special treatments, i.e.,
analyzing the KKT condition, etc., for deriving the backpropagation formula.
Instead, in this paper, we propose a method to utilize fixed-point iteration
(FPI), a generalization of many types of numerical algorithms, as a network
layer. We show that the derivative of an FPI layer depends only on the fixed
point, and then we present a method to calculate it efficiently using another
FPI which we call the backward FPI. The proposed method can be easily
implemented based on the autograd functionalities in existing deep learning
tools. Since FPI covers vast different types of numerical algorithms in machine
learning and other fields, it has a lot of potential applications. In the
experiments, the differentiable FPI layer is applied to two scenarios, i.e.,
gradient descent iterations for differentiable optimization problems and FPI
with arbitrary neural network modules, of which the results demonstrate the
simplicity and the effectiveness.
\\ ( https://arxiv.org/abs/2002.02868 ,  757kb)
------------------------------------------------------------------------------
\\
arXiv:2002.02879
Date: Fri, 7 Feb 2020 16:23:17 GMT   (1200kb,D)

Title: Targeted display advertising: the case of preferential attachment
Authors: Saurav Manchanda and Pranjul Yadav and Khoa Doan and S. Sathiya
  Keerthi
Categories: cs.LG cs.IR cs.SI stat.ML
Comments: IEEE BigData 2019 paper
\\
  An average adult is exposed to hundreds of digital advertisements daily
(https://www.mediadynamicsinc.com/uploads/files/PR092214-Note-only-150-Ads-2mk.pdf),
making the digital advertisement industry a classic example of a
big-data-driven platform. As such, the ad-tech industry relies on historical
engagement logs (clicks or purchases) to identify potentially interested users
for the advertisement campaign of a partner (a seller who wants to target users
for its products). The number of advertisements that are shown for a partner,
and hence the historical campaign data available for a partner depends upon the
budget constraints of the partner. Thus, enough data can be collected for the
high-budget partners to make accurate predictions, while this is not the case
with the low-budget partners. This skewed distribution of the data leads to
"preferential attachment" of the targeted display advertising platforms towards
the high-budget partners. In this paper, we develop "domain-adaptation"
approaches to address the challenge of predicting interested users for the
partners with insufficient data, i.e., the tail partners. Specifically, we
develop simple yet effective approaches that leverage the similarity among the
partners to transfer information from the partners with sufficient data to
cold-start partners, i.e., partners without any campaign data. Our approaches
readily adapt to the new campaign data by incremental fine-tuning, and hence
work at varying points of a campaign, and not just the cold-start. We present
an experimental analysis on the historical logs of a major display advertising
platform (https://www.criteo.com/). Specifically, we evaluate our approaches
across 149 partners, at varying points of their campaigns. Experimental results
show that the proposed approaches outperform the other "domain-adaptation"
approaches at different time points of the campaigns.
\\ ( https://arxiv.org/abs/2002.02879 ,  1200kb)
------------------------------------------------------------------------------
\\
arXiv:2002.02883
Date: Fri, 7 Feb 2020 16:34:14 GMT   (7097kb,D)

Title: A learning without forgetting approach to incorporate artifact knowledge
  in polyp localization tasks
Authors: Roger D. Soberanis-Mukul, Maxime Kayser, Anna-Maria Zvereva (M.D.),
  Peter Klare (M.D.), Nassir Navab, Shadi Albarqouni
Categories: cs.LG eess.IV stat.ML
\\
  Colorectal polyps are abnormalities in the colon tissue that can develop into
colorectal cancer. The survival rate for patients is higher when the disease is
detected at an early stage and polyps can be removed before they develop into
malignant tumors. Deep learning methods have become the state of art in
automatic polyp detection. However, the performance of current models heavily
relies on the size and quality of the training datasets. Endoscopic video
sequences tend to be corrupted by different artifacts affecting visibility and
hence, the detection rates. In this work, we analyze the effects that artifacts
have in the polyp localization problem. For this, we evaluate the RetinaNet
architecture, originally defined for object localization. We also define a
model inspired by the learning without forgetting framework, which allows us to
employ artifact detection knowledge in the polyp localization problem. Finally,
we perform several experiments to analyze the influence of the artifacts in the
performance of these models. To our best knowledge, this is the first extensive
analysis of the influence of artifact in polyp localization and the first work
incorporating learning without forgetting ideas for simultaneous artifact and
polyp localization tasks.
\\ ( https://arxiv.org/abs/2002.02883 ,  7097kb)
------------------------------------------------------------------------------
\\
arXiv:2002.02884
Date: Fri, 7 Feb 2020 16:35:50 GMT   (27kb)

Title: Grammar Filtering For Syntax-Guided Synthesis
Authors: Kairo Morton, William Hallahan, Elven Shum, Ruzica Piskac, Mark
  Santolucito
Categories: cs.LG cs.PL stat.ML
\\
  Programming-by-example (PBE) is a synthesis paradigm that allows users to
generate functions by simply providing input-output examples. While a promising
interaction paradigm, synthesis is still too slow for realtime interaction and
more widespread adoption. Existing approaches to PBE synthesis have used
automated reasoning tools, such as SMT solvers, as well as works applying
machine learning techniques. At its core, the automated reasoning approach
relies on highly domain specific knowledge of programming languages. On the
other hand, the machine learning approaches utilize the fact that when working
with program code, it is possible to generate arbitrarily large training
datasets. In this work, we propose a system for using machine learning in
tandem with automated reasoning techniques to solve Syntax Guided Synthesis
(SyGuS) style PBE problems. By preprocessing SyGuS PBE problems with a neural
network, we can use a data driven approach to reduce the size of the search
space, then allow automated reasoning-based solvers to more quickly find a
solution analytically. Our system is able to run atop existing SyGuS PBE
synthesis tools, decreasing the runtime of the winner of the 2019 SyGuS
Competition for the PBE Strings track by 47.65% to outperform all of the
competing tools.
\\ ( https://arxiv.org/abs/2002.02884 ,  27kb)
------------------------------------------------------------------------------
\\
arXiv:2002.02885
Date: Fri, 7 Feb 2020 16:36:06 GMT   (1022kb,D)

Title: Understanding and Optimizing Packed Neural Network Training for
  Hyper-Parameter Tuning
Authors: Rui Liu, Sanjan Krishnan, Aaron J. Elmore, Michael J. Franklin
Categories: cs.LG stat.ML
\\
  As neural networks are increasingly employed in machine learning practice,
organizations will have to determine how to share limited training resources
among a diverse set of model training tasks. This paper studies jointly
training multiple neural network models on a single GPU. We presents an
empirical study of this operation, called pack, and end-to-end experiments that
suggest significant improvements for hyperparameter search systems. Our
research prototype is in TensorFlow, and we evaluate performance across
different models (ResNet, MobileNet, DenseNet, and MLP) and training scenarios.
The results suggest: (1) packing two models can bring up to 40% performance
improvement over unpacked setups for a single training step and the improvement
increases when packing more models; (2) the benefit of a pack primitive largely
depends on a number of factors including memory capacity, chip architecture,
neural network structure, and batch size; (3) there exists a trade-off between
packing and unpacking when training multiple neural network models on limited
resources; (4) a pack-based Hyperband is up to 2.7x faster than the original
Hyperband training method in our experiment setting, with this improvement
growing as memory size increases and subsequently the density of models packed.
\\ ( https://arxiv.org/abs/2002.02885 ,  1022kb)
------------------------------------------------------------------------------
\\
arXiv:2002.02886
Date: Fri, 7 Feb 2020 16:39:31 GMT   (2637kb,D)

Title: Weakly-Supervised Disentanglement Without Compromises
Authors: Francesco Locatello, Ben Poole, Gunnar R\"atsch, Bernhard Sch\"olkopf,
  Olivier Bachem, Michael Tschannen
Categories: cs.LG stat.ML
\\
  Intelligent agents should be able to learn useful representations by
observing changes in their environment. We model such observations as pairs of
non-i.i.d. images sharing at least one of the underlying factors of variation.
First, we theoretically show that only knowing how many factors have changed,
but not which ones, is sufficient to learn disentangled representations.
Second, we provide practical algorithms that learn disentangled representations
from pairs of images without requiring annotation of groups, individual
factors, or the number of factors that have changed. Third, we perform a
large-scale empirical study and show that such pairs of observations are
sufficient to reliably learn disentangled representations on several benchmark
data sets. Finally, we evaluate our learned representations and find that they
are simultaneously useful on a diverse suite of tasks, including generalization
under covariate shifts, fairness, and abstract reasoning. Overall, our results
demonstrate that weak supervision enables learning of useful disentangled
representations in realistic scenarios.
\\ ( https://arxiv.org/abs/2002.02886 ,  2637kb)
------------------------------------------------------------------------------
\\
arXiv:2002.02887
Date: Fri, 7 Feb 2020 16:39:43 GMT   (500kb,D)

Title: Meta-learning framework with applications to zero-shot time-series
  forecasting
Authors: Boris N. Oreshkin, Dmitri Carpov, Nicolas Chapados, Yoshua Bengio
Categories: cs.LG stat.ML
\\
  Can meta-learning discover generic ways of processing time-series (TS) from a
diverse dataset so as to greatly improve generalization on new TS coming from
different datasets? This work provides positive evidence to demonstrate this
using a broad meta-learning framework which we show subsumes many existing
meta-learning algorithms as specific cases. We further identify via theoretical
analysis the meta-learning adaptation mechanisms within N-BEATS, a recent
neural TS forecasting model. Our meta-learning theory predicts that N-BEATS
iteratively generates a subset of its task-specific parameters based on a given
TS input, thus gradually expanding the expressive power of the architecture
on-the-fly. Our empirical results emphasize the importance of meta-learning for
successful zero-shot forecasting to new sources of TS, supporting the claim
that it is viable to train a neural network on a source TS dataset and deploy
it on a different target TS dataset without retraining, resulting in
performance that is at least as good as that of state-of-practice univariate
forecasting models.
\\ ( https://arxiv.org/abs/2002.02887 ,  500kb)
------------------------------------------------------------------------------
\\
arXiv:2002.02897
Date: Fri, 7 Feb 2020 16:55:21 GMT   (4234kb,D)

Title: MDLdroid: a ChainSGD-reduce Approach to Mobile Deep Learning for
  Personal Mobile Sensing
Authors: Yu Zhang, Tao Gu, Xi Zhang
Categories: cs.LG cs.NI stat.ML
Comments: Published in the International Conference on Information Processing
  in Sensor Networks (IPSN), 2020
\\
  Personal mobile sensing is fast permeating our daily lives to enable activity
monitoring, healthcare and rehabilitation. Combined with deep learning, these
applications have achieved significant success in recent years. Different from
conventional cloud-based paradigms, running deep learning on devices offers
several advantages including data privacy preservation and low-latency response
for both model inference and update. Since data collection is costly in
reality, Google's Federated Learning offers not only complete data privacy but
also better model robustness based on multiple user data. However, personal
mobile sensing applications are mostly user-specific and highly affected by
environment. As a result, continuous local changes may seriously affect the
performance of a pre-trained global model generated by Federated Learning. In
addition, deploying Federated Learning on a local server, e.g., edge server,
may quickly reach the bottleneck due to resource constraint and serious failure
by attacks. Towards pushing deep learning on devices, we present MDLdroid, a
novel decentralized mobile deep learning framework to enable resource-aware
on-device collaborative learning for personal mobile sensing applications. To
address resource limitation, we propose a ChainSGD-reduce approach which
includes a novel chain-directed Synchronous Stochastic Gradient Descent
algorithm to effectively reduce overhead among multiple devices. We also design
an agent-based multi-goal reinforcement learning mechanism to balance resources
in a fair and efficient manner. Our evaluations show that our model training on
off-the-shelf mobile devices achieves 2x to 3.5x faster than single-device
training, and 1.5x faster than the master-slave approach.
\\ ( https://arxiv.org/abs/2002.02897 ,  4234kb)
------------------------------------------------------------------------------
\\
arXiv:2002.02912
Date: Fri, 7 Feb 2020 17:25:59 GMT   (256kb)

Title: Universal Equivariant Multilayer Perceptrons
Authors: Siamak Ravanbakhsh
Categories: cs.LG cs.NE math.GR stat.ML
\\
  Group invariant and equivariant Multilayer Perceptrons (MLP), also known as
Equivariant Networks, have achieved remarkable success in learning on a variety
of data structures, such as sequences, images, sets, and graphs. Using tools
from group theory, this paper proves the universality of a broad class of
equivariant MLPs with a single hidden layer. In particular, it is shown that
having a hidden layer on which the group acts regularly is sufficient for
universal equivariance. Next, Burnside's table of marks is used to decompose
product spaces. It is shown that the product of two G-sets always contains an
orbit larger than the input orbits. Therefore high order hidden layers
inevitably contain a regular orbit, leading to the universality of the
corresponding MLP. It is shown that with an order larger than the logarithm of
the size of the stabilizer group, a high-order equivariant MLP is equivariant
universal.
\\ ( https://arxiv.org/abs/2002.02912 ,  256kb)
------------------------------------------------------------------------------
\\
arXiv:2002.02913
Date: Fri, 7 Feb 2020 17:27:30 GMT   (8964kb,D)

Title: Learning Autoencoders with Relational Regularization
Authors: Hongteng Xu, Dixin Luo, Ricardo Henao, Svati Shah, Lawrence Carin
Categories: cs.LG stat.ML
\\
  A new algorithmic framework is proposed for learning autoencoders of data
distributions. We minimize the discrepancy between the model and target
distributions, with a \emph{relational regularization} on the learnable latent
prior. This regularization penalizes the fused Gromov-Wasserstein (FGW)
distance between the latent prior and its corresponding posterior, allowing one
to flexibly learn a structured prior distribution associated with the
generative model. Moreover, it helps co-training of multiple autoencoders even
if they have heterogeneous architectures and incomparable latent spaces. We
implement the framework with two scalable algorithms, making it applicable for
both probabilistic and deterministic autoencoders. Our relational regularized
autoencoder (RAE) outperforms existing methods, $e.g.$, the variational
autoencoder, Wasserstein autoencoder, and their variants, on generating images.
Additionally, our relational co-training strategy for autoencoders achieves
encouraging results in both synthesis and real-world multi-view learning tasks.
\\ ( https://arxiv.org/abs/2002.02913 ,  8964kb)
------------------------------------------------------------------------------
\\
arXiv:2002.02923
Date: Fri, 7 Feb 2020 17:51:26 GMT   (2687kb,D)

Title: Geometric Dataset Distances via Optimal Transport
Authors: David Alvarez-Melis and Nicol\`o Fusi
Categories: cs.LG stat.ML
\\
  The notion of task similarity is at the core of various machine learning
paradigms, such as domain adaptation and meta-learning. Current methods to
quantify it are often heuristic, make strong assumptions on the label sets
across the tasks, and many are architecture-dependent, relying on task-specific
optimal parameters (e.g., require training a model on each dataset). In this
work we propose an alternative notion of distance between datasets that (i) is
model-agnostic, (ii) does not involve training, (iii) can compare datasets even
if their label sets are completely disjoint and (iv) has solid theoretical
footing. This distance relies on optimal transport, which provides it with rich
geometry awareness, interpretable correspondences and well-understood
properties. Our results show that this novel distance provides meaningful
comparison of datasets, and correlates well with transfer learning hardness
across various experimental settings and datasets.
\\ ( https://arxiv.org/abs/2002.02923 ,  2687kb)
------------------------------------------------------------------------------
\\
arXiv:2002.02948
Date: Fri, 7 Feb 2020 18:32:44 GMT   (2472kb)

Title: A deep-learning view of chemical space designed to facilitate drug
  discovery
Authors: Paul Maragakis, Hunter Nisonoff, Brian Cole, and David E. Shaw
Categories: cs.LG stat.ML
\\
  Drug discovery projects entail cycles of design, synthesis, and testing that
yield a series of chemically related small molecules whose properties, such as
binding affinity to a given target protein, are progressively tailored to a
particular drug discovery goal. The use of deep learning technologies could
augment the typical practice of using human intuition in the design cycle, and
thereby expedite drug discovery projects. Here we present DESMILES, a deep
neural network model that advances the state of the art in machine learning
approaches to molecular design. We applied DESMILES to a previously published
benchmark that assesses the ability of a method to modify input molecules to
inhibit the dopamine receptor D2, and DESMILES yielded a 77% lower failure rate
compared to state-of-the-art models. To explain the ability of DESMILES to hone
molecular properties, we visualize a layer of the DESMILES network, and further
demonstrate this ability by using DESMILES to tailor the same molecules used in
the D2 benchmark test to dock more potently against seven different receptors.
\\ ( https://arxiv.org/abs/2002.02948 ,  2472kb)
------------------------------------------------------------------------------
\\
arXiv:2002.02949
Date: Fri, 7 Feb 2020 18:34:31 GMT   (8126kb,D)

Title: Activation Density driven Energy-Efficient Pruning in Training
Authors: Timothy Foldy-Porto, and Priyadarshini Panda
Categories: cs.LG cs.CV cs.NE stat.ML
Comments: 7 pages, 3 figures, 3 tables
\\
  The process of neural network pruning with suitable fine-tuning and
retraining can yield networks with considerably fewer parameters than the
original with comparable degrees of accuracy. Typically, pruning methods
require large, pre-trained networks as a starting point from which they perform
a time-intensive iterative pruning and retraining algorithm. We propose a novel
pruning in-training method that prunes a network real-time during training,
reducing the overall training time to achieve an optimal compressed network. To
do so, we introduce an activation density based analysis that identifies the
optimal relative sizing or compression for each layer of the network. Our
method removes the need for pre-training and is architecture agnostic, allowing
it to be employed on a wide variety of systems. For VGG-19 and ResNet18 on
CIFAR-10, CIFAR-100, and TinyImageNet, we obtain exceedingly sparse networks
(up to 200x reduction in parameters and >60x reduction in inference compute
operations in the best case) with comparable accuracies (up to 2%-3% loss with
respect to the baseline network). By reducing the network size periodically
during training, we achieve total training times that are shorter than those of
previously proposed pruning methods. Furthermore, training compressed networks
at different epochs with our proposed method yields considerable reduction in
training compute complexity (1.6x -3.2x lower) at near iso-accuracy as compared
to a baseline network trained entirely from scratch.
\\ ( https://arxiv.org/abs/2002.02949 ,  8126kb)
------------------------------------------------------------------------------
\\
arXiv:2002.02950
Date: Fri, 7 Feb 2020 18:36:39 GMT   (34kb)

Title: Logistic Regression Regret: What's the Catch?
Authors: Gil I. Shamir
Categories: cs.LG stat.ML
Comments: Submitted to COLT 2020
\\
  We address the problem of the achievable regret rates with online logistic
regression. We derive lower bounds with logarithmic regret under $L_1$, $L_2$,
and $L_\infty$ constraints on the parameter values. The bounds are dominated by
$d/2 \log T$, where $T$ is the horizon and $d$ is the dimensionality of the
parameter space. We show their achievability for $d=o(T^{1/3})$ in all these
cases with Bayesian methods, that achieve them up to a $d/2 \log d$ term.
Interesting different behaviors are shown for larger dimensionality.
Specifically, on the negative side, if $d = \Omega(\sqrt{T})$, any algorithm is
guaranteed regret of $\Omega(d \log T)$ (greater than $\Omega(\sqrt{T})$) under
$L_\infty$ constraints on the parameters (and the example features). On the
positive side, under $L_1$ constraints on the parameters, there exist
algorithms that can achieve regret that is sub-linear in $d$ for the
asymptotically larger values of $d$. For $L_2$ constraints, it is shown that
for large enough $d$, the regret remains linear in $d$ but no longer
logarithmic in $T$. Adapting the redundancy-capacity theorem from information
theory, we demonstrate a principled methodology based on grids of parameters to
derive lower bounds. Grids are also utilized to derive some upper bounds. Our
results strengthen results by Kakade and Ng (2005) and Foster et al. (2018) for
upper bounds for this problem, introduce novel lower bounds, and adapt a
methodology that can be used to obtain such bounds for other related problems.
They also give a novel characterization of the asymptotic behavior when the
dimension of the parameter space is allowed to grow with $T$. They additionally
establish connections to the information theory literature, demonstrating that
the actual regret for logistic regression depends on the richness of the
parameter class, where even within this problem, richer classes lead to greater
regret.
\\ ( https://arxiv.org/abs/2002.02950 ,  34kb)
------------------------------------------------------------------------------
\\
arXiv:2002.02512
Date: Thu, 6 Feb 2020 20:58:48 GMT   (36kb)

Title: Relating Apartness and Bisimulation
Authors: Herman Geuvers and Bart Jacobs
Categories: cs.LO cs.FL
Comments: 23 pages
ACM-class: D.2.4; D.3.1; F.3.1
\\
  A bisimulation for a coalgebra of a functor on the category of sets can be
described via a coalgebra in the category of relations, of a lifted functor. A
final coalgebra then gives rise to the coinduction principle, which states that
two bisimilar elements are equal. For polynomial functors, this leads to
well-known descriptions. In the present paper we look at the dual notion of
"apartness". Intuitively, two elements are apart if there is a positive way to
distinguish them. Phrased differently: two elements are apart if and only if
they are not bisimilar. Since apartness is an inductive notion, described by a
least fixed point, one can look for proof rules. We study this in two different
ways. First, for weak forms of bisimulation on labelled transition systems,
where silent (tau) steps are included, we define an apartness notion that
corresponds to weak bisimulation and another apartness that corresponds to
branching bisimulation. We show how the rules for apartness can be used to show
that two states of a labelled transition system are not branching bismilar.
Next, we also study the more general categorical situation and show that
indeed, apartness is the dual of bisimilarity in a precise categorical sense:
apartness is an initial algebra and gives rise to an induction principle. In
this analogy, we include the powerset functor, which gives a semantics to
non-deterministic choice in process-theory.
\\ ( https://arxiv.org/abs/2002.02512 ,  36kb)
------------------------------------------------------------------------------
\\
arXiv:2002.02536
Date: Thu, 6 Feb 2020 22:19:13 GMT   (138kb,D)

Title: Constructive Hybrid Games
Authors: Brandon Bohrer, Andr\'e Platzer
Categories: cs.LO
Comments: 60 pages, preprint, under review
\\
  Hybrid games are models which combine discrete, continuous, and adversarial
dynamics. Game logic enables proving (classical) existence of winning
strategies. We introduce constructive differential game logic (CdGL) for hybrid
games, where proofs that a player can win the game correspond to computable
winning strategies. This is the logical foundation for synthesis of correct
control and monitoring code for safety-critical cyber-physical systems. Our
contributions include novel static and dynamic semantics as well as soundness
and consistency.
\\ ( https://arxiv.org/abs/2002.02536 ,  138kb)
------------------------------------------------------------------------------
\\
arXiv:2002.02576
Date: Fri, 7 Feb 2020 01:06:28 GMT   (168kb,D)

Title: Refining Constructive Hybrid Games
Authors: Brandon Bohrer and Andr\'e Platzer
Categories: cs.LO
Comments: 40 pages. Extended preprint
\\
  We extend the constructive differential game logic (CdGL) of hybrid games
with a refinement connective that relates two hybrid games. We use this
connective to prove a folk theorem relating hybrid games to hybrid systems.
\\ ( https://arxiv.org/abs/2002.02576 ,  168kb)
------------------------------------------------------------------------------
\\
arXiv:2002.02929
Date: Fri, 7 Feb 2020 18:05:53 GMT   (39kb)

Title: Intuitionistic Euler-Venn Diagrams (extended)
Authors: Sven Linker
Categories: cs.LO
\\
  We present an intuitionistic interpretation of Euler-Venn diagrams with
respect to Heyting algebras. In contrast to classical Euler-Venn diagrams, we
treat shaded and missing zones differently, to have diagrammatic
representations of conjunction, disjunction and intuitionistic implication. We
present a cut-free sequent calculus for this language, and prove it to be sound
and complete. Furthermore, we show that the rules of cut, weakening and
contraction are admissible.
\\ ( https://arxiv.org/abs/2002.02929 ,  39kb)
------------------------------------------------------------------------------
\\
arXiv:2002.02513
Date: Thu, 6 Feb 2020 20:58:58 GMT   (401kb,D)

Title: Multi Type Mean Field Reinforcement Learning
Authors: Sriram Ganapathi Subramanian and Pascal Poupart and Matthew E. Taylor
  and Nidhi Hegde
Categories: cs.MA cs.AI cs.LG
Comments: Paper to appear in the Proceedings of International Conference on
  Autonomous Agents and Multi-Agent Systems (AAMAS) 2020
\\
  Mean field theory provides an effective way of scaling multiagent
reinforcement learning algorithms to environments with many agents that can be
abstracted by a virtual mean agent. In this paper, we extend mean field
multiagent algorithms to multiple types. The types enable the relaxation of a
core assumption in mean field games, which is that all agents in the
environment are playing almost similar strategies and have the same goal. We
conduct experiments on three different testbeds for the field of many agent
reinforcement learning, based on the standard MAgents framework. We consider
two different kinds of mean field games: a) Games where agents belong to
predefined types that are known a priori and b) Games where the type of each
agent is unknown and therefore must be learned based on observations. We
introduce new algorithms for each type of game and demonstrate their superior
performance over state of the art algorithms that assume that all agents belong
to the same type and other baseline algorithms in the MAgent framework.
\\ ( https://arxiv.org/abs/2002.02513 ,  401kb)
------------------------------------------------------------------------------
\\
arXiv:2002.02484
Date: Thu, 6 Feb 2020 19:48:52 GMT   (6484kb,D)

Title: Conservative numerical schemes with optimal dispersive wave relations --
  Part II. Numerical evaluations
Authors: Qingshan Chen, Lili Ju, Roger Temam
Categories: math.NA cs.NA physics.ao-ph physics.geo-ph
\\
  A new energy and enstrophy conserving scheme is evaluated using a suite of
test cases over the global spherical domain or bounded domains. The evaluation
is organized around a set of pre-defined properties: accuracy of individual
opeartors, accuracy of the whole scheme, conservation, control of the
divergence variable, representation of the energy and enstrophy spectra, and
simulation of nonlinear dynamics. The results confirm that the scheme is
between the first and second order accurate, and conserves the total energy and
potential enstrophy up to the time truncation errors. The scheme is capable of
producing more physically realistic energy and enstrophy spectra, indicating
that the new scheme can help prevent the unphysical energy cascade towards the
finest resolvable scales. With an optimal representation of the dispersive wave
relations, the scheme is able to keep the flow close to being non-divergent,
maintain the geostrophically balanced structures with large-scale geophysical
flows over long-term simulations.
\\ ( https://arxiv.org/abs/2002.02484 ,  6484kb)
------------------------------------------------------------------------------
\\
arXiv:2002.02517
Date: Thu, 6 Feb 2020 21:26:43 GMT   (2709kb,D)

Title: Hybrid Solver for the Radiative Transport Equation Using Finite Volume
  and Discontinuous Galerkin
Authors: Vincent Heningburg and Cory D. Hauck
Categories: math.NA cs.NA
Comments: 25 pages, 5 figures, 10 tables
\\
  We propose a hybrid spatial discretization for the radiative transport
equation that combines a second-order discontinuous Galerkin (DG) method and a
second-order finite volume (FV) method. The strategy relies on a simple
operator splitting that has been used previously to combine different angular
discretizations. Unlike standard FV methods with upwind fluxes, the hybrid
approach is able to accurately simulate problems in scattering dominated
regimes. However, it requires less memory and yields a faster computational
time than a uniform DG discretization. In addition, the underlying splitting
allows naturally for hybridization in both space and angle. Numerical results
are given to demonstrate the efficiency of the hybrid approach in the context
of discrete ordinate angular discretizations and Cartesian spatial grids.
\\ ( https://arxiv.org/abs/2002.02517 ,  2709kb)
------------------------------------------------------------------------------
\\
arXiv:2002.02680
Date: Fri, 7 Feb 2020 09:27:26 GMT   (5005kb,D)

Title: Virtual Element Formulation For Finite Strain Elastodynamics
Authors: M. Cihan, F. Aldakheel, B. Hudobivnik and P. Wriggers
Categories: math.NA cs.NA
\\
  This work provides an efficient virtual element scheme for the modeling of
nonlinear elastodynamics undergoing large deformations. The virtual element
method (VEM) has been applied to various engineering problems such as
elasto-plasticity, multiphysics, damage and fracture mechanics. This work
focuses on the extension of VEM towards dynamic applications. Within this
framework, we employ low-order ansatz functions in one, two and three
dimensions that having arbitrary convex or concave polygonal elements. The
formulations considered in this contribution are based on minimization of
potential function for both the static and the dynamic behavior. While the
stiffness-matrix needs a suitable stabilization, the mass-matrix can be
calculated using only the projection part. For the implicit time integration
scheme, Newmark-Method is used. To show the performance of the method, various
numerical examples in 1D, 2D and 3D are presented.
\\ ( https://arxiv.org/abs/2002.02680 ,  5005kb)
------------------------------------------------------------------------------
\\
arXiv:2002.02804
Date: Tue, 4 Feb 2020 00:49:47 GMT   (9752kb,D)

Title: A Deep Learning Approach for the Computation of Curvature in the
  Level-Set Method
Authors: Luis \'Angel Larios C\'ardenas and Frederic Gibou
Categories: math.NA cs.LG cs.NA stat.ML
Comments: Submitted to SIAM Journal on Scientific Computing
MSC-class: 68T99 (primary), 65Z05 (secondary), 65N06
ACM-class: I.2.6; G.1.8
\\
  We propose a deep learning strategy to compute the mean curvature of an
implicit level-set representation of an interface. Our approach is based on
fitting neural networks to synthetic datasets of pairs of nodal $\phi$ values
and curvatures obtained from circular interfaces immersed in different uniform
resolutions. These neural networks are multilayer perceptrons that ingest
sample level-set values of grid points along a free boundary and output the
dimensionless curvature at the center vertices of each sampled neighborhood.
Evaluations with irregular (smooth and sharp) interfaces, in both uniform and
adaptive meshes, show that our deep learning approach is systematically
superior to conventional numerical approximation in the $L^2$ and $L^\infty$
norms. Our methodology is also less sensitive to steep curvatures and
approximates them well with samples collected with fewer iterations of the
reinitialization equation, often needed to regularize the underlying implicit
function. Additionally, we show that an application-dependent map of local
resolutions to neural networks can be constructed and employed to estimate
interface curvatures more efficiently than using typically expensive numerical
schemes while still attaining comparable or higher precision.
\\ ( https://arxiv.org/abs/2002.02804 ,  9752kb)
------------------------------------------------------------------------------
\\
arXiv:2002.02812
Date: Fri, 7 Feb 2020 14:38:02 GMT   (1735kb)

Title: Randomized Algorithms for Generalized Singular Value Decomposition with
  Application to Sensitivity Analysis
Authors: Arvind K. Saibaba, Joseph Hart, Bart van Bloemen Waanders
Categories: math.NA cs.NA
Comments: 24 pages, 10 figures, 1 table
\\
  The generalized singular value decomposition (GSVD) is a valuable tool that
has many applications in computational science. However, computing the GSVD for
large-scale problems is challenging. Motivated by applications in
hyper-differential sensitivity analysis (HDSA), we propose new randomized
algorithms for computing the GSVD which use randomized subspace iteration and
weighted QR factorization. Detailed error analysis is given which provides
insight into the accuracy of the algorithms and the choice of the algorithmic
parameters. We demonstrate the performance of our algorithms on test matrices
and a large-scale model problem where HDSA is used to study subsurface flow.
\\ ( https://arxiv.org/abs/2002.02812 ,  1735kb)
------------------------------------------------------------------------------
\\
arXiv:2002.02874
Date: Fri, 7 Feb 2020 16:19:33 GMT   (4212kb,D)

Title: Recovering missing data in coherent diffraction imaging
Authors: David Barmherzig, Alex B. Barnett, Charles L. Epstein, Leslie F.
  Greengard, Jeremy F. Magland, and Manas Rachh
Categories: math.NA cs.NA eess.SP hep-ex
MSC-class: 78A46, 78A45, 42A16, 65T40
\\
  In coherent diffraction imaging (CDI) experiments, the intensity of the
scattered wave impinging on an object is measured on an array of detectors.
This signal can be interpreted as the square of the modulus of the Fourier
transform of the unknown scattering density. A beam-stop obstructs the forward
scattered wave and, hence, the modulus Fourier data from a neighborhood of k=0
cannot be measured. In this note, we describe a linear method for recovering
this unmeasured modulus Fourier data from the measured values and an estimate
of the support of the image's autocorrelation function without consideration of
phase retrieval. We analyze the conditioning of this problem, which grows
exponentially with the modulus of the maximum spatial frequency not measured,
and the effects of noise.
\\ ( https://arxiv.org/abs/2002.02874 ,  4212kb)
------------------------------------------------------------------------------
\\
arXiv:2002.02930
Date: Fri, 7 Feb 2020 18:05:58 GMT   (1007kb,D)

Title: An Eulerian-Lagrangian discontinuous Galerkin method for transport
  problems and its application to nonlinear dynamics
Authors: Xiaofeng Cai, Jing-Mei Qiu and Yang Yang
Categories: math.NA cs.NA physics.comp-ph physics.flu-dyn
\\
  We propose a new Eulerian-Lagrangian (EL) discontinuous Galerkin (DG) method.
The method is designed as a generalization of the semi-Lagrangian (SL) DG
method for linear advection problems proposed in [J. Sci. Comput. 73: 514-542,
2017], which is formulated based on an adjoint problem and tracing upstream
cells by tracking characteristics curves highly accurately. In the SLDG method,
depending on the velocity field, upstream cells could be of arbitrary shape.
Thus, a more sophisticated approximation to sides of the upstream cells is
required to get high order approximation. For example, quadratic-curved (QC)
quadrilaterals were proposed to approximate upstream cells for a third-order
spatial accuracy in a swirling deformation example. In this paper, for linear
advection problems, we propose a more general formulation, named the ELDG
method. The scheme is formulated based on a {\em modified} adjoint problem for
which the upstream cells are always quadrilaterals, which avoids the need to
use QC quadrilaterals in the SLDG algorithm. The newly proposed ELDG method can
be viewed as a new general framework, in which both the classical Eulerian
Runge-Kutta DG formulation and the SL DG formulation can fit in. Numerical
results on linear transport problems, as well as the nonlinear Vlasov and
incompressible Euler dynamics using the exponential RK time integrators, are
presented to demonstrate the effectiveness of the ELDG method.
\\ ( https://arxiv.org/abs/2002.02930 ,  1007kb)
------------------------------------------------------------------------------
\\
arXiv:2002.02636
Date: Fri, 7 Feb 2020 06:33:05 GMT   (8495kb,D)

Title: Dynamic Multi-objective Optimization of the Travelling Thief Problem
Authors: Daniel Herring, Michael Kirley, Xin Yao
Categories: cs.NE
\\
  Investigation of detailed and complex optimisation problem formulations that
reflect realistic scenarios is a burgeoning field of research. A growing body
of work exists for the Travelling Thief Problem, including multi-objective
formulations and comparisons of exact and approximate methods to solve it.
However, as many realistic scenarios are non-static in time, dynamic
formulations have yet to be considered for the TTP. Definition of dynamics
within three areas of the TTP problem are addressed; in the city locations,
availability map and item values. Based on the elucidation of solution
conservation between initial sets and obtained non-dominated sets, we define a
range of initialisation mechanisms using solutions generated via solvers,
greedily and randomly. These are then deployed to seed the population after a
change and the performance in terms of hypervolume and spread is presented for
comparison. Across a range of problems with varying TSP-component and
KP-component sizes, we observe interesting trends in line with existing
conclusions; there is little benefit to using randomisation as a strategy for
initialisation of solution populations when the optimal TSP and KP component
solutions can be exploited. Whilst these separate optima don't guarantee good
TTP solutions, when combined, provide better initial performance and therefore
in some examined instances, provides the best response to dynamic changes. A
combined approach that mixes solution generation methods to provide a composite
population in response to dynamic changes provides improved performance in some
instances for the different dynamic TTP formulations. Potential for further
development of a more cooperative combined method are realised to more
cohesively exploit known information about the problems.
\\ ( https://arxiv.org/abs/2002.02636 ,  8495kb)
------------------------------------------------------------------------------
\\
arXiv:2002.02869
Date: Fri, 7 Feb 2020 16:05:54 GMT   (6462kb,D)

Title: Differential Evolution with Reversible Linear Transformations
Authors: Jakub M. Tomczak and Ewelina Weglarz-Tomczak and Agoston E. Eiben
Categories: cs.NE
Comments: Code: https://github.com/jmtomczak
\\
  Differential evolution (DE) is a well-known type of evolutionary algorithms
(EA). Similarly to other EA variants it can suffer from small populations and
loose diversity too quickly. This paper presents a new approach to mitigate
this issue: We propose to generate new candidate solutions by utilizing
reversible linear transformation applied to a triplet of solutions from the
population. In other words, the population is enlarged by using newly generated
individuals without evaluating their fitness. We assess our methods on three
problems: (i) benchmark function optimization, (ii) discovering parameter
values of the gene repressilator system, (iii) learning neural networks. The
empirical results indicate that the proposed approach outperforms vanilla DE
and a version of DE with applying differential mutation three times on all
testbeds.
\\ ( https://arxiv.org/abs/2002.02869 ,  6462kb)
------------------------------------------------------------------------------
\\
arXiv:2002.02522
Date: Thu, 6 Feb 2020 22:02:06 GMT   (106kb,D)

Title: Link Capacity Distributions and Optimal Capacities for Competent Network
  Performance
Authors: Saptarshi Pal, Ayan Chatterjee, Dripto Bakshi, Amitava Mukherjee
Categories: cs.NI
\\
  This work addresses the problem of evaluating optimal link capacities of a
packet-flow network for the objective of congestion minimization. We present a
simple model of packet flow in networks and present a numerical approach to
evaluate packet flow probability mass function at any arbitrary edge of the
network for a given routing algorithm and traffic rate. We further discuss
techniques of assigning optimal capacity at each edge for attaining desired
minimized congestion and discuss related trade-offs. Our framework is built
around the assumption of Poisson traffic, however the numerical approach fits
for any general distribution of packet influx. Lastly, we define metrics of
global performance of link capacities allocation and discuss the effect of
network structure on capacity allocation and performance.
\\ ( https://arxiv.org/abs/2002.02522 ,  106kb)
------------------------------------------------------------------------------
\\
arXiv:2002.02596
Date: Fri, 7 Feb 2020 02:45:54 GMT   (1436kb,D)

Title: Delay-Optimal Distributed Edge Computing in Wireless Edge Networks
Authors: Xiaowen Gong
Categories: cs.NI cs.DC
Comments: This paper has been accepted by IEEE INFOCOM 2020
\\
  By integrating edge computing with parallel computing, distributed edge
computing (DEC) makes use of distributed devices in edge networks to perform
computing in parallel, which can substantially reduce service delays. In this
paper, we explore DEC that exploits distributed edge devices connected by a
wireless network to perform a computation task offloaded from an end device. In
particular, we study the fundamental problem of minimizing the delay of
executing a distributed algorithm of the computation task. We first establish
some structural properties of the optimal communication scheduling policy.
Then, given these properties, we characterize the optimal computation
allocation policy, which can be found by an efficient algorithm. Next, based on
the optimal computation allocation, we characterize the optimal scheduling
order of communications for some special cases, and develop an efficient
algorithm with a finite approximation ratio to find it for the general case.
Last, based on the optimal computation allocation and communication scheduling,
we further show that the optimal selection of devices can be found efficiently
for some special cases. Our results provide some useful insights for the
optimal computation-communication co-design. We evaluate the performance of the
theoretical findings using simulations.
\\ ( https://arxiv.org/abs/2002.02596 ,  1436kb)
------------------------------------------------------------------------------
\\
arXiv:2002.02708
Date: Fri, 7 Feb 2020 10:53:17 GMT   (326kb,D)

Title: Embedding Jamming Attacks into Physical Layer Models in Optical Networks
Authors: Mounir Bensalem, \'Italo Brasileiro, Andr\'e Drummond, Admela Jukan
Categories: cs.NI eess.SP
\\
  Optical networks are prone to physical layer attacks, in particular the
insertion of high jamming power. In this paper, we present a study of jamming
attacks in elastic optical networks (EON) by embedding the jamming into the
physical layer model, and we analyze its impact on the blocking probability and
slots utilization. We evaluate our proposed model using a single link and a
network topology and we show that for in-band-jamming, the slots utilization
decreases with the increase of jamming power, and becomes null when the jamming
power is higher than 3 dB, while for out-of-band jamming, the impact is maximal
for a specific jamming power, 1.75 dB in our simulation. Considering multiple
positions of attackers, we attained the highest blocking probability 32% for a
specific jamming power 2 dB. We conclude that the impact of jamming depends on
attacker positions as well as the jamming power.
\\ ( https://arxiv.org/abs/2002.02708 ,  326kb)
------------------------------------------------------------------------------
\\
arXiv:2002.02771
Date: Wed, 5 Feb 2020 19:35:15 GMT   (2511kb)

Title: Dynamic-TDD Interference Analysis in Macro-Cell and Small-Cell
  Deployments
Authors: Jalal Rachad, Ridha Nasri, Laurent Decreusefond
Categories: cs.NI
Comments: arXiv admin note: text overlap with arXiv:1805.06638
\\
  Meeting the continued growth in data traffic volume, Dynamic Time Division
Duplex (D-TDD) has been introduced as a solution to deal with the uplink (UL)
and downlink (DL) traffic asymmetry, mainly observed for dense heterogeneous
network deployments, since it is based on instantaneous traffic estimation and
provide more flexibility in resource assignment. However, using this feature
requires new interference mitigation schemes capable to handle two additional
types of interference between cells in opposite transmission direction: DL to
UL and UL to DL interference. The aim of this work is to provide a complete
analytical approach to model inter-cell interference in macro-cells deployment
and dense small-cells. We derive the explicit expressions of Interference to
Signal Ratio (ISR) metric at each position of the network, in both DL and UL,
to quantify the impact of each type of interference on the perceived
performance. Also, we provide the explicit expressions of the coverage
probability as a functions of different system parameters for both macro-cells
and small-cells deployments. Finally, through system level simulations, we
analyze the feasibility of D-TDD and its comparison with the static-TDD
configuration.
\\ ( https://arxiv.org/abs/2002.02771 ,  2511kb)
------------------------------------------------------------------------------
\\
arXiv:2002.02880
Date: Fri, 7 Feb 2020 16:32:48 GMT   (1267kb,D)

Title: Multilayer Routing and Resource Assignment in Spatial Channel Networks
  (SCNs): Oriented Toward the Massive SDM Era
Authors: Mingcong Yang, Qian Wu, Maiko Shigeno, and YongbingZhang
Categories: cs.NI cs.SY eess.SY
Comments: This work has been submitted to the IEEE for possible publication.
  Copyright may be transferred without notice, after which this version may no
  longer be accessible
\\
  In the past few decades, optical transport networks (OTNs) have undergone
significant evolution, from the earliest wavelength-division multiplexing (WDM)
OTNs to elastic optical networks (EONs) and later to space-division
multiplexing (SDM) OTNs, to address the continuous growth of Internet traffic.
By 2024, Pbps-level OTNs are expected, far exceeding the capacity limit of
single-mode fibers. The massive SDM era is on the horizon. In this context,
newly designed OTNs called spatial channel networks (SCNs), which achieve high
cost efficiency by means of practical hierarchical optical cross-connects, have
recently been proposed. However, the evolution of OTNs will simultaneously
present challenges related to resource allocation in networking. For instance,
with the evolution from WDM-OTNs to EONs, the resource allocation problem was
transformed from the routing and wavelength assignment (RWA) problem to the
routing and spectrum assignment (RSA) problem due to the additionally
introduced constraint of spectrum contiguity. Similarly, specially designed
algorithms are also expected to be essential for addressing the resource
allocation problem in SCNs. In this paper, we define this new problem as the
routing, spatial channel, and spectrum assignment (RSCSA) problem. We propose
an integer linear programming (ILP) model and a heuristic algorithm to solve
the RSCSA problem. We examine the performance of the proposed approaches via
simulation experiments. The results show that both proposed approaches are
effective in finding the optimal solutions or solutions close to the lower
bounds. To the best of our knowledge, this is the first work to focus on the
problem of resource allocation in SCNs.
\\ ( https://arxiv.org/abs/2002.02880 ,  1267kb)
------------------------------------------------------------------------------
\\
arXiv:2002.02710
Date: Fri, 7 Feb 2020 10:54:57 GMT   (66kb,D)

Title: Formalising and verifying smart contracts with Solidifier: a bounded
  model checker for Solidity
Authors: Pedro Antonino and A. W. Roscoe
Categories: cs.PL cs.CR cs.LO cs.SE
ACM-class: D.2.4; D.3.1; D.3.3; F.3.1; F.3.2; F.3.3
\\
  The exploitation of smart-contract vulnerabilities can have catastrophic
consequences such as the loss of millions of pounds worth of crypto assets.
Formal verification can be a useful tool in identifying vulnerabilities and
proving that they have been fixed. In this paper, we present a formalisation of
Solidity and the Ethereum blockchain using the Solid language and its
blockchain; a Solid program is obtained by explicating/desugaring a Solidity
program. We make some abstractions that over-approximate the way in which
Solidity/Ethereum behave. Based on this formalisation, we create Solidifier: a
bounded model checker for Solidity. It translates Solid into Boogie, an
intermediate verification language, that is later verified using Corral, a
bounded model checker for Boogie. Unlike much of the work in this area, we do
not try to find specific behavioural/code patterns that might lead to
vulnerabilities. Instead, we provide a tool to find errors/bad states, i.e.
program states that do not conform with the intent of the developer. Such a bad
state, be it a vulnerability or not, might be reached through the execution of
specific known code patterns or through behaviours that have not been
anticipated.
\\ ( https://arxiv.org/abs/2002.02710 ,  66kb)
------------------------------------------------------------------------------
\\
arXiv:2002.02904
Date: Fri, 7 Feb 2020 17:03:53 GMT   (64kb)

Title: RHLE: Automatic Verification of $\forall\exists$-Hyperproperties
Authors: Robert Dickerson, Qianchuan Ye, Benjamin Delaware
Categories: cs.PL cs.LO
ACM-class: F.3.1; D.2.4
\\
  Specifications of program behavior typically consider single executions of a
program, usually requiring that every execution never reaches a bad state (a
safety property) or that every execution can eventually produce some good state
(a liveness property). Many desirable behaviors, however, including refinement
and non-interference, range over multiple executions of a program. These sorts
of behaviors are instead expressible as a combination of k-safety and
k-liveness hyperproperties. Relational program logics allow for reasoning about
the validity of hyperproperties, but, just as Floyd-Hoare logics focus on
axiomatic reasoning about safety, existing relational logics have focused on
proving k-safety properties. Such relational logics are unfortunately not
suitable for verifying more general combinations of k-safety and k-liveness
hyperproperties.
  This paper presents RHLE, a relational program logic for reasoning about a
class of such hyperproperties that we term $\forall\exists$-hyperproperties.
RHLE forms the basis for an algorithm capable of automatically verifying this
class of hyperproperties. We present an implementation of this algorithm which
we have used to automatically verify a number of
$\forall\exists$-hyperproperties, including refinement and non-interference
properties, on a corpus of representative programs.
\\ ( https://arxiv.org/abs/2002.02904 ,  64kb)
------------------------------------------------------------------------------
\\
arXiv:2002.02914
Date: Fri, 7 Feb 2020 17:29:54 GMT   (47kb)

Title: Improving the GP 2 Compiler
Authors: Graham Campbell and Jack Romo and Detlef Plump
Categories: cs.PL cs.LO
Comments: Technical Report, Department of Computer Science, University of York,
  42 pages, 2019
MSC-class: 68Q42, 68N20
\\
  GP 2 is an experimental programming language based on graph transformation
rules which aims to facilitate program analysis and verification. Writing
efficient programs in such a language is hard because graph matching is
expensive, however GP 2 addresses this problem by providing rooted rules which,
under mild conditions, can be matched in constant time using the GP 2 to C
compiler. In this report, we document various improvements made to the
compiler; most notably the introduction of node lists to improve iteration
performance for destructive programs, meaning that binary DAG recognition by
reduction need only take linear time where the previous implementation required
quadratic time.
\\ ( https://arxiv.org/abs/2002.02914 ,  47kb)
------------------------------------------------------------------------------
\\
arXiv:2002.02474
Date: Thu, 6 Feb 2020 19:14:19 GMT   (6715kb,D)

Title: Design of a Fully Actuated Robotic Hand With Multiple Gelsight Tactile
  Sensors
Authors: Achu Wilson, Shaoxiong Wang, Branden Romero, Edward Adelson
Categories: cs.RO
\\
  This work details the design of a novel two finger robot gripper with
multiple Gelsight based optical-tactile sensors covering the inner surface of
the hand. The multiple Gelsight sensors can gather the surface topology of the
object from multiple views simultaneously as well as can track the shear and
tensile stress. In addition, other sensing modalities enable the hand to gather
the thermal, acoustic and vibration information from the object being grasped.
The force controlled gripper is fully actuated so that it can be used for
various grasp configurations and can also be used for in-hand manipulation
tasks. Here we present the design of such a gripper.
\\ ( https://arxiv.org/abs/2002.02474 ,  6715kb)
------------------------------------------------------------------------------
\\
arXiv:2002.02538
Date: Thu, 6 Feb 2020 22:26:00 GMT   (9260kb,D)

Title: Sim2Real2Sim: Bridging the Gap Between Simulation and Real-World in
  Flexible Object Manipulation
Authors: Peng Chang, Taskin Padir
Categories: cs.RO
\\
  This paper addresses a new strategy called Simulation-to-Real-to-Simulation
(Sim2Real2Sim) to bridge the gap between simulation and real-world, and
automate a flexible object manipulation task. This strategy consists of three
steps: (1) using the rough environment with the estimated models to develop the
methods to complete the manipulation task in the simulation; (2) applying the
methods from simulation to real-world and comparing their performance; (3)
updating the models and methods in simulation based on the differences between
the real world and the simulation. The Plug Task from the 2015 DARPA Robotics
Challenge Finals is chosen to evaluate our Sim2Real2Sim strategy. A new
identification approach for building the model of the linear flexible objects
is derived from real-world to simulation. The automation of the DRC plug task
in both simulation and real-world proves the success of the Sim2Real2Sim
strategy. Numerical experiments are implemented to validate the simulated
model.
\\ ( https://arxiv.org/abs/2002.02538 ,  9260kb)
------------------------------------------------------------------------------
\\
arXiv:2002.02580
Date: Fri, 7 Feb 2020 01:41:29 GMT   (4198kb,D)

Title: Autonomous Industrial Assembly using Force, Torque, and RGB-D sensing
Authors: James Watson, Austin Miller and Nikolaus Correll
Categories: cs.RO
Journal-ref: https://www.tandfonline.com/doi/ref/10.1080/01691864.2020.1715254?scroll=top#metrics-content
DOI: 10.1080/01691864.2020.1715254
\\
  We present algorithms and results for a robotic manipulation system that was
designed to be easily programmable and adaptable to various tasks common to
industrial setting, which is inspired by the Industrial Assembly Challenge at
the 2018 World Robotics Summit in Tokyo. This challenge included assembly of
standard, commercially available industrial parts into 2D and 3D assemblies. We
demonstrate three tasks that can be classified into "peg-in-hole" and
"hole-on-peg" tasks and identify two canonical algorithms: spiral-based search
and tilting insertion. Both algorithms use hand-coded thresholds in the force
and torque domains to detect critical points in the assembly. After briefly
summarizing the state of the art in research, we describe the strategy and
approach utilized by the tested system, how it's design bears on its
performance, statistics on 20 experimental trials for each task, lessons
learned during the development of the system, and open research challenges that
still remain.
\\ ( https://arxiv.org/abs/2002.02580 ,  4198kb)
------------------------------------------------------------------------------
\\
arXiv:2002.02715
Date: Fri, 7 Feb 2020 11:07:16 GMT   (2275kb,D)

Title: Free Space of Rigid Objects: Caging, Path Non-Existence, and Narrow
  Passage Detection
Authors: Anastasiia Varava and J. Frederico Carvalho, Danica Kragic, Florian T.
  Pokorny
Categories: cs.RO
Comments: submitted to IJRR
\\
  In this work we propose algorithms to explicitly construct a conservative
estimate of the configuration spaces of rigid objects in 2D and 3D. Our
approach is able to detect compact path components and narrow passages in
configuration space which are important for applications in robotic
manipulation and path planning. Moreover, as we demonstrate, they are also
applicable to identification of molecular cages in chemistry. Our algorithms
are based on a decomposition of the resulting 3 and 6 dimensional configuration
spaces into slices corresponding to a finite sample of fixed orientations in
configuration space. We utilize dual diagrams of unions of balls and uniform
grids of orientations to approximate the configuration space. We carry out
experiments to evaluate the computational efficiency on a set of objects with
different geometric features thus demonstrating that our approach is applicable
to different object shapes. We investigate the performance of our algorithm by
computing increasingly fine-grained approximations of the object's
configuration space.
\\ ( https://arxiv.org/abs/2002.02715 ,  2275kb)
------------------------------------------------------------------------------
\\
arXiv:2002.02783
Date: Fri, 7 Feb 2020 13:49:00 GMT   (21kb)

Title: Integral P-Recursive Sequences
Authors: Shaoshi Chen, Lixin Du, Manuel Kauers, Thibaut Verron
Categories: cs.SC math.NT
Comments: 20 pages
\\
  In an earlier paper, the notion of integrality known from algebraic number
fields and fields of algebraic functions has been extended to D-finite
functions. The aim of the present paper is to extend the notion to the case of
P-recursive sequences. In order to do so, we formulate a general algorithm for
finding all integral elements for valued vector spaces and then show that this
algorithm includes not only the algebraic and the D-finite cases but also
covers the case of P-recursive sequences.
\\ ( https://arxiv.org/abs/2002.02783 ,  21kb)
------------------------------------------------------------------------------
\\
arXiv:2002.02520
Date: Thu, 6 Feb 2020 21:47:39 GMT   (168kb,D)

Title: Robust Multi-channel Speech Recognition using Frequency Aligned Network
Authors: Taejin Park, Kenichi Kumatani, Minhua Wu, Shiva Sundaram
Categories: cs.SD cs.CL eess.AS
\\
  Conventional speech enhancement technique such as beamforming has known
benefits for far-field speech recognition. Our own work in frequency-domain
multi-channel acoustic modeling has shown additional improvements by training a
spatial filtering layer jointly within an acoustic model. In this paper, we
further develop this idea and use frequency aligned network for robust
multi-channel automatic speech recognition (ASR). Unlike an affine layer in the
frequency domain, the proposed frequency aligned component prevents one
frequency bin influencing other frequency bins. We show that this modification
not only reduces the number of parameters in the model but also significantly
and improves the ASR performance. We investigate effects of frequency aligned
network through ASR experiments on the real-world far-field data where users
are interacting with an ASR system in uncontrolled acoustic environments. We
show that our multi-channel acoustic model with a frequency aligned network
shows up to 18% relative reduction in word error rate.
\\ ( https://arxiv.org/abs/2002.02520 ,  168kb)
------------------------------------------------------------------------------
\\
arXiv:2002.02650
Date: Fri, 7 Feb 2020 07:19:34 GMT   (5782kb,D)

Title: What You See is What it Means! Semantic Representation Learning of Code
  based on Visualization and Transfer Learning
Authors: Patrick Keller and Laura Plein and Tegawend\'e F. Bissyand\'e and
  Jacques Klein and Yves Le Traon
Categories: cs.SE
\\
  Recent successes in training word embeddings for NLP tasks have encouraged a
wave of research on representation learning for source code, which builds on
similar NLP methods. The overall objective is then to produce code embeddings
that capture the maximum of program semantics. State-of-the-art approaches
invariably rely on a syntactic representation (i.e., raw lexical tokens,
abstract syntax trees, or intermediate representation tokens) to generate
embeddings, which are criticized in the literature as non-robust or
non-generalizable. In this work, we investigate a novel embedding approach
based on the intuition that source code has visual patterns of semantics. We
further use these patterns to address the outstanding challenge of identifying
semantic code clones. We propose the WYSIWIM ("What You See Is What It Means")
approach where visual representations of source code are fed into powerful
pre-trained image classification neural networks from the field of computer
vision to benefit from the practical advantages of transfer learning. We
evaluate the proposed embedding approach on two variations of the task of
semantic code clone identification: code clone detection (a binary
classification problem), and code classification (a multi-classification
problem). We show with experiments on the BigCloneBench (Java) and Open Judge
(C) datasets that although simple, our WYSIWIM approach performs as effectively
as state of the art approaches such as ASTNN or TBCNN. We further explore the
influence of different steps in our approach, such as the choice of visual
representations or the classification algorithm, to eventually discuss the
promises and limitations of this research direction.
\\ ( https://arxiv.org/abs/2002.02650 ,  5782kb)
------------------------------------------------------------------------------
\\
arXiv:2002.02672
Date: Fri, 7 Feb 2020 09:00:12 GMT   (139kb,D)

Title: How do Quantifiers Affect the Quality of Requirements?
Authors: Katharina Winter, Henning Femmer, Andreas Vogelsang
Categories: cs.SE
\\
  Context: Requirements quality can have a substantial impact on the
effectiveness and efficiency of using requirements artifacts in a development
process. Quantifiers such as "at least", "all", or "exactly" are common
language constructs used to express requirements. Quantifiers can be formulated
by affirmative phrases ("At least") or negative phrases ("Not less than").
Problem: It is long assumed that negation in quantification negatively affects
the readability of requirements, however, empirical research on these topics
remains sparse. Principal Idea: In a web-based experiment with 51 participants,
we compare the impact of negations and quantifiers on readability in terms of
reading effort, reading error rate and perceived reading difficulty of
requirements. Results: For 5 out of 9 quantifiers, our participants performed
better on the affirmative phrase compared to the negative phrase. Only for one
quantifier, the negative phrase was more effective. Contribution: This research
focuses on creating an empirical understanding of the effect of language in
Requirements Engineering. It furthermore provides concrete advice on how to
phrase requirements.
\\ ( https://arxiv.org/abs/2002.02672 ,  139kb)
------------------------------------------------------------------------------
\\
arXiv:2002.02760
Date: Wed, 29 Jan 2020 18:52:17 GMT   (294kb,D)

Title: TarTar: A Timed Automata Repair Tool
Authors: Martin Koelbl (1) and Stefan Leue (1) and Thomas Wies (2) ((1)
  University of Konstanz, (2) New York University)
Categories: cs.SE cs.FL
Comments: 15 pages, 7 figures
\\
  We present TarTar, an automatic repair analysis tool that, given a timed
diagnostic trace (TDT) obtained during the model checking of a timed automaton
model, suggests possible syntactic repairs of the analyzed model. The suggested
repairs include modified values for clock bounds in location invariants and
transition guards, adding or removing clock resets, etc. The proposed repairs
are guaranteed to eliminate executability of the given TDT, while preserving
the overall functional behavior of the system. We give insights into the design
and architecture of TarTar, and show that it can successfully repair 69% of the
seeded errors in system models taken from a diverse suite of case studies.
\\ ( https://arxiv.org/abs/2002.02760 ,  294kb)
------------------------------------------------------------------------------
\\
arXiv:2002.02793
Date: Fri, 7 Feb 2020 14:02:43 GMT   (935kb,D)

Title: Views on Quality Requirements in Academia and Practice: Commonalities,
  Differences, and Context-Dependent Grey Areas
Authors: Andreas Vogelsang, Jonas Eckhardt, Daniel Mendez, Moritz Berger
Categories: cs.SE
DOI: 10.1016/j.infsof.2019.106253
\\
  Context: Quality requirements (QRs) are a topic of constant discussions both
in industry and academia. Debates entwine around the definition of quality
requirements, the way how to handle them, or their importance for project
success. While many academic endeavors contribute to the body of knowledge
about QRs, practitioners may have different views. In fact, we still lack a
consistent body of knowledge on QRs since much of the discussion around this
topic is still dominated by observations that are strongly context-dependent.
This holds for both academic and practitioners' views. Our assumption is that,
in consequence, those views may differ. Objective: We report on a study to
better understand the extent to which available research statements on quality
requirements, as found in exemplary peer-reviewed and frequently cited
publications, are reflected in the perception of practitioners. Our goal is to
analyze differences, commonalities, and context-dependent grey areas in the
views of academics and practitioners to allow a discussion on potential
misconceptions (on either sides) and opportunities for future research. Method:
We conducted a survey with 109 practitioners to assess whether they agree with
research statements about QRs reflected in the literature. Based on a
statistical model, we evaluate the impact of a set of context factors to the
perception of research statements. Results: Our results show that a majority of
the statements is well respected by practitioners; however, not all of them.
When examining the different groups and backgrounds of respondents, we noticed
interesting deviations of perceptions within different groups that may lead to
new research questions. Conclusions: Our results help identifying prevalent
context-dependent differences about how academics and practitioners view QRs
and pinpointing statements where further research might be useful.
\\ ( https://arxiv.org/abs/2002.02793 ,  935kb)
------------------------------------------------------------------------------
\\
arXiv:2002.02890
Date: Fri, 7 Feb 2020 16:47:08 GMT   (585kb,D)

Title: Session-Based Recommender Systems for Action Selection in GUI Test
  Generation
Authors: Varun Nayak and Daniel Kraus
Categories: cs.SE
Comments: 5 pages, 3 figures, to be published in ICSTW 2020
\\
  Test generation at the graphical user interface (GUI) level has proven to be
an effective method to reveal faults. When doing so, a test generator has to
repeatably decide what action to execute given the current state of the system
under test (SUT). This problem of action selection usually involves random
choice, which is often referred to as monkey testing. Some approaches leverage
other techniques to improve the overall effectiveness, but only a few try to
create human-like actions---or even entire action sequences. We have built a
novel session-based recommender system that can guide test generation. This
allows us to mimic past user behavior, reaching states that require complex
interactions. We present preliminary results from an empirical study, where we
use GitHub as the SUT. These results show that recommender systems appear to be
well-suited for action selection, and that the approach can significantly
contribute to the improvement of GUI-based test generation.
\\ ( https://arxiv.org/abs/2002.02890 ,  585kb)
------------------------------------------------------------------------------
\\
arXiv:2002.02707
Date: Fri, 7 Feb 2020 10:47:30 GMT   (111kb)

Title: A Complete Set of Related Git Repositories Identified via Community
  Detection Approaches Based on Shared Commits
Authors: Audris Mockus, Diomidis Spinellis, Zoe Kotti, Gabriel John Dusing
Categories: cs.SI
Comments: 5 pages
\\
  In order to understand the state and evolution of the entirety of open source
software we need to get a handle on the set of distinct software projects. Most
of open source projects presently utilize Git, which is a distributed version
control system allowing easy creation of clones and resulting in numerous
repositories that are almost entirely based on some parent repository from
which they were cloned. Git commits are based on Merkle Tree and two commits
are highly unlikely to be produced independently. Shared commits, therefore,
appear like an excellent way to group cloned repositories and obtain an
accurate map for such repositories. We use World of Code infrastructure
containing approximately 2B commits and 100M repositories to create and share
such a map. We discover that the largest group contains almost 14M repositories
most of which are unrelated to each other. As it turns out, the developers can
push git object to an arbitrary repository or pull objects from unrelated
repositories, thus linking unrelated repositories. To address this, we apply
Louvain community detection algorithm to this very large graph consisting of
links between commits and projects. The approach successfully reduces the size
of the megacluster with the largest group of highly interconnected projects
containing under 100K repositories. We expect the tools that the resulting map
of related projects as well as tools and methods to handle the very large graph
will serve as a reference set for mining software projects and other
applications. Further work is needed to determine different types of
relationships among projects induced by shared commits and other relationships,
for example, by shared source code or similar filenames.
\\ ( https://arxiv.org/abs/2002.02707 ,  111kb)
------------------------------------------------------------------------------
\\
arXiv:2002.02728
Date: Fri, 7 Feb 2020 11:56:15 GMT   (277kb)

Title: Impact of the Interaction Network on the Dynamics of Word-of-Mouth with
  Information Seeking
Authors: Samuel Thiriot
Categories: cs.SI cs.CC cs.MA
Comments: 12 pages
\\
  Word-of-Mouth refers to the dynamics of interpersonal communication occurring
during the diffusion of innovations (novel practices, ideas or products).
According to field studies, word-of-mouth is made of both information seeking
and proactive communication: individuals first become aware of the existence of
an innovation, then start actively seeking out for the expert knowledge
required to evaluate the innovation; when they hold the expert knowledge, they
might start promoting it pro-actively. Successful diffusion of innovation
requires the individuals to hold both awareness and expert knowledge, so they
can evaluate the innovation and use it properly. A computational model
"USA/IPK" was recently proposed to study the role and impact of information
seeking on the dynamics of word-of-mouth. We propose here an analysis of the
impact of the network of interaction on the dynamics of this model. We compare
the dynamics of the model over networks generated with different algorithms
with the original dynamics. The results demonstrate the dynamics of the model
are similar across tested networks, with the noticeable exception of the
efficiency of the diffusion which varies between networks having similar
densities and sizes.
\\ ( https://arxiv.org/abs/2002.02728 ,  277kb)
------------------------------------------------------------------------------
\\
arXiv:2002.02800
Date: Fri, 7 Feb 2020 14:18:53 GMT   (106kb,D)

Title: Depressed individuals express more distorted thinking on social media
Authors: Krishna C. Bathina, Marijn ten Thij, Lorenzo Lorenzo-Luaces, Lauren A.
  Rutter, and Johan Bollen
Categories: cs.SI cs.CL
\\
  Depression is a leading cause of disability worldwide, but is often
under-diagnosed and under-treated. One of the tenets of cognitive-behavioral
therapy (CBT) is that individuals who are depressed exhibit distorted modes of
thinking, so-called cognitive distortions, which can negatively affect their
emotions and motivation. Here, we show that individuals with a self-reported
diagnosis of depression on social media express higher levels of distorted
thinking than a random sample. Some types of distorted thinking were found to
be more than twice as prevalent in our depressed cohort, in particular
Personalizing and Emotional Reasoning. This effect is specific to the distorted
content of the expression and can not be explained by the presence of specific
topics, sentiment, or first-person pronouns. Our results point towards the
detection, and possibly mitigation, of patterns of online language that are
generally deemed depressogenic. They may also provide insight into recent
observations that social media usage can have a negative impact on mental
health.
\\ ( https://arxiv.org/abs/2002.02800 ,  106kb)
------------------------------------------------------------------------------
\\
arXiv:2002.02544
Date: Thu, 6 Feb 2020 22:52:53 GMT   (1678kb)

Title: The Voltage Regulation of a Buck Converter Using a Neural Network
  Predictive Controller
Authors: Sepehr Saadatmand, Pourya Shamsi, and Mehdi Ferdowsi
Categories: eess.SY cs.SY
Comments: Accepted paper: 2020 IEEE Texas Power and Energy Conference (TPEC)
\\
  In this paper, a neural network predictive controller (NNPC) is proposed to
control a buck converter. Conventional controllers such as proportional
integral (PI) or proportional integral derivative (PID) are designed based on
the linearized small signal model near the operating point. Therefore, the
performance of the controller in the start up, load change, or reference change
is not optimal since the system model changes by changing the operating point.
The neural network predictive controller optimally controls the buck converter
by following the concept of the traditional model predictive controller. The
advantage of the NNPC is that the neural network system identification
decreases the inaccuracy of the system model with inaccurate parameters. A NNPC
with a well trained neural network can perform as an optimal controller for the
buck converter. To compare the effectiveness of the traditional buck converter
and the NNPC, the simulation results are provided.
\\ ( https://arxiv.org/abs/2002.02544 ,  1678kb)
------------------------------------------------------------------------------
\\
arXiv:2002.02687
Date: Fri, 7 Feb 2020 09:49:46 GMT   (133kb)

Title: On Abstraction-Based Controller Design With Output Feedback
Authors: Rupak Majumdar, Necmiye Ozay, Anne-Kathrin Schmuck
Categories: eess.SY cs.SY
\\
  We consider abstraction-based design of output-feedback controllers for
dynamical systems with a finite set of inputs and outputs against
specifications in linear-time temporal logic. The usual procedure for
abstraction-based controller design (ABCD) first constructs a finite-state
abstraction of the underlying dynamical system, and second, uses reactive
synthesis techniques to compute an abstract state-feedback controller on the
abstraction. In this context, our contribution is two-fold: (I) we define a
suitable relation between the original system and its abstraction which
characterizes the soundness and completeness conditions for an abstract
state-feedback controller to be refined to a concrete output-feedback
controller for the original system, and (II) we provide an algorithm to compute
a sound finite-state abstraction fulfilling this relation.
  Our relation generalizes feedback-refinement relations from ABCD with
state-feedback. Our algorithm for constructing sound finite-state abstractions
is inspired by the simultaneous reachability and bisimulation minimization
algorithm of Lee and Yannakakis. We lift their idea to the computation of an
observation-equivalent system and show how sound abstractions can be obtained
by stopping this algorithm at any point. Additionally, our new algorithm
produces a realization of the topological closure of the input/output behavior
of the original system if it is finite-state realizable.
\\ ( https://arxiv.org/abs/2002.02687 ,  133kb)
------------------------------------------------------------------------------
\\
arXiv:2002.02737
Date: Fri, 7 Feb 2020 12:35:33 GMT   (74kb,D)

Title: Developing a Hybrid Data-Driven, Mechanistic Virtual Flow Meter -- a
  Case Study
Authors: Mathilde Hotvedt, Bjarne Grimstad, Lars Imsland
Categories: eess.SY cs.LG cs.SY
Comments: 6 pages, 5 figures
ACM-class: I.2; I.6; J.2
\\
  Virtual flow meters, mathematical models predicting production flow rates in
petroleum assets, are useful aids in production monitoring and optimization.
Mechanistic models based on first-principles are most common, however,
data-driven models exploiting patterns in measurements are gaining popularity.
This research investigates a hybrid modeling approach, utilizing techniques
from both the aforementioned areas of expertise, to model a well production
choke. The choke is represented with a simplified set of first-principle
equations and a neural network to estimate the valve flow coefficient.
Historical production data from the petroleum platform Edvard Grieg is used for
model validation. Additionally, a mechanistic and a data-driven model are
constructed for comparison of performance. A practical framework for
development of models with varying degree of hybridity and stochastic
optimization of its parameters is established. Results of the hybrid model
performance are promising albeit with considerable room for improvements.
\\ ( https://arxiv.org/abs/2002.02737 ,  74kb)
------------------------------------------------------------------------------
\\
arXiv:2002.02928
Date: Fri, 7 Feb 2020 18:01:54 GMT   (2317kb,D)

Title: Towards Integrated Perception and Motion Planning with Distributionally
  Robust Risk Constraints
Authors: Venkatraman Renganathan, Iman Shames, Tyler H. Summers
Categories: eess.SY cs.SY
\\
  Safely deploying robots in uncertain and dynamic environments requires a
systematic accounting of various risks, both within and across layers in an
autonomy stack from perception to motion planning and control. Many widely used
motion planning algorithms do not adequately incorporate inherent perception
and prediction uncertainties, often ignoring them altogether or making
questionable assumptions of Gaussianity. We propose a distributionally robust
incremental sampling-based motion planning framework that explicitly and
coherently incorporates perception and prediction uncertainties. We design
output feedback policies and consider moment-based ambiguity sets of
distributions to enforce probabilistic collision avoidance constraints under
the worst-case distribution in the ambiguity set. Our solution approach, called
Output Feedback Distributionally Robust $RRT^{*}$(OFDR-$RRT^{*})$, produces
asymptotically optimal risk-bounded trajectories for robots operating in
dynamic, cluttered, and uncertain environments, explicitly incorporating
mapping and localization error, stochastic process disturbances, unpredictable
obstacle motion, and uncertain obstacle locations. Numerical experiments
illustrate the effectiveness of the proposed algorithm.
\\ ( https://arxiv.org/abs/2002.02928 ,  2317kb)
%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-
------------------------------------------------------------------------------
\\
arXiv:2002.02770 (*cross-listing*)
Date: Wed, 5 Feb 2020 21:35:29 GMT   (840kb,D)

Title: A Survey on Causal Inference
Authors: Liuyi Yao, Zhixuan Chu, Sheng Li, Yaliang Li, Jing Gao, Aidong Zhang
Categories: stat.ME cs.AI cs.LG stat.ML
\\
  Causal inference is a critical research topic across many domains, such as
statistics, computer science, education, public policy and economics, for
decades. Nowadays, estimating causal effect from observational data has become
an appealing research direction owing to the large amount of available data and
low budget requirement, compared with randomized controlled trials. Embraced
with the rapidly developed machine learning area, various causal effect
estimation methods for observational data have sprung up. In this survey, we
provide a comprehensive review of causal inference methods under the potential
outcome framework, one of the well known causal inference framework. The
methods are divided into two categories depending on whether they require all
three assumptions of the potential outcome framework or not. For each category,
both the traditional statistical methods and the recent machine learning
enhanced methods are discussed and compared. The plausible applications of
these methods are also presented, including the applications in advertising,
recommendation, medicine and so on. Moreover, the commonly used benchmark
datasets as well as the open-source codes are also summarized, which facilitate
researchers and practitioners to explore, evaluate and apply the causal
inference methods.
\\ ( https://arxiv.org/abs/2002.02770 ,  840kb)
------------------------------------------------------------------------------
\\
arXiv:2002.02562 (*cross-listing*)
Date: Fri, 7 Feb 2020 00:04:04 GMT   (215kb,D)

Title: Transformer Transducer: A Streamable Speech Recognition Model with
  Transformer Encoders and RNN-T Loss
Authors: Qian Zhang, Han Lu, Hasim Sak, Anshuman Tripathi, Erik McDermott,
  Stephen Koo, Shankar Kumar
Categories: eess.AS cs.CL cs.SD
Comments: This version of draft has been submitted to the ICASSP 2020 on Oct
  21, 2019 and has been accepted to the conference
\\
  In this paper we present an end-to-end speech recognition model with
Transformer encoders that can be used in a streaming speech recognition system.
Transformer computation blocks based on self-attention are used to encode both
audio and label sequences independently. The activations from both audio and
label encoders are combined with a feed-forward layer to compute a probability
distribution over the label space for every combination of acoustic frame
position and label history. This is similar to the Recurrent Neural Network
Transducer (RNN-T) model, which uses RNNs for information encoding instead of
Transformer encoders. The model is trained with a monotonic RNN-T loss
well-suited to frame-synchronous, streaming decoding. We present results on the
LibriSpeech dataset showing that limiting the left context for self-attention
in the Transformer layers makes decoding computationally tractable for
streaming, with only a slight degradation in accuracy. We also show that the
full attention version of our model achieves competitive performance compared
to existing LibriSpeech benchmarks for attention-based models trained with
cross-entropy loss. Our results also show that we can bridge the gap between
full attention and limited attention versions of our model by attending to a
limited number of future frames.
\\ ( https://arxiv.org/abs/2002.02562 ,  215kb)
------------------------------------------------------------------------------
\\
arXiv:2002.02735 (*cross-listing*)
Date: Fri, 7 Feb 2020 12:28:56 GMT   (113kb,D)

Title: LEAP System for SRE19 Challenge -- Improvements and Error Analysis
Authors: Shreyas Ramoji, Prashant Krishnan, Bhargavram Mysore, Prachi Singh,
  Sriram Ganapathy
Categories: eess.AS cs.CL cs.LG cs.SD
Comments: Submitted to Odyssey 2020, the Speaker and Language Recognition
  Workshop. Link to GitHub Implementation:
  https://github.com/iiscleap/NeuralPlda
\\
  The NIST Speaker Recognition Evaluation - Conversational Telephone Speech
(CTS) challenge 2019 was an open evaluation for the task of speaker
verification in challenging conditions. In this paper, we provide a detailed
account of the LEAP SRE system submitted to the CTS challenge focusing on the
novel components in the back-end system modeling. All the systems used the
time-delay neural network (TDNN) based x-vector embeddings. The x-vector system
in our SRE19 submission used a large pool of training speakers (about 14k
speakers). Following the x-vector extraction, we explored a neural network
approach to backend score computation that was optimized for a speaker
verification cost. The system combination of generative and neural PLDA models
resulted in significant improvements for the SRE evaluation dataset. We also
found additional gains for the SRE systems based on score normalization and
calibration. Subsequent to the evaluations, we have performed a detailed
analysis of the submitted systems. The analysis revealed the incremental gains
obtained for different training dataset combinations as well as the modeling
methods.
\\ ( https://arxiv.org/abs/2002.02735 ,  113kb)
------------------------------------------------------------------------------
\\
arXiv:2002.02848 (*cross-listing*)
Date: Fri, 7 Feb 2020 15:34:53 GMT   (55kb,D)

Title: Unsupervised pretraining transfers well across languages
Authors: Morgane Rivi\`ere, Armand Joulin, Pierre-Emmanuel Mazar\'e, Emmanuel
  Dupoux
Categories: eess.AS cs.CL cs.LG cs.SD
Comments: 6 pages. Accepted at ICASSP 2020. However the 2 pages of
  supplementary materials will appear only in the arxiv version
Journal-ref: ICASSP 2020
\\
  Cross-lingual and multi-lingual training of Automatic Speech Recognition
(ASR) has been extensively investigated in the supervised setting. This assumes
the existence of a parallel corpus of speech and orthographic transcriptions.
Recently, contrastive predictive coding (CPC) algorithms have been proposed to
pretrain ASR systems with unlabelled data. In this work, we investigate whether
unsupervised pretraining transfers well across languages. We show that a slight
modification of the CPC pretraining extracts features that transfer well to
other languages, being on par or even outperforming supervised pretraining.
This shows the potential of unsupervised methods for languages with few
linguistic resources.
\\ ( https://arxiv.org/abs/2002.02848 ,  55kb)
------------------------------------------------------------------------------
\\
arXiv:2002.02582 (*cross-listing*)
Date: Fri, 7 Feb 2020 01:48:13 GMT   (656kb,D)

Title: Quantifying the Value of Lateral Views in Deep Learning for Chest X-rays
Authors: Mohammad Hashir, Hadrien Bertrand and Joseph Paul Cohen
Categories: eess.IV cs.CV cs.LG stat.ML
Comments: Under review at MIDL 2020
\\
  Most deep learning models in chest X-ray prediction utilize the
posteroanterior (PA) view due to the lack of other views available. PadChest is
a large-scale chest X-ray dataset that has almost 200 labels and multiple views
available. In this work, we use PadChest to explore multiple approaches to
merging the PA and lateral views for predicting the radiological labels
associated with the X-ray image. We find that different methods of merging the
model utilize the lateral view differently. We also find that including the
lateral view increases performance for 32 labels in the dataset, while being
neutral for the others. The increase in overall performance is comparable to
the one obtained by using only the PA view with twice the amount of patients in
the training set.
\\ ( https://arxiv.org/abs/2002.02582 ,  656kb)
------------------------------------------------------------------------------
\\
arXiv:2002.02657 (*cross-listing*)
Date: Fri, 7 Feb 2020 07:46:31 GMT   (5228kb)

Title: Optimization of Structural Similarity in Mathematical Imaging
Authors: D. Otero, D. La Torre, O. Michailovich, E.R. Vrscay
Categories: math.OC cs.CV cs.NA eess.IV math.NA
\\
  It is now generally accepted that Euclidean-based metrics may not always
adequately represent the subjective judgement of a human observer. As a result,
many image processing methodologies have been recently extended to take
advantage of alternative visual quality measures, the most prominent of which
is the Structural Similarity Index Measure (SSIM). The superiority of the
latter over Euclidean-based metrics have been demonstrated in several studies.
However, being focused on specific applications, the findings of such studies
often lack generality which, if otherwise acknowledged, could have provided a
useful guidance for further development of SSIM-based image processing
algorithms. Accordingly, instead of focusing on a particular image processing
task, in this paper, we introduce a general framework that encompasses a wide
range of imaging applications in which the SSIM can be employed as a fidelity
measure. Subsequently, we show how the framework can be used to cast some
standard as well as original imaging tasks into optimization problems, followed
by a discussion of a number of novel numerical strategies for their solution.
\\ ( https://arxiv.org/abs/2002.02657 ,  5228kb)
------------------------------------------------------------------------------
\\
arXiv:2002.02763 (*cross-listing*)
Date: Thu, 30 Jan 2020 18:09:30 GMT   (728kb,D)

Title: Slipping through the net: can data science approaches help target clean
  cooking policy interventions?
Authors: Andr\'e Paul Neto-Bradley (1), Ruchi Choudhary (1 and 2), Amir Bazaz
  (3) ((1) University of Cambridge, (2) Alan Turing Institute, (3) Indian
  Institute for Human Settlements)
Categories: physics.soc-ph cs.CY stat.AP
Comments: 40 pages, 7 figures, submitted to Energy Policy
\\
  Reliance on solid biomass cooking fuels in India has negative health and
socio-economic consequences for households, yet policies aimed at promoting
uptake of LPG for cooking have not always been effective at promoting sustained
transition to cleaner cooking amongst intended beneficiaries. This paper uses a
two step approach combining predictive and descriptive analyses of the IHDS
panel dataset to identify different groups of households that switched stove
between 2004/5 and 2011/12. A tree-based ensemble machine learning predictive
analysis identifies key determinants of a switch from biomass to non-biomass
stoves. A descriptive clustering analysis is used to identify groups of
stove-switching households that follow different transition pathways. There are
three key findings of this study: Firstly non-income determinants of stove
switching do not have a linear effect on stove switching, in particular
variables on time of use and appliance ownership which offer a proxy for
household energy practices; secondly location specific factors including
region, infrastructure availability, and dwelling quality are found to be key
determinants and as a result policies must be tailored to take into account
local variations; thirdly clean cooking interventions must enact a range of
measures to address the barriers faced by households on different energy
transition pathways.
\\ ( https://arxiv.org/abs/2002.02763 ,  728kb)
------------------------------------------------------------------------------
\\
arXiv:2002.02762 (*cross-listing*)
Date: Wed, 29 Jan 2020 13:13:52 GMT   (41kb)

Title: A Categorical Semantics for Guarded Petri Nets
Authors: Fabrizio Genovese, David I. Spivak
Categories: math.CT cs.DC
Comments: 24 pages (11 appendix), 13 figures
\\
  We build on the correspondence between Petri nets and frees ymmetric strict
monoidal categories already investigated in the literature, and present a
categorical semantics for Petri nets with guards. This comes in two flavors:
Deterministic and with side-effects. Using the Grothendieck construction, we
show how the guard semantics can beinternalized in the net itself.
\\ ( https://arxiv.org/abs/2002.02762 ,  41kb)
------------------------------------------------------------------------------
\\
arXiv:1907.05055 (*cross-listing*)
Date: Thu, 11 Jul 2019 08:50:30 GMT   (251kb,D)
Date (revised v2): Thu, 6 Feb 2020 16:45:46 GMT   (330kb,D)

Title: Even maps, the Colin de~Verdi\`ere number and representations of graphs
Authors: Vojt\v{e}ch Kalu\v{z}a and Martin Tancer
Categories: math.CO cs.DM
Comments: 28 pages, 4 figures. In v2 we slightly changed one of the core
  definitions (previously "extended representation" now "semivalid
  representation"). We also use it to introduce a new graph parameter, denoted
  eta, which did not appear in v1. It allows us to establish an extended
  version of the main result showing that mu(G) is at most eta(G) which is at
  most sigma(G) for every graph G
\\
  Van der Holst and Pendavingh introduced a graph parameter $\sigma$, which
coincides with the more famous Colin de Verdi\`{e}re graph parameter $\mu$ for
small values. However, the definition of $\sigma$ is much more
geometric/topological directly reflecting embeddability properties of the
graph. They proved $\mu(G) \leq \sigma(G) + 2$ and conjectured $\mu(G) \leq
\sigma(G)$ for any graph $G$. We confirm this conjecture. As far as we know,
this is the first topological upper bound on $\mu(G)$ which is, in general,
tight.
  Equality between $\mu$ and $\sigma$ does not hold in general as van der Holst
and Pendavingh showed that there is a graph $G$ with $\mu(G) \leq 18$ and
$\sigma(G)\geq 20$. We show that the gap appears on much smaller values,
namely, we exhibit a graph $H$ for which $\mu(H)\leq 7$ and $\sigma(H)\geq 8$.
We also prove that, in general, the gap can be large: The incidence graphs
$H_q$ of finite projective planes of order $q$ satisfy $\mu(H_q) \in
O(q^{3/2})$ and $\sigma(H_q) \geq q^2$.
\\ ( https://arxiv.org/abs/1907.05055 ,  330kb)
------------------------------------------------------------------------------
\\
arXiv:2002.02769 (*cross-listing*)
Date: Wed, 5 Feb 2020 21:25:03 GMT   (1507kb,D)

Title: Limits of multiplicative inhomogeneous random graphs and L\'evy trees:
  Limit theorems
Authors: Nicolas Broutin, Thomas Duquesne, and Minmin Wang
Categories: math.PR cs.DM math.CO
Comments: 81 pages. arXiv admin note: substantial text overlap with
  arXiv:1804.05871
\\
  We consider a natural model of inhomogeneous random graphs that extends the
classical Erd\H os-R\'enyi graphs and shares a close connection with the
multiplicative coalescence, as pointed out by Aldous [AOP 1997]. In this model,
the vertices are assigned weights that govern their tendency to form edges. It
is by looking at the asymptotic distributions of the masses (sum of the
weights) of the connected components of these graphs that Aldous and Limic [EJP
1998] have identified the entrance boundary of the multiplicative coalescence,
which is intimately related to the excursion lengths of certain L\'evy-type
processes. We, instead, look at the metric structure of these components and
prove their Gromov-Hausdorff-Prokhorov convergence to a class of random compact
measured metric spaces that have been introduced in a companion paper. Our
asymptotic regimes relate directly to the general convergence condition
appearing in the work of Aldous and Limic. Our techniques provide a unified
approach for this general "critical" regime, and relies upon two key
ingredients: an encoding of the graph by some L\'evy process as well as an
embedding of its connected components into Galton-Watson forests. This
embedding transfers asymptotically into an embedding of the limit objects into
a forest of L\'evy trees, which allows us to give an explicit construction of
the limit objects from the excursions of the L\'evy-type process. The mains
results combined with the ones in the other paper allow us to extend and
complement several previous results that had been obtained via regime-specific
proofs, for instance: the case of Erd\H os-R\'enyi random graphs obtained by
Addario-Berry, Goldschmidt and B. [PTRF 2012], the asymptotic homogeneous case
as studied by Bhamidi, Sen and Wang [PTRF 2017], or the power-law case as
considered by Bhamidi, Sen and van der Hofstad [PTRF 2018].
\\ ( https://arxiv.org/abs/2002.02769 ,  1507kb)
------------------------------------------------------------------------------
\\
arXiv:2002.02801 (*cross-listing*)
Date: Wed, 29 Jan 2020 03:00:22 GMT   (1718kb,D)

Title: Multiple Access in Dynamic Cell-Free Networks: Outage Performance and
  Deep Reinforcement Learning-Based Design
Authors: Yasser Al-Eryani, Mohamed Akrout, and Ekram Hossain
Categories: eess.SP cs.IT cs.LG math.IT stat.ML
Comments: This article has been submitted to IEEE for possible publication
\\
  In future cell-free (or cell-less) wireless networks, a large number of
devices in a geographical area will be served simultaneously in non-orthogonal
multiple access scenarios by a large number of distributed access points (APs),
which coordinate with a centralized processing pool. For such a centralized
cell-free network with static predefined beamforming design, we first derive a
closed-form expression of the uplink per-user probability of outage. To
significantly reduce the complexity of joint processing of users' signals in
presence of a large number of devices and APs, we propose a novel dynamic
cell-free network architecture. In this architecture, the distributed APs are
partitioned (i.e. clustered) among a set of subgroups with each subgroup acting
as a virtual AP equipped with a distributed antenna system (DAS). The
conventional static cell-free network is a special case of this dynamic
cell-free network when the cluster size is one. For this dynamic cell-free
network, we propose a successive interference cancellation (SIC)-enabled signal
detection method and an inter-user-interference (IUI)-aware DAS's receive
diversity combining scheme. We then formulate the general problem of clustering
APs and designing the beamforming vectors with an objective to maximizing the
sum rate or maximizing the minimum rate. To this end, we propose a hybrid deep
reinforcement learning (DRL) model, namely, a deep deterministic policy
gradient (DDPG)-deep double Q-network (DDQN) model, to solve the optimization
problem for online implementation with low complexity. The DRL model for
sum-rate optimization significantly outperforms that for maximizing the minimum
rate in terms of average per-user rate performance. Also, in our system
setting, the proposed DDPG-DDQN scheme is found to achieve around $78\%$ of the
rate achievable through an exhaustive search-based design.
\\ ( https://arxiv.org/abs/2002.02801 ,  1718kb)
------------------------------------------------------------------------------
\\
arXiv:2002.02939 (*cross-listing*)
Date: Fri, 7 Feb 2020 18:16:46 GMT   (3071kb,D)

Title: Phase Retrieval for Partially Coherent Observations
Authors: Jonas Kornprobst, Alexander Paulus, Josef Knapp, Thomas F. Eibert
Categories: eess.SP cs.IT cs.NA math.IT math.NA math.OC
\\
  Phase retrieval is in general a non-convex and non-linear task and the
corresponding algorithms struggle with the problem of local minima. We consider
the case where portions of the measurement samples are coherently linked to
each other - which is a reasonable assumption for our objective of antenna
measurements. We propose several formulations of the corresponding phase
retrieval problem. The problem may even be reduced to a linear system of
equations similar to an eigenvalue problem and to the search for a unique
non-trivial null-space vector. Accurate phase reconstruction for partially
coherent observations is, thus, possible by a reliable solution process where
we are able to judge the solution quality. Under ideal, noise-free conditions,
the required sampling density is less than two times the number of unknowns.
Noise and other observation errors increase this value slightly. Simulations
for Gaussian random matrices and for antenna measurement scenarios demonstrate
that reliable phase reconstruction is possible with the presented approach.
\\ ( https://arxiv.org/abs/2002.02939 ,  3071kb)
------------------------------------------------------------------------------
\\
arXiv:2002.02247 (*cross-listing*)
Date: Thu, 6 Feb 2020 13:25:26 GMT   (63kb)

Title: Almost Sure Convergence of Dropout Algorithms for Neural Networks
Authors: Albert Senen-Cerda, Jaron Sanders
Categories: math.OC cs.LG math.PR
Comments: 20 pages, 2 figures
\\
  We investigate the convergence and convergence rate of stochastic training
algorithms for Neural Networks (NNs) that, over the years, have spawned from
Dropout (Hinton et al., 2012). Modeling that neurons in the brain may not fire,
dropout algorithms consist in practice of multiplying the weight matrices of a
NN component-wise by independently drawn random matrices with $\{0,1\}$-valued
entries during each iteration of the Feedforward-Backpropagation algorithm.
This paper presents a probability theoretical proof that for any NN topology
and differentiable polynomially bounded activation functions, if we project the
NN's weights into a compact set and use a dropout algorithm, then the weights
converge to a unique stationary set of a projected system of Ordinary
Differential Equations (ODEs). We also establish an upper bound on the rate of
convergence of Gradient Descent (GD) on the limiting ODEs of dropout algorithms
for arborescences (a class of trees) of arbitrary depth and with linear
activation functions.
\\ ( https://arxiv.org/abs/2002.02247 ,  63kb)
------------------------------------------------------------------------------
\\
arXiv:2002.02497 (*cross-listing*)
Date: Thu, 6 Feb 2020 20:07:54 GMT   (1321kb,D)

Title: On the limits of cross-domain generalization in automated X-ray
  prediction
Authors: Joseph Paul Cohen and Mohammad Hashir and Rupert Brooks and Hadrien
  Bertrand
Categories: eess.IV cs.LG q-bio.QM stat.ML
Comments: Submitted to MIDL2020
\\
  This large scale study focuses on quantifying what X-rays diagnostic
prediction tasks generalize well across multiple different datasets. We present
evidence that the issue of generalization is not due to a shift in the images
but instead a shift in the labels. We study the cross-domain performance,
agreement between models, and model representations. We find interesting
discrepancies between performance and agreement where models which both achieve
good performance disagree in their predictions as well as models which agree
yet achieve poor performance. We also test for concept similarity by
regularizing a network to group tasks across multiple datasets together and
observe variation across the tasks.
\\ ( https://arxiv.org/abs/2002.02497 ,  1321kb)
------------------------------------------------------------------------------
\\
arXiv:2002.02521 (*cross-listing*)
Date: Thu, 6 Feb 2020 21:51:39 GMT   (7578kb,D)

Title: Enhancement of shock-capturing methods via machine learning
Authors: Ben Stevens, Tim Colonius
Categories: physics.comp-ph cs.LG cs.NA cs.NE math.NA physics.flu-dyn
Comments: 10 pages, 11 figures. Under review for TCFD
\\
  In recent years, machine learning has been used to create data-driven
solutions to problems for which an algorithmic solution is intractable, as well
as fine-tuning existing algorithms. This research applies machine learning to
the development of an improved finite-volume method for simulating PDEs with
discontinuous solutions. Shock capturing methods make use of nonlinear
switching functions that are not guaranteed to be optimal. Because data can be
used to learn nonlinear relationships, we train a neural network to improve the
results of a fifth-order WENO method. We post-process the outputs of the neural
network to guarantee that the method is consistent. The training data consists
of the exact mapping between cell averages and interpolated values for a set of
integrable functions that represent waveforms we would expect to see while
simulating a PDE. We demonstrate our method on linear advection of a
discontinuous function, the inviscid Burgers' equation, and the 1-D Euler
equations. For the latter, we examine the Shu-Osher model problem for
turbulence-shockwave interactions. We find that our method outperforms WENO in
simulations where the numerical solution becomes overly diffused due to
numerical viscosity.
\\ ( https://arxiv.org/abs/2002.02521 ,  7578kb)
------------------------------------------------------------------------------
\\
arXiv:2002.02525 (*cross-listing*)
Date: Thu, 6 Feb 2020 22:08:36 GMT   (101kb,D)

Title: Interpolation under latent factor regression models
Authors: Florentina Bunea, Seth Strimas-Mackey, Marten Wegkamp
Categories: stat.ML cs.LG math.ST stat.TH
Comments: 47 pages, 1 figure
\\
  This work studies finite-sample properties of the risk of the minimum-norm
interpolating predictor in high-dimensional regression models. If the effective
rank of the covariance matrix $\Sigma$ of the $p$ regression features is much
larger than the sample size $n$, we show that the min-norm interpolating
predictor is not desirable, as its risk approaches the risk of predicting the
response by $0$. However, our detailed finite sample analysis reveals,
surprisingly, that this behavior is not present when the regression response
and the features are jointly low-dimensional, and follow a widely used factor
regression model. Within this popular model class, and when the effective rank
of $\Sigma$ is smaller than $n$, while still allowing for $p \gg n$, both the
bias and the variance terms of the excess risk can be controlled, and the risk
of the minimum-norm interpolating predictor approaches optimal benchmarks.
Moreover, through a detailed analysis of the bias term, we exhibit model
classes under which our upper bound on the excess risk approaches zero, while
the corresponding upper bound in the recent work arXiv:1906.11300v3 diverges.
Furthermore, we show that minimum-norm interpolating predictors analyzed under
factor regression models, despite being model-agnostic, can have similar risk
to model-assisted predictors based on principal components regression, in the
high-dimensional regime.
\\ ( https://arxiv.org/abs/2002.02525 ,  101kb)
------------------------------------------------------------------------------
\\
arXiv:2002.02527 (*cross-listing*)
Date: Fri, 17 Jan 2020 11:00:32 GMT   (120kb,D)

Title: Synthetic Magnetic Resonance Images with Generative Adversarial Networks
Authors: Antoine Delplace
Categories: eess.IV cs.LG stat.ML
Comments: 4 pages, 1 figure, UQ Conference paper
\\
  Data augmentation is essential for medical research to increase the size of
training datasets and achieve better results. In this work, we experiment three
GAN architectures with different loss functions to generate new brain MRIs. The
results show the importance of hyperparameter tuning and the use of mini-batch
similarity layer in the Discriminator and gradient penalty in the loss function
to achieve convergence with high quality and realism. Moreover, huge
computation time is needed to generate indistinguishable images from the
original dataset.
\\ ( https://arxiv.org/abs/2002.02527 ,  120kb)
------------------------------------------------------------------------------
\\
arXiv:2002.02530 (*cross-listing*)
Date: Fri, 31 Jan 2020 19:31:23 GMT   (2140kb,D)

Title: Machine learning on DNA-encoded libraries: A new paradigm for
  hit-finding
Authors: Kevin McCloskey, Eric A. Sigel, Steven Kearnes, Ling Xue, Xia Tian,
  Dennis Moccia, Diana Gikunju, Sana Bazzaz, Betty Chan, Matthew A. Clark, John
  W. Cuozzo, Marie-Aude Gui\'e, John P. Guilinger, Christelle Huguet,
  Christopher D. Hupp, Anthony D. Keefe, Christopher J. Mulhern, Ying Zhang,
  and Patrick Riley
Categories: q-bio.QM cs.LG
\\
  DNA-encoded small molecule libraries (DELs) have enabled discovery of novel
inhibitors for many distinct protein targets of therapeutic value through
screening of libraries with up to billions of unique small molecules. We
demonstrate a new approach applying machine learning to DEL selection data by
identifying active molecules from a large commercial collection and a virtual
library of easily synthesizable compounds. We train models using only DEL
selection data and apply automated or automatable filters with chemist review
restricted to the removal of molecules with potential for instability or
reactivity. We validate this approach with a large prospective study (nearly
2000 compounds tested) across three diverse protein targets: sEH (a hydrolase),
ER{\alpha} (a nuclear receptor), and c-KIT (a kinase). The approach is
effective, with an overall hit rate of {\sim}30% at 30 {\textmu}M and discovery
of potent compounds (IC50 <10 nM) for every target. The model makes useful
predictions even for molecules dissimilar to the original DEL and the compounds
identified are diverse, predominantly drug-like, and different from known
ligands. Collectively, the quality and quantity of DEL selection data; the
power of modern machine learning methods; and access to large, inexpensive,
commercially-available libraries creates a powerful new approach for hit
finding.
\\ ( https://arxiv.org/abs/2002.02530 ,  2140kb)
------------------------------------------------------------------------------
\\
arXiv:2002.02533 (*cross-listing*)
Date: Mon, 3 Feb 2020 19:50:31 GMT   (95kb)

Title: Understanding the dynamics of message passing algorithms: a free
  probability heuristics
Authors: Manfred Opper and Burak \c{C}akmak
Categories: cond-mat.stat-mech cond-mat.dis-nn cs.LG stat.ML
Comments: 11 pages, 2 figures. Presented at the conference "Random Matrix
  Theory: Applications in the Information Era'' 2019 Krak\'{o}w
\\
  We use freeness assumptions of random matrix theory to analyze the dynamical
behavior of inference algorithms for probabilistic models with dense coupling
matrices in the limit of large systems. For a toy Ising model, we are able to
recover previous results such as the property of vanishing effective memories
and the analytical convergence rate of the algorithm.
\\ ( https://arxiv.org/abs/2002.02533 ,  95kb)
------------------------------------------------------------------------------
\\
arXiv:2002.02534 (*cross-listing*)
Date: Wed, 5 Feb 2020 12:55:28 GMT   (337kb,D)

Title: Fast inference of Boosted Decision Trees in FPGAs for particle physics
Authors: Sioni Summers, Giuseppe Di Guglielmo, Javier Duarte, Philip Harris,
  Duc Hoang, Sergo Jindariani, Edward Kreinar, Vladimir Loncar, Jennifer
  Ngadiuba, Maurizio Pierini, Dylan Rankin, Nhan Tran, Zhenbin Wu
Categories: physics.comp-ph astro-ph.IM cs.LG hep-ex
\\
  We describe the implementation of Boosted Decision Trees in the hls4ml
library, which allows the conversion of a trained model into an FPGA firmware
through an automatic highlevel-synthesis conversion. Thanks to its full on-chip
implementation, hls4ml allows performance of inference of Boosted Decision Tree
models with extremely low latency. A benchmark model achieving near state of
the art classification performance is implemented on an FPGA with 60 ns
inference latency, using 8% of the Look Up Tables of the target device. This
solution is compatible with the needs of fast real-time processing such as the
L1 trigger system of a typical collider experiment.
\\ ( https://arxiv.org/abs/2002.02534 ,  337kb)
------------------------------------------------------------------------------
\\
arXiv:2002.02568 (*cross-listing*)
Date: Fri, 7 Feb 2020 00:38:03 GMT   (4369kb,D)

Title: High Temporal Resolution Rainfall Runoff Modelling Using
  Long-Short-Term-Memory (LSTM) Networks
Authors: Wei Li (1), Amin Kiaghadi (1), Clint N. Dawson (1) ((1) Oden Institute
  for Computational Engineering and Sciences, The University of Texas at
  Austin, Austin, TX)
Categories: eess.SP cs.LG stat.ML
\\
  Accurate and efficient models for rainfall runoff (RR) simulations are
crucial for flood risk management. Most rainfall models in use today are
process-driven; i.e. they solve either simplified empirical formulas or some
variation of the St. Venant (shallow water) equations. With the development of
machine-learning techniques, we may now be able to emulate rainfall models
using, for example, neural networks. In this study, a data-driven RR model
using a sequence-to-sequence Long-short-Term-Memory (LSTM) network was
constructed. The model was tested for a watershed in Houston, TX, known for
severe flood events. The LSTM network's capability in learning long-term
dependencies between the input and output of the network allowed modeling RR
with high resolution in time (15 minutes). Using 10-years precipitation from
153 rainfall gages and river channel discharge data (more than 5.3 million data
points), and by designing several numerical tests the developed model
performance in predicting river discharge was tested. The model results were
also compared with the output of a process-driven model Gridded Surface
Subsurface Hydrologic Analysis (GSSHA). Moreover, physical consistency of the
LSTM model was explored. The model results showed that the LSTM model was able
to efficiently predict discharge and achieve good model performance. When
compared to GSSHA, the data-driven model was more efficient and robust in terms
of prediction and calibration. Interestingly, the performance of the LSTM model
improved (test Nash-Sutcliffe model efficiency from 0.666 to 0.942) when a
selected subset of rainfall gages based on the model performance, were used as
input instead of all rainfall gages.
\\ ( https://arxiv.org/abs/2002.02568 ,  4369kb)
------------------------------------------------------------------------------
\\
arXiv:2002.02574 (*cross-listing*)
Date: Fri, 7 Feb 2020 00:58:49 GMT   (173kb)

Title: The Power of Linear Controllers in LQR Control
Authors: Gautam Goel, Babak Hassibi
Categories: math.OC cs.LG
\\
  The Linear Quadratic Regulator (LQR) framework considers the problem of
regulating a linear dynamical system perturbed by environmental noise. We
compute the policy regret between three distinct control policies: i) the
optimal online policy, whose linear structure is given by the Ricatti
equations; ii) the optimal offline linear policy, which is the best linear
state feedback policy given the noise sequence; and iii) the optimal offline
policy, which selects the globally optimal control actions given the noise
sequence. We fully characterize the optimal offline policy and show that it has
a recursive form in terms of the optimal online policy and future disturbances.
We also show that cost of the optimal offline linear policy converges to the
cost of the optimal online policy as the time horizon grows large, and
consequently the optimal offline linear policy incurs linear regret relative to
the optimal offline policy, even in the optimistic setting where the noise is
drawn i.i.d from a known distribution. Although we focus on the setting where
the noise is stochastic, our results also imply new lower bounds on the policy
regret achievable when the noise is chosen by an adaptive adversary.
\\ ( https://arxiv.org/abs/2002.02574 ,  173kb)
------------------------------------------------------------------------------
\\
arXiv:2002.02584 (*cross-listing*)
Date: Fri, 7 Feb 2020 01:52:21 GMT   (43kb,D)

Title: Explicit Mean-Square Error Bounds for Monte-Carlo and Linear Stochastic
  Approximation
Authors: Shuhang Chen, Adithya M. Devraj, Ana Bu\v{s}i\'c, Sean Meyn
Categories: math.PR cs.LG cs.SY eess.SY math.OC math.ST stat.ML stat.TH
\\
  This paper concerns error bounds for recursive equations subject to Markovian
disturbances. Motivating examples abound within the fields of Markov chain
Monte Carlo (MCMC) and Reinforcement Learning (RL), and many of these
algorithms can be interpreted as special cases of stochastic approximation
(SA). It is argued that it is not possible in general to obtain a Hoeffding
bound on the error sequence, even when the underlying Markov chain is
reversible and geometrically ergodic, such as the M/M/1 queue. This is
motivation for the focus on mean square error bounds for parameter estimates.
It is shown that mean square error achieves the optimal rate of $O(1/n)$,
subject to conditions on the step-size sequence. Moreover, the exact constants
in the rate are obtained, which is of great value in algorithm design.
\\ ( https://arxiv.org/abs/2002.02584 ,  43kb)
------------------------------------------------------------------------------
\\
arXiv:2002.02601 (*cross-listing*)
Date: Fri, 7 Feb 2020 03:11:44 GMT   (518kb,D)

Title: Bidimensional linked matrix factorization for pan-omics pan-cancer
  analysis
Authors: Eric F. Lock, Jun Young Park, and Katherine A. Hoadley
Categories: stat.ML cs.LG q-bio.QM stat.AP stat.ME
Comments: 46 pages, 5 figures
\\
  Several modern applications require the integration of multiple large data
matrices that have shared rows and/or columns. For example, cancer studies that
integrate multiple omics platforms across multiple types of cancer, pan-omics
pan-cancer analysis, have extended our knowledge of molecular heterogenity
beyond what was observed in single tumor and single platform studies. However,
these studies have been limited by available statistical methodology. We
propose a flexible approach to the simultaneous factorization and decomposition
of variation across such bidimensionally linked matrices, BIDIFAC+. This
decomposes variation into a series of low-rank components that may be shared
across any number of row sets (e.g., omics platforms) or column sets (e.g.,
cancer types). This builds on a growing literature for the factorization and
decomposition of linked matrices, which has primarily focused on multiple
matrices that are linked in one dimension (rows or columns) only. Our objective
function extends nuclear norm penalization, is motivated by random matrix
theory, gives an identifiable decomposition under relatively mild conditions,
and can be shown to give the mode of a Bayesian posterior distribution. We
apply BIDIFAC+ to pan-omics pan-cancer data from TCGA, identifying shared and
specific modes of variability across 4 different omics platforms and 29
different cancer types.
\\ ( https://arxiv.org/abs/2002.02601 ,  518kb)
------------------------------------------------------------------------------
\\
arXiv:2002.02610 (*cross-listing*)
Date: Fri, 7 Feb 2020 03:47:15 GMT   (5818kb,D)

Title: Statistical Inference in Heterogeneous Block Model
Authors: Majid Noroozi and Marianna Pensky
Categories: stat.ML cs.LG math.ST stat.TH
Comments: 28 pages, 4 figures
\\
  There exist various types of network block models such as the Stochastic
Block Model (SBM), the Degree Corrected Block Model (DCBM), and the Popularity
Adjusted Block Model (PABM). While this leads to a variety of choices, the
block models do not have a nested structure. In addition, there is a
substantial jump in the number of parameters from the DCBM to the PABM. The
objective of this paper is formulation of a hierarchy of block model which does
not rely on arbitrary identifiability conditions, treats the SBM, the DCBM and
the PABM as its particular cases with specific parameter values and, in
addition, allows a multitude of versions that are more complicated than DCBM
but have fewer unknown parameters than the PABM. The latter allows one to carry
out clustering and estimation without preliminary testing to see which block
model is really true.
\\ ( https://arxiv.org/abs/2002.02610 ,  5818kb)
------------------------------------------------------------------------------
\\
arXiv:2002.02618 (*cross-listing*)
Date: Fri, 7 Feb 2020 04:39:09 GMT   (167kb,D)

Title: Finding Quantum Critical Points with Neural-Network Quantum States
Authors: Remmy Zen, Long My, Ryan Tan, Frederic Hebert, Mario Gattobigio,
  Christian Miniatura, Dario Poletti, Stephane Bressan
Categories: physics.comp-ph cond-mat.dis-nn cs.LG quant-ph
Comments: 19 pages, 12 figures, extended version of an accepted paper at the
  24th European Conference on Artificial Intelligence (ECAI 2020)
\\
  Finding the precise location of quantum critical points is of particular
importance to characterise quantum many-body systems at zero temperature.
However, quantum many-body systems are notoriously hard to study because the
dimension of their Hilbert space increases exponentially with their size.
Recently, machine learning tools known as neural-network quantum states have
been shown to effectively and efficiently simulate quantum many-body systems.
We present an approach to finding the quantum critical points of the quantum
Ising model using neural-network quantum states, analytically constructed
innate restricted Boltzmann machines, transfer learning and unsupervised
learning. We validate the approach and evaluate its efficiency and
effectiveness in comparison with other traditional approaches.
\\ ( https://arxiv.org/abs/2002.02618 ,  167kb)
------------------------------------------------------------------------------
\\
arXiv:2002.02620 (*cross-listing*)
Date: Fri, 7 Feb 2020 04:46:14 GMT   (336kb)

Title: Constructing a variational family for nonlinear state-space models
Authors: Jarrad Courts, Christopher Renton, Thomas B. Sch\"on and Adrian Wills
Categories: stat.ML cs.LG
\\
  We consider the problem of maximum likelihood parameter estimation for
nonlinear state-space models. This is an important, but challenging problem.
This challenge stems from the intractable multidimensional integrals that must
be solved in order to compute, and maximise, the likelihood. Here we present a
new variational family where variational inference is used in combination with
tractable approximations of these integrals resulting in a deterministic
optimisation problem. Our developments also include a novel means for
approximating the smoothed state distributions. We demonstrate our construction
on several examples and show that they perform well compared to state of the
art methods on real data-sets.
\\ ( https://arxiv.org/abs/2002.02620 ,  336kb)
------------------------------------------------------------------------------
\\
arXiv:2002.02751 (*cross-listing*)
Date: Thu, 16 Jan 2020 00:48:27 GMT   (658kb)

Title: Prediction of Discharge Capacity of Labyrinth Weir with Gene Expression
  Programming
Authors: Hossein Bonakdari, Isa Ebtehaj, Bahram Gharabaghi, Ali Sharifi, Amir
  Mosavi
Categories: physics.flu-dyn cs.LG cs.NE
Comments: 16 pages, 6 figures
MSC-class: 68T01
\\
  This paper proposes a model based on gene expression programming for
predicting the discharge coefficient of triangular labyrinth weirs. The
parameters influencing discharge coefficient prediction were first examined and
presented as crest height ratio to the head over the crest of the weir, a crest
length of water to channel width, a crest length of water to the head over the
crest of the weir, Froude number and vertex angle dimensionless parameters.
Different models were then presented using sensitivity analysis in order to
examine each of the dimensionless parameters presented in this study. In
addition, an equation was presented through the use of nonlinear regression
(NLR) for the purpose of comparison with GEP. The results of the studies
conducted by using different statistical indexes indicated that GEP is more
capable than NLR. This is to the extent that GEP predicts the discharge
coefficient with an average relative error of approximately 2.5% in such a
manner that the predicted values have less than 5% relative error in the worst
model.
\\ ( https://arxiv.org/abs/2002.02751 ,  658kb)
------------------------------------------------------------------------------
\\
arXiv:2002.02779 (*cross-listing*)
Date: Tue, 4 Feb 2020 02:57:08 GMT   (796kb,D)

Title: Generating Digital Twins with Multiple Sclerosis Using Probabilistic
  Neural Networks
Authors: Jonathan R. Walsh, Aaron M. Smith, Yannick Pouliot, David Li-Bland,
  Anton Loukianov, and Charles K. Fisher
Categories: stat.ML cs.LG q-bio.QM
\\
  Multiple Sclerosis (MS) is a neurodegenerative disorder characterized by a
complex set of clinical assessments. We use an unsupervised machine learning
model called a Conditional Restricted Boltzmann Machine (CRBM) to learn the
relationships between covariates commonly used to characterize subjects and
their disease progression in MS clinical trials. A CRBM is capable of
generating digital twins, which are simulated subjects having the same baseline
data as actual subjects. Digital twins allow for subject-level statistical
analyses of disease progression. The CRBM is trained using data from 2395
subjects enrolled in the placebo arms of clinical trials across the three
primary subtypes of MS. We discuss how CRBMs are trained and show that digital
twins generated by the model are statistically indistinguishable from their
actual subject counterparts along a number of measures.
\\ ( https://arxiv.org/abs/2002.02779 ,  796kb)
------------------------------------------------------------------------------
\\
arXiv:2002.02797 (*cross-listing*)
Date: Thu, 6 Feb 2020 16:00:03 GMT   (3586kb,D)

Title: Variational Depth Search in ResNets
Authors: Javier Antor\'an, James Urquhart Allingham, Jos\'e Miguel
  Hern\'andez-Lobato
Categories: stat.ML cs.LG
\\
  One-shot neural architecture search allows joint learning of weights and
network architecture, reducing computational cost. We limit our search space to
the depth of residual networks and formulate an analytically tractable
variational objective that allows for obtaining an unbiased approximate
posterior over depths in one-shot. We propose a heuristic to prune our networks
based on this distribution. We compare our proposed method against manual
search over network depths on the MNIST, Fashion-MNIST, SVHN datasets. We find
that pruned networks do not incur a loss in predictive performance, obtaining
accuracies competitive with unpruned networks. Marginalising over depth allows
us to obtain better-calibrated test-time uncertainty estimates than regular
networks, in a single forward pass.
\\ ( https://arxiv.org/abs/2002.02797 ,  3586kb)
------------------------------------------------------------------------------
\\
arXiv:2002.02798 (*cross-listing*)
Date: Fri, 7 Feb 2020 14:15:02 GMT   (338kb,D)

Title: How to train your neural ODE
Authors: Chris Finlay, J\"orn-Henrik Jacobsen, Levon Nurbekyan, Adam M Oberman
Categories: stat.ML cs.LG
\\
  Training neural ODEs on large datasets has not been tractable due to the
necessity of allowing the adaptive numerical ODE solver to refine its step size
to very small values. In practice this leads to dynamics equivalent to many
hundreds or even thousands of layers. In this paper, we overcome this apparent
difficulty by introducing a theoretically-grounded combination of both optimal
transport and stability regularizations which encourage neural ODEs to prefer
simpler dynamics out of all the dynamics that solve a problem well. Simpler
dynamics lead to faster convergence and to fewer discretizations of the solver,
considerably decreasing wall-clock time without loss in performance. Our
approach allows us to train neural ODE based generative models to the same
performance as the unregularized dynamics in just over a day on one GPU,
whereas unregularized dynamics can take up to 4-6 days of training time on
multiple GPUs. This brings neural ODEs significantly closer to practical
relevance in large-scale applications.
\\ ( https://arxiv.org/abs/2002.02798 ,  338kb)
------------------------------------------------------------------------------
\\
arXiv:2002.02805 (*cross-listing*)
Date: Thu, 6 Feb 2020 16:39:44 GMT   (743kb,D)

Title: Short Term Blood Glucose Prediction based on Continuous Glucose
  Monitoring Data
Authors: Ali Mohebbi, Alexander R. Johansen, Nicklas Hansen, Peter E.
  Christensen, Jens M. Tarp, Morten L. Jensen, Henrik Bengtsson and Morten
  M{\o}rup
Categories: eess.SP cs.LG stat.ML
Comments: 6 pages, 4 figures
\\
  Continuous Glucose Monitoring (CGM) has enabled important opportunities for
diabetes management. This study explores the use of CGM data as input for
digital decision support tools. We investigate how Recurrent Neural Networks
(RNNs) can be used for Short Term Blood Glucose (STBG) prediction and compare
the RNNs to conventional time-series forecasting using Autoregressive
Integrated Moving Average (ARIMA). A prediction horizon up to 90 min into the
future is considered. In this context, we evaluate both population-based and
patient-specific RNNs and contrast them to patient-specific ARIMA models and a
simple baseline predicting future observations as the last observed. We find
that the population-based RNN model is the best performing model across the
considered prediction horizons without the need of patient-specific data. This
demonstrates the potential of RNNs for STBG prediction in diabetes patients
towards detecting/mitigating severe events in the STBG, in particular
hypoglycemic events. However, further studies are needed in regards to the
robustness and practical use of the investigated STBG prediction models.
\\ ( https://arxiv.org/abs/2002.02805 ,  743kb)
------------------------------------------------------------------------------
\\
arXiv:2002.02820 (*cross-listing*)
Date: Fri, 7 Feb 2020 14:48:16 GMT   (1563kb,D)

Title: Noisy-Input Entropy Search for Efficient Robust Bayesian Optimization
Authors: Lukas P. Fr\"ohlich, Edgar D. Klenske, Julia Vinogradska, Christian
  Daniel, Melanie N. Zeilinger
Categories: stat.ML cs.LG
\\
  We consider the problem of robust optimization within the well-established
Bayesian optimization (BO) framework. While BO is intrinsically robust to noisy
evaluations of the objective function, standard approaches do not consider the
case of uncertainty about the input parameters. In this paper, we propose
Noisy-Input Entropy Search (NES), a novel information-theoretic acquisition
function that is designed to find robust optima for problems with both input
and measurement noise. NES is based on the key insight that the robust
objective in many cases can be modeled as a Gaussian process, however, it
cannot be observed directly. We evaluate NES on several benchmark problems from
the optimization literature and from engineering. The results show that NES
reliably finds robust optima, outperforming existing methods from the
literature on all benchmarks.
\\ ( https://arxiv.org/abs/2002.02820 ,  1563kb)
------------------------------------------------------------------------------
\\
arXiv:2002.02870 (*cross-listing*)
Date: Fri, 7 Feb 2020 16:08:19 GMT   (1810kb)

Title: The Effect of Data Augmentation on Classification of Atrial Fibrillation
  in Short Single-Lead ECG Signals Using Deep Neural Networks
Authors: Faezeh Nejati Hatamian, Nishant Ravikumar, Sulaiman Vesal, Felix P.
  Kemeth, Matthias Struck, Andreas Maier
Categories: eess.SP cs.LG stat.ML
\\
  Cardiovascular diseases are the most common cause of mortality worldwide.
Detection of atrial fibrillation (AF) in the asymptomatic stage can help
prevent strokes. It also improves clinical decision making through the delivery
of suitable treatment such as, anticoagulant therapy, in a timely manner. The
clinical significance of such early detection of AF in electrocardiogram (ECG)
signals has inspired numerous studies in recent years, of which many aim to
solve this task by leveraging machine learning algorithms. ECG datasets
containing AF samples, however, usually suffer from severe class imbalance,
which if unaccounted for, affects the performance of classification algorithms.
Data augmentation is a popular solution to tackle this problem.
  In this study, we investigate the impact of various data augmentation
algorithms, e.g., oversampling, Gaussian Mixture Models (GMMs) and Generative
Adversarial Networks (GANs), on solving the class imbalance problem. These
algorithms are quantitatively and qualitatively evaluated, compared and
discussed in detail. The results show that deep learning-based AF signal
classification methods benefit more from data augmentation using GANs and GMMs,
than oversampling. Furthermore, the GAN results in circa $3\%$ better AF
classification accuracy in average while performing comparably to the GMM in
terms of f1-score.
\\ ( https://arxiv.org/abs/2002.02870 ,  1810kb)
------------------------------------------------------------------------------
\\
arXiv:2002.02881 (*cross-listing*)
Date: Fri, 7 Feb 2020 16:33:31 GMT   (2819kb,D)

Title: Low Rank Saddle Free Newton: Algorithm and Analysis
Authors: Thomas O'Leary-Roseberry, Nick Alger, Omar Ghattas
Categories: math.OC cs.LG cs.NA math.NA
\\
  Many tasks in engineering fields and machine learning involve minimizing a
high dimensional non-convex function. The existence of saddle points poses a
central challenge in practice. The Saddle Free Newton (SFN) algorithm can
rapidly escape high dimensional saddle points by using the absolute value of
the Hessian of the empirical risk function. In SFN, a Lanczos type procedure is
used to approximate the absolute value of the Hessian. Motivated by recent
empirical works that note neural network training Hessians are typically low
rank, we propose using approximation via scalable randomized low rank methods.
Such factorizations can be efficiently inverted via Sherman Morrison Woodbury
formula. We derive bounds for convergence rates in expectation for a stochastic
version of the algorithm, which quantify errors incurred in subsampling as well
as in approximating the Hessian via low rank factorization. We test the method
on standard neural network training benchmark problems: MNIST and CIFAR10.
Numerical results demonstrate that in addition to avoiding saddle points, the
method can converge faster than first order methods, and the Hessian can be
subsampled significantly relative to the gradient and retain superior
performance for the method.
\\ ( https://arxiv.org/abs/2002.02881 ,  2819kb)
------------------------------------------------------------------------------
\\
arXiv:2002.02882 (*cross-listing*)
Date: Fri, 7 Feb 2020 16:33:34 GMT   (30kb)

Title: Ill-Posedness and Optimization Geometry for Nonlinear Neural Network
  Training
Authors: Thomas O'Leary-Roseberry, Omar Ghattas
Categories: math.OC cs.LG cs.NE
\\
  In this work we analyze the role nonlinear activation functions play at
stationary points of dense neural network training problems. We consider a
generic least squares loss function training formulation. We show that the
nonlinear activation functions used in the network construction play a critical
role in classifying stationary points of the loss landscape. We show that for
shallow dense networks, the nonlinear activation function determines the
Hessian nullspace in the vicinity of global minima (if they exist), and
therefore determines the ill-posedness of the training problem. Furthermore,
for shallow nonlinear networks we show that the zeros of the activation
function and its derivatives can lead to spurious local minima, and discuss
conditions for strict saddle points. We extend these results to deep dense
neural networks, showing that the last activation function plays an important
role in classifying stationary points, due to how it shows up in the gradient
from the chain rule.
\\ ( https://arxiv.org/abs/2002.02882 ,  30kb)
------------------------------------------------------------------------------
\\
arXiv:2002.02892 (*cross-listing*)
Date: Fri, 7 Feb 2020 16:49:25 GMT   (98kb,D)

Title: Sparse and Smooth: improved guarantees for Spectral Clustering in the
  Dynamic Stochastic Block Model
Authors: Nicolas Keriven, Samuel Vaiter
Categories: stat.ML cs.LG math.ST stat.TH
\\
  In this paper, we analyse classical variants of the Spectral Clustering (SC)
algorithm in the Dynamic Stochastic Block Model (DSBM). Existing results show
that, in the relatively sparse case where the expected degree grows
logarithmically with the number of nodes, guarantees in the static case can be
extended to the dynamic case and yield improved error bounds when the DSBM is
sufficiently smooth in time, that is, the communities do not change too much
between two time steps. We improve over these results by drawing a new link
between the sparsity and the smoothness of the DSBM: the more regular the DSBM
is, the more sparse it can be, while still guaranteeing consistent recovery. In
particular, a mild condition on the smoothness allows to treat the sparse case
with bounded degree. We also extend these guarantees to the normalized
Laplacian, and as a by-product of our analysis, we obtain to our knowledge the
best spectral concentration bound available for the normalized Laplacian of
matrices with independent Bernoulli entries.
\\ ( https://arxiv.org/abs/2002.02892 ,  98kb)
------------------------------------------------------------------------------
\\
arXiv:2002.02901 (*cross-listing*)
Date: Fri, 7 Feb 2020 16:59:24 GMT   (83kb,D)

Title: Oblivious Data for Fairness with Kernels
Authors: Steffen Gr\"unew\"alder and Azadeh Khaleghi
Categories: stat.ML cs.LG math.ST stat.TH
\\
  We investigate the problem of algorithmic fairness in the case where
sensitive and non-sensitive features are available and one aims to generate
new, `oblivious', features that closely approximate the non-sensitive features,
and are only minimally dependent on the sensitive ones. We study this question
in the context of kernel methods. We analyze a relaxed version of the Maximum
Mean Discrepancy criterion which does not guarantee full independence but makes
the optimization problem tractable. We derive a closed-form solution for this
relaxed optimization problem and complement the result with a study of the
dependencies between the newly generated features and the sensitive ones. Our
key ingredient for generating such oblivious features is a Hilbert-space-valued
conditional expectation, which needs to be estimated from data. We propose a
plug-in approach and demonstrate how the estimation errors can be controlled.
Our theoretical results are accompanied by experimental evaluations.
\\ ( https://arxiv.org/abs/2002.02901 ,  83kb)
------------------------------------------------------------------------------
\\
arXiv:2002.02903 (*cross-listing*)
Date: Fri, 7 Feb 2020 17:01:59 GMT   (442kb,D)

Title: Subsampling Winner Algorithm for Feature Selection in Large Regression
  Data
Authors: Yiying Fan and Jiayang Sun
Categories: stat.ML cs.LG
\\
  Feature selection from a large number of covariates (aka features) in a
regression analysis remains a challenge in data science, especially in terms of
its potential of scaling to ever-enlarging data and finding a group of
scientifically meaningful features. For example, to develop new, responsive
drug targets for ovarian cancer, the actual false discovery rate (FDR) of a
practical feature selection procedure must also match the target FDR. The
popular approach to feature selection, when true features are sparse, is to use
a penalized likelihood or a shrinkage estimation, such as a LASSO, SCAD,
Elastic Net, or MCP procedure (call them benchmark procedures). We present a
different approach using a new subsampling method, called the Subsampling
Winner algorithm (SWA). The central idea of SWA is analogous to that used for
the selection of US national merit scholars. SWA uses a "base procedure" to
analyze each of the subsamples, computes the scores of all features according
to the performance of each feature from all subsample analyses, obtains the
"semifinalist" based on the resulting scores, and then determines the
"finalists," i.e., the most important features. Due to its subsampling nature,
SWA can scale to data of any dimension in principle. The SWA also has the
best-controlled actual FDR in comparison with the benchmark procedures and the
randomForest, while having a competitive true-feature discovery rate. We also
suggest practical add-on strategies to SWA with or without a penalized
benchmark procedure to further assure the chance of "true" discovery. Our
application of SWA to the ovarian serous cystadenocarcinoma specimens from the
Broad Institute revealed functionally important genes and pathways, which we
verified by additional genomics tools. This second-stage investigation is
essential in the current discussion of the proper use of P-values.
\\ ( https://arxiv.org/abs/2002.02903 ,  442kb)
------------------------------------------------------------------------------
\\
arXiv:2002.02919 (*cross-listing*)
Date: Fri, 7 Feb 2020 17:47:07 GMT   (189kb)

Title: Extended Stochastic Gradient MCMC for Large-Scale Bayesian Variable
  Selection
Authors: Qifan Song, Yan Sun, Mao Ye, Faming Liang
Categories: stat.CO cs.LG stat.ML
\\
  Stochastic gradient Markov chain Monte Carlo (MCMC) algorithms have received
much attention in Bayesian computing for big data problems, but they are only
applicable to a small class of problems for which the parameter space has a
fixed dimension and the log-posterior density is differentiable with respect to
the parameters. This paper proposes an extended stochastic gradient MCMC
lgoriathm which, by introducing appropriate latent variables, can be applied to
more general large-scale Bayesian computing problems, such as those involving
dimension jumping and missing data. Numerical studies show that the proposed
algorithm is highly scalable and much more efficient than traditional MCMC
algorithms. The proposed algorithms have much alleviated the pain of Bayesian
methods in big data computing.
\\ ( https://arxiv.org/abs/2002.02919 ,  189kb)
------------------------------------------------------------------------------
\\
arXiv:2002.02529 (*cross-listing*)
Date: Wed, 29 Jan 2020 18:09:09 GMT   (3045kb)

Title: A Repeated Game Freeway Lane Changing Model
Authors: Kyungwon Kang and Hesham A Rakha
Categories: physics.soc-ph cs.MA
Comments: The paper has been submitted to Sensors
\\
  Lane changes are complex safety and throughput critical driver actions. Most
lane changing models deal with lane-changing maneuvers solely from the merging
driver's standpoint and thus ignore driver interaction. To overcome this
shortcoming, we develop a game-theoretical decision-making model and validate
the model using empirical merging maneuver data at a freeway on-ramp.
Specifically, this paper advances our repeated game model in a previous paper
by using updated payoff functions. Validation results using the NGSIM empirical
data show that the developed game-theoretical model provides better prediction
accuracy compared to previous work, with correct predictions approximately 86
percent of the time. In addition, a sensitivity analysis demonstrates the
rationality and sensitivity of the model to variations in various factors. To
provide evidence of the benefits of the repeated game approach, which takes
into account previous decision-making results, a case study is conducted using
an agent-based simulation model. The proposed repeated game model produces
superior performance to a one-shot game model, when simulating actual freeway
merging behaviors. Finally, this lane change model, which captures the
collective decision-making between human drivers, can be used to develop
automated vehicle driving strategies.
\\ ( https://arxiv.org/abs/2002.02529 ,  3045kb)
------------------------------------------------------------------------------
\\
arXiv:2002.02802 (*cross-listing*)
Date: Wed, 29 Jan 2020 21:16:18 GMT   (4304kb,D)

Title: From kinetic to macroscopic models and back
Authors: M. Herty, G. Puppo, G. Visconti
Categories: math.AP cs.NA math.NA
\\
  We study kinetic models for traffic flow characterized by the property of
producing backward propagating waves. These waves may be identified with the
phenomenon of stop-and-go waves typically observed on highways. In particular,
a refined modeling of the space of the microscopic speeds and of the
interaction rate in the kinetic model allows to obtain weakly unstable backward
propagating waves in dense traffic, without relying on non-local terms or
multi--valued fundamental diagrams. A stability analysis of these waves is
carried out using the Chapman-Enskog expansion. This leads to a BGK-type model
derived as the mesoscopic limit of a Follow-The-Leader or Bando model, and its
macroscopic limit belongs to the class of second-order Aw-Rascle and Zhang
models.
\\ ( https://arxiv.org/abs/2002.02802 ,  4304kb)
------------------------------------------------------------------------------
\\
arXiv:2002.02810 (*cross-listing*)
Date: Tue, 21 Jan 2020 22:43:00 GMT   (429kb,D)

Title: On meso-scale approximations for vibrations of membranes with
  lower-dimensional clusters of inertial inclusions
Authors: Vladimir Maz'ya, Alexander Movchan and Michael Nieves
Categories: math.AP cs.NA math-ph math.MP math.NA
Comments: 19 pages, 2 figures
MSC-class: 76M45, 35J05
\\
  In this paper we consider formal asymptotic algorithms for a class of
meso-scale approximations for problems of vibration of elastic membranes, which
contain clusters of small inertial inclusions distributed along contours of
pre-defined smooth shapes. Effective transmission conditions have been
identified for inertial structured interfaces, and approximations to solutions
of eigenvalue problems have been derived for domains containing
lower-dimensional clusters of inclusions.
\\ ( https://arxiv.org/abs/2002.02810 ,  429kb)
------------------------------------------------------------------------------
\\
arXiv:2002.02833 (*cross-listing*)
Date: Fri, 7 Feb 2020 15:08:35 GMT   (1030kb,D)

Title: Accelerating linear system solvers for time domain component separation
  of cosmic microwave background data
Authors: J. Papez, L. Grigori, R. Stompor
Categories: astro-ph.CO cs.NA math.NA physics.comp-ph
\\
  Component separation is one of the key stages of any modern, cosmic microwave
background (CMB) data analysis pipeline. It is an inherently non-linear
procedure and typically involves a series of sequential solutions of linear
systems with similar, albeit not identical system matrices, derived for
different data models of the same data set. Sequences of this kind arise for
instance in the maximization of the data likelihood with respect to foreground
parameters or sampling of their posterior distribution. However, they are also
common in many other contexts. In this work we consider solving the component
separation problem directly in the measurement (time) domain, which can have a
number of important advantageous over the more standard pixel-based methods, in
particular if non-negligible time-domain noise correlations are present as it
is commonly the case. The time-domain based approach implies, however,
significant computational effort due to the need to manipulate the full volume
of time-domain data set. To address this challenge, we propose and study
efficient solvers adapted to solving time-domain-based, component separation
systems and their sequences and which are capable of capitalizing on
information derived from the previous solutions. This is achieved either via
adapting the initial guess of the subsequent system or through a so-called
subspace recycling, which allows to construct progressively more efficient,
two-level preconditioners. We report an overall speed-up over solving the
systems independently of a factor of nearly 7, or 5, in the worked examples
inspired respectively by the likelihood maximization and likelihood sampling
procedures we consider in this work.
\\ ( https://arxiv.org/abs/2002.02833 ,  1030kb)
------------------------------------------------------------------------------
\\
arXiv:2002.02838 (*cross-listing*)
Date: Fri, 7 Feb 2020 15:24:02 GMT   (1934kb,D)

Title: A convergent low-wavenumber, high-frequency homogenization of the wave
  equation in periodic media with a source term
Authors: Shixu Meng, Othman Oudghiri-Idrissi, Bojan B. Guzina
Categories: math.AP cs.NA math.NA
\\
  We pursue a low-wavenumber, second-order homogenized solution of the
time-harmonic wave equation in periodic media with a source term whose
frequency resides inside a band gap. Considering the wave motion in an
unbounded medium $\mathbb{R}^d$ ($d\geqslant1$), we first use the Bloch
transform to formulate an equivalent variational problem in a bounded domain.
By investigating the source term's projection onto certain periodic functions,
the second-order model can then be derived via asymptotic expansion of the
Bloch eigenfunction and the germane dispersion relationship. We establish the
convergence of the second-order homogenized solution, and we include numerical
examples to illustrate the convergence result.
\\ ( https://arxiv.org/abs/2002.02838 ,  1934kb)
------------------------------------------------------------------------------
\\
arXiv:2002.02807 (*cross-listing*)
Date: Fri, 7 Feb 2020 14:25:21 GMT   (3398kb,D)

Title: Adaptive control for hindlimb locomotion in a simulated mouse through
  temporal cerebellar learning
Authors: T. P. Jensen, S. Tata, A. J. Ijspeert, S. Tolu
Categories: q-bio.NC cs.NE
Comments: To be published in NICE '20: Proceedings of the 8th Annual
  Neuro-inspired Computational Elements Workshop. 8 pages, 13 figures
\\
  Human beings and other vertebrates show remarkable performance and efficiency
in locomotion, but the functioning of their biological control systems for
locomotion is still only partially understood. The basic patterns and timing
for locomotion are provided by a central pattern generator (CPG) in the spinal
cord. The cerebellum is known to play an important role in adaptive locomotion.
Recent studies have given insights into the error signals responsible for
driving the cerebellar adaptation in locomotion. However, the question of how
the cerebellar output influences the gait remains unanswered. We hypothesize
that the cerebellar correction is applied to the pattern formation part of the
CPG. Here, a bio-inspired control system for adaptive locomotion of the
musculoskeletal system of the mouse is presented, where a cerebellar-like
module adapts the step time by using the double support interlimb asymmetry as
a temporal teaching signal. The control system is tested on a simulated mouse
in a split-belt treadmill setup similar to those used in experiments with real
mice. The results show adaptive locomotion behavior in the interlimb parameters
similar to that seen in humans and mice. The control system adaptively
decreases the double support asymmetry that occurs due to environmental
perturbations in the split-belt protocol.
\\ ( https://arxiv.org/abs/2002.02807 ,  3398kb)
------------------------------------------------------------------------------
\\
arXiv:2002.02451 (*cross-listing*)
Date: Thu, 6 Feb 2020 08:51:47 GMT   (2615kb,D)

Title: Federated Orchestration for Network Slicing of Bandwidth and
  Computational Resource
Authors: Yingyu Li, Anqi Huang, Yong Xiao, Xiaohu Ge, Sumei Sun, Han-Chieh Chao
Categories: eess.SP cs.NI
Comments: arXiv admin note: substantial text overlap with arXiv:2002.01101
\\
  Network slicing has been considered as one of the key enablers for 5G to
support diversified IoT services and application scenarios. This paper studies
the distributed network slicing for a massive scale IoT network supported by 5G
with fog computing. Multiple services with various requirements need to be
supported by both spectrum resource offered by 5G network and computational
resourc of the fog computing network. We propose a novel distributed framework
based on a new control plane entity, federated-orchestrator , which can
coordinate the spectrum and computational resources without requiring any
exchange of the local data and resource information from BSs. We propose a
distributed resource allocation algorithm based on Alternating Direction Method
of Multipliers with Partial Variable Splitting . We prove DistADMM-PVS
minimizes the average service response time of the entire network with
guaranteed worst-case performance for all supported types of services when the
coordination between the F-orchestrator and BSs is perfectly synchronized.
Motivated by the observation that coordination synchronization may result in
high coordination delay that can be intolerable when the network is large in
scale, we propose a novel asynchronized ADMM algorithm. We prove that AsynADMM
can converge to the global optimal solution with improved scalability and
negligible coordination delay. We evaluate the performance of our proposed
framework using two-month of traffic data collected in a in-campus smart
transportation system supported by a 5G network. Extensive simulation has been
conducted for both pedestrian and vehicular-related services during peak and
non-peak hours. Our results show that the proposed framework offers significant
reduction on service response time for both supported services, especially
compared to network slicing with only a single resource.
\\ ( https://arxiv.org/abs/2002.02451 ,  2615kb)
------------------------------------------------------------------------------
\\
arXiv:2002.02493 (*cross-listing*)
Date: Thu, 6 Feb 2020 19:57:04 GMT   (5868kb)

Title: On Ridership and Frequency
Authors: Simon Berrebi and Taylor Gibbs and Sanskruti Joshi and Kari E Watkins
Categories: physics.soc-ph cs.SI econ.EM stat.AP
\\
  In 2018, bus ridership attained its lowest level since 1973. If transit
agencies hope to reverse this trend, they must understand how their service
allocation policies affect ridership. This paper is among the first to model
ridership trends on a hyper-local level over time. A Poisson fixed-effects
model is developed to evaluate the ridership elasticity to frequency using
passenger count data from Portland, Miami, Minneapolis/St-Paul, and Atlanta
between 2012 and 2018. In every agency, ridership is found to be elastic to
frequency when observing the variation between individual route-segments at one
point in time. In other words, the most frequent routes are already the most
productive. When observing the variation within each route-segment over time,
however, ridership is inelastic; each additional vehicle-trip is expected to
generate less ridership than the average bus already on the route. In three of
the four agencies, the elasticity is a decreasing function of prior frequency,
meaning that low-frequency routes are the most sensitive to frequency change.
This paper can help transit agencies anticipate the marginal effect of shifting
service throughout the network. As the quality and availability of passenger
count data improve, this paper can serve as the methodological basis to explore
the dynamics of bus ridership.
\\ ( https://arxiv.org/abs/2002.02493 ,  5868kb)
------------------------------------------------------------------------------
\\
arXiv:2002.02819 (*cross-listing*)
Date: Fri, 7 Feb 2020 14:45:03 GMT   (887kb,D)

Title: Lightning Network: a second path towards centralisation of the Bitcoin
  economy
Authors: Jian-Hong Lin, Kevin Primicerio, Tiziano Squartini, Christian Decker,
  and Claudio J.Tessone
Categories: physics.soc-ph cs.SI
\\
  The Bitcoin Lightning Network (BLN), a so-called "second layer" payment
protocol, was launched in 2018 to scale up the number of transactions between
Bitcoin owners. In this paper, we analyse the structure of the BLN over a
period of 18 months, ranging from 14th January 2018 to 13th July 2019, at the
end of which the network has reached 8.216 users, 122.517 active channels and
2.732,5 transacted bitcoins. Here, we consider three representations of the
BLN: the daily snapshot one, the weekly snapshot one and the daily-block
snapshot one. By studying the topological properties of the binary and weighted
versions of the three representations above, we find that the total volume of
transacted bitcoins approximately grows as the square of the network size;
however, despite the huge activity characterising the BLN, the bitcoins
distribution is very unequal: the average Gini coefficient of the node
strengths is approximately 0.88 causing 10% (50%) the of the nodes to hold the
80% (99%) of the bitcoins at stake in the BLN (on average, across the entire
period). Like for other economic systems, we hypothesise that local properties
of nodes, like the degree, ultimately determine part of its characteristics.
Therefore, we have tested the goodness of the Undirected Binary Configuration
Model (UBCM) in reproducing the structural features of the BLN: the UBCM
recovers the disassortative and the hierarchical character of the BLN but
underestimates the centrality of nodes; this suggests that the BLN is becoming
an increasingly centralised network, more and more compatible with a
core-periphery structure. Further inspection of the resilience of the BLN shows
that removing hubs leads to the collapse of the network into many components,
an evidence suggesting that this network may be a target for the so-called
split attacks.
\\ ( https://arxiv.org/abs/2002.02819 ,  887kb)
------------------------------------------------------------------------------
\\
arXiv:2002.02524 (*cross-listing*)
Date: Thu, 6 Feb 2020 22:06:42 GMT   (6433kb,D)

Title: High-Accuracy Multi-Node Ranging For Coherent Distributed Antenna Arrays
Authors: Sean Ellison and Jeffrey Nanzer
Categories: eess.SP cs.SY eess.SY
Comments: Submitted to IEEE Transactions on Aerospace and Electronic Systems
\\
  The design and experimental implementation of a waveform for high-accuracy
inter-node ranging in a coherent distributed antenna array is presented. Based
on a spectrally-sparse high-accuracy ranging waveform, the presented
multi-frequency waveform enables high-accuracy ranging between multiple nodes
in an array simultaneously, without interference. The waveform is based on a
unique time-frequency duplexing approach combining a stepped-frequency waveform
with different step cycles per node pair. The waveform also inherently includes
beneficial disambiguation properties. The ambiguity function of the waveform is
derived, and theoretical bounds on the ranging accuracy are obtained.
Measurements were conducted in software-defined radio-based nodes in a
three-element distributed array, demonstrating high-accuracy unambiguous
ranging between two slave nodes and one master node.
\\ ( https://arxiv.org/abs/2002.02524 ,  6433kb)
------------------------------------------------------------------------------
\\
arXiv:2002.02830 (*cross-listing*)
Date: Fri, 7 Feb 2020 15:02:05 GMT   (457kb)

Title: H2 and H-infinity Suboptimal Distributed Filter Design for Linear
  Systems
Authors: Junjie Jiao, Harry L. Trentelman, M. Kanat Camlibel
Categories: math.OC cs.SY eess.SY
Comments: 13 pages, 5 figures
\\
  This paper investigates the H2 and H-infinity suboptimal distributed
filtering problems for continuous time linear systems. Consider a linear system
monitored by a number of filters, where each of the filters receives only part
of the measured output of the system. Each filter can communicate with the
other filters according to an a priori given strongly connected weighted
directed graph. The aim is to design filter gains that guarantee the H2 or
H-infinity norm of the transfer matrix from the disturbance input to the output
estimation error to be smaller than an a priori given upper bound, while all
local filters reconstruct the full system state asymptotically. We provide a
centralized design method for obtaining such H2 and H-infinity suboptimal
distributed filters. The proposed design method is illustrated by a simulation
example.
\\ ( https://arxiv.org/abs/2002.02830 ,  457kb)
%%--%%--%%--%%--%%--%%--%%--%%--%%--%%--%%--%%--%%--%%--%%--%%--%%--%%--%%--%%
------------------------------------------------------------------------------
\\
arXiv:1908.08474
replaced with revised version Fri, 7 Feb 2020 17:43:11 GMT   (121kb,D)

Title: The many Shapley values for model explanation
Authors: Mukund Sundararajan and Amir Najmi
Categories: cs.AI cs.LG econ.TH
Comments: 9 pages
\\ ( https://arxiv.org/abs/1908.08474 ,  121kb)
------------------------------------------------------------------------------
\\
arXiv:1909.03094
replaced with revised version Thu, 6 Feb 2020 23:15:48 GMT   (759kb,D)

Title: Automatic Critical Mechanic Discovery in Video Games
Authors: Michael Cerny Green, Ahmed Khalifa, Gabriella A.B. Barros, Tiago
  Machado and Julian Togelius
Categories: cs.AI
Comments: 9 pages, 4 figures, 2 tables, 1 algorithm, 1 equation
\\ ( https://arxiv.org/abs/1909.03094 ,  759kb)
------------------------------------------------------------------------------
\\
arXiv:1910.02486
replaced with revised version Fri, 7 Feb 2020 07:39:08 GMT   (7516kb,D)

Title: Interpretable neural networks based on continuous-valued logic and
  multicriteria decision operators
Authors: Orsolya Csisz\'ar, G\'abor Csisz\'ar, J\'ozsef Dombi
Categories: cs.AI
\\ ( https://arxiv.org/abs/1910.02486 ,  7516kb)
------------------------------------------------------------------------------
\\
arXiv:2002.02376
replaced with revised version Fri, 7 Feb 2020 01:26:11 GMT   (61kb)

Title: A Survey on String Constraint Solving
Authors: Roberto Amadini
Categories: cs.AI cs.FL
\\ ( https://arxiv.org/abs/2002.02376 ,  61kb)
------------------------------------------------------------------------------
\\
arXiv:1604.07138
replaced with revised version Fri, 7 Feb 2020 02:26:24 GMT   (770kb)

Title: An integral-transform approach to the bioheat transfer problems in
  magnetic hyperthermia
Authors: Kenya Murase
Categories: cs.CE physics.med-ph
\\ ( https://arxiv.org/abs/1604.07138 ,  770kb)
------------------------------------------------------------------------------
\\
arXiv:1711.10414
replaced with revised version Thu, 6 Feb 2020 19:46:25 GMT   (23kb)

Title: When are epsilon-nets small?
Authors: Andrey Kupavskii, Nikita Zhivotovskiy
Categories: cs.CG cs.LG math.CO
Comments: 22 pages; minor changes, accepted version
\\ ( https://arxiv.org/abs/1711.10414 ,  23kb)
------------------------------------------------------------------------------
\\
arXiv:1908.04211
replaced with revised version Fri, 7 Feb 2020 17:44:52 GMT   (529kb,D)

Title: On Identifiability in Transformers
Authors: Gino Brunner, Yang Liu, Dami\'an Pascual, Oliver Richter, Massimiliano
  Ciaramita, Roger Wattenhofer
Categories: cs.CL cs.LG
Comments: Published as a conference paper at ICLR 2020
MSC-class: I.2.7, I.7.0
ACM-class: I.2.7; I.7.0
\\ ( https://arxiv.org/abs/1908.04211 ,  529kb)
------------------------------------------------------------------------------
\\
arXiv:1909.12408
replaced with revised version Fri, 7 Feb 2020 00:15:41 GMT   (176kb,D)

Title: Optimizing Speech Recognition For The Edge
Authors: Yuan Shangguan, Jian Li, Qiao Liang, Raziel Alvarez, Ian McGraw
Categories: cs.CL cs.LG eess.AS
\\ ( https://arxiv.org/abs/1909.12408 ,  176kb)
------------------------------------------------------------------------------
\\
arXiv:2001.08604
replaced with revised version Fri, 7 Feb 2020 12:15:35 GMT   (603kb,D)

Title: Variational Hierarchical Dialog Autoencoder for Dialog State Tracking
  Data Augmentation
Authors: Kang Min Yoo, Hanbit Lee, Franck Dernoncourt, Trung Bui, Walter Chang,
  Sang-goo Lee
Categories: cs.CL cs.LG
Comments: 10 pages, 1 figure, 6 tables, preprint
\\ ( https://arxiv.org/abs/2001.08604 ,  603kb)
------------------------------------------------------------------------------
\\
arXiv:2002.01808
replaced with revised version Fri, 7 Feb 2020 03:30:44 GMT   (911kb,D)

Title: K-Adapter: Infusing Knowledge into Pre-Trained Models with Adapters
Authors: Ruize Wang, Duyu Tang, Nan Duan, Zhongyu Wei, Xuanjing Huang, Jianshu
  ji, Cuihong Cao, Daxin Jiang, Ming Zhou
Categories: cs.CL cs.LG
\\ ( https://arxiv.org/abs/2002.01808 ,  911kb)
------------------------------------------------------------------------------
\\
arXiv:1901.05741
replaced with revised version Fri, 7 Feb 2020 05:11:09 GMT   (712kb)

Title: RepChain: A Reputation-based Secure, Fast and High Incentive Blockchain
  System via Sharding
Authors: Chenyu Huang, Zeyu Wang, Huangxun Chen, Qiwei Hu, Qian Zhang, Wei
  Wang, Xia Guan
Categories: cs.CR cs.NI
\\ ( https://arxiv.org/abs/1901.05741 ,  712kb)
------------------------------------------------------------------------------
\\
arXiv:1904.03501
replaced with revised version Thu, 6 Feb 2020 19:33:54 GMT   (334kb)

Title: DeepSEED: 3D Squeeze-and-Excitation Encoder-Decoder Convolutional Neural
  Networks for Pulmonary Nodule Detection
Authors: Yuemeng Li, Yong Fan
Categories: cs.CV
Comments: Accepted by 2020 IEEE International Symposium on Biomedical Imaging
  (ISBI)
\\ ( https://arxiv.org/abs/1904.03501 ,  334kb)
------------------------------------------------------------------------------
\\
arXiv:1904.07793
replaced with revised version Fri, 7 Feb 2020 18:11:58 GMT   (5462kb,D)

Title: AT-GAN: An Adversarial Generator Model for Non-constrained Adversarial
  Examples
Authors: Xiaosen Wang, Kun He, Chuanbiao Song, Liwei Wang, John E. Hopcroft
Categories: cs.CV cs.CR cs.LG
Comments: 15 pages, 6 figures
\\ ( https://arxiv.org/abs/1904.07793 ,  5462kb)
------------------------------------------------------------------------------
\\
arXiv:1905.02319
replaced with revised version Fri, 7 Feb 2020 09:32:31 GMT   (4990kb,D)

Title: Automatic 4D Facial Expression Recognition via Collaborative
  Cross-domain Dynamic Image Network
Authors: Muzammil Behzad, Nhat Vo, Xiaobai Li, Guoying Zhao
Categories: cs.CV
Comments: Published in the 30th British Machine Vision Conference (BMVC) 2019
\\ ( https://arxiv.org/abs/1905.02319 ,  4990kb)
------------------------------------------------------------------------------
\\
arXiv:1907.06890
replaced with revised version Fri, 7 Feb 2020 12:10:56 GMT   (5665kb,D)

Title: A General Framework for Uncertainty Estimation in Deep Learning
Authors: Antonio Loquercio, Mattia Seg\`u, Davide Scaramuzza
Categories: cs.CV stat.ML
Comments: Accepted for publication in the Robotics and Automation Letters 2020,
  and for presentation at the International Conference on Robotics and
  Automation (ICRA) 2020
\\ ( https://arxiv.org/abs/1907.06890 ,  5665kb)
------------------------------------------------------------------------------
\\
arXiv:1907.11819
replaced with revised version Fri, 7 Feb 2020 11:36:18 GMT   (9520kb,D)

Title: Grape detection, segmentation and tracking using deep neural networks
  and three-dimensional association
Authors: Thiago T. Santos, Leonardo L. de Souza, Andreza A. dos Santos and
  Sandra Avila
Categories: cs.CV
Journal-ref: Computers and Electronics in Agriculture, 170, 105-247 (2020)
DOI: 10.1016/J.COMPAG.2020.105247
\\ ( https://arxiv.org/abs/1907.11819 ,  9520kb)
------------------------------------------------------------------------------
\\
arXiv:1908.06391
replaced with revised version Fri, 7 Feb 2020 03:20:01 GMT   (7949kb,D)

Title: PANet: Few-Shot Image Semantic Segmentation with Prototype Alignment
Authors: Kaixin Wang, Jun Hao Liew, Yingtian Zou, Daquan Zhou, Jiashi Feng
Categories: cs.CV
Comments: 10 pages, 6 figures, ICCV 2019, code available at
  https://github.com/kaixin96/PANet
\\ ( https://arxiv.org/abs/1908.06391 ,  7949kb)
------------------------------------------------------------------------------
\\
arXiv:1909.07721
replaced with revised version Fri, 7 Feb 2020 16:09:54 GMT   (3406kb,D)

Title: DS-PASS: Detail-Sensitive Panoramic Annular Semantic Segmentation
  through SwaftNet for Surrounding Sensing
Authors: Kailun Yang, Xinxin Hu, Hao Chen, Kaite Xiang, Kaiwei Wang and Rainer
  Stiefelhagen
Categories: cs.CV cs.RO eess.IV eess.SP
Comments: 8 pages, 10 figures
\\ ( https://arxiv.org/abs/1909.07721 ,  3406kb)
------------------------------------------------------------------------------
\\
arXiv:1909.08228
replaced with revised version Fri, 7 Feb 2020 04:41:32 GMT   (2831kb,D)

Title: Memory-Efficient Hierarchical Neural Architecture Search for Image
  Denoising
Authors: Haokui Zhang, Ying Li, Hao Chen, Chunhua Shen
Categories: cs.CV
\\ ( https://arxiv.org/abs/1909.08228 ,  2831kb)
------------------------------------------------------------------------------
\\
arXiv:1910.05445
replaced with revised version Fri, 7 Feb 2020 09:34:25 GMT   (6015kb,D)

Title: Landmarks-assisted Collaborative Deep Framework for Automatic 4D Facial
  Expression Recognition
Authors: Muzammil Behzad, Nhat Vo, Xiaobai Li and Guoying Zhao
Categories: cs.CV
Comments: Published in 15th IEEE International Conference on Automatic Face and
  Gesture Recognition
\\ ( https://arxiv.org/abs/1910.05445 ,  6015kb)
------------------------------------------------------------------------------
\\
arXiv:1910.05483
replaced with revised version Thu, 6 Feb 2020 23:59:10 GMT   (1688kb,D)

Title: Frustum VoxNet for 3D object detection from RGB-D or Depth images
Authors: Xiaoke Shen and Ioannis Stamos
Categories: cs.CV eess.IV
Comments: page 8, add Acknowledgement. page 10, add Supplementary Material. The
  paper got accepted by 2020 Winter Conference on Applications of Computer
  Vision (WACV '20). The first arxiv version can be found here:
  arXiv:1910.05483
\\ ( https://arxiv.org/abs/1910.05483 ,  1688kb)
------------------------------------------------------------------------------
\\
arXiv:1911.10535
replaced with revised version Fri, 7 Feb 2020 00:58:10 GMT   (1187kb,D)

Title: Using Panoramic Videos for Multi-person Localization and Tracking in a
  3D Panoramic Coordinate
Authors: Fan Yang, Feiran Li, Yang Wu, Sakriani Sakti, and Satoshi Nakamura
Categories: cs.CV
Comments: 5 pages
\\ ( https://arxiv.org/abs/1911.10535 ,  1187kb)
------------------------------------------------------------------------------
\\
arXiv:2001.03233
replaced with revised version Thu, 6 Feb 2020 19:45:16 GMT   (8119kb,D)

Title: RSL-Net: Localising in Satellite Images From a Radar on the Ground
Authors: Tim Y. Tang, Daniele De Martini, Dan Barnes, Paul Newman
Categories: cs.CV cs.RO eess.IV
Comments: Accepted to IEEE Robotics and Automation Letters (RA-L)
\\ ( https://arxiv.org/abs/2001.03233 ,  8119kb)
------------------------------------------------------------------------------
\\
arXiv:2002.02100
replaced with revised version Fri, 7 Feb 2020 06:42:20 GMT   (700kb,D)

Title: An Information-rich Sampling Technique over Spatio-Temporal CNN for
  Classification of Human Actions in Videos
Authors: S.H. Shabbeer Basha, Viswanath Pulabaigari, Snehasis Mukherjee
Categories: cs.CV cs.LG
\\ ( https://arxiv.org/abs/2002.02100 ,  700kb)
------------------------------------------------------------------------------
\\
arXiv:1908.08920
replaced with revised version Thu, 6 Feb 2020 22:55:03 GMT   (1641kb,D)

Title: Automation is no barrier to light vehicle electrification
Authors: Aniruddh Mohan and Shashank Sripad and Parth Vaishnav and
  Venkatasubramanian Viswanathan
Categories: cs.CY
Comments: 25 pages, 4 figures, 14 pages of Supporting Information
\\ ( https://arxiv.org/abs/1908.08920 ,  1641kb)
------------------------------------------------------------------------------
\\
arXiv:1703.04780
replaced with revised version Thu, 6 Feb 2020 21:16:32 GMT   (153kb,D)

Title: Learning Models over Relational Data using Sparse Tensors and Functional
  Dependencies
Authors: Mahmoud Abo Khamis and Hung Q. Ngo and XuanLong Nguyen and Dan Olteanu
  and Maximilian Schleich
Categories: cs.DB
Comments: 61 pages, 9 figures, 2 tables
ACM-class: H.2.4; I.2.6
\\ ( https://arxiv.org/abs/1703.04780 ,  153kb)
------------------------------------------------------------------------------
\\
arXiv:1911.01225
replaced with revised version Thu, 6 Feb 2020 19:49:04 GMT   (3404kb,D)

Title: Fast Dimensional Analysis for Root Cause Investigation in a Large-Scale
  Service Environment
Authors: Fred Lin, Keyur Muzumdar, Nikolay Pavlovich Laptev, Mihai-Valentin
  Curelea, Seunghak Lee, Sriram Sankar
Categories: cs.DC cs.DB cs.LG stat.ML
Comments: 13 pages
\\ ( https://arxiv.org/abs/1911.01225 ,  3404kb)
------------------------------------------------------------------------------
\\
arXiv:2001.07091
replaced with revised version Fri, 7 Feb 2020 14:41:27 GMT   (2381kb,D)

Title: Blockchain Consensus Algorithms: A Survey
Authors: Md Sadek Ferdous, Mohammad Jabed Morshed Chowdhury, Mohammad A. Hoque
  and Alan Colman
Categories: cs.DC
\\ ( https://arxiv.org/abs/2001.07091 ,  2381kb)
------------------------------------------------------------------------------
\\
arXiv:1903.04214
replaced with revised version Fri, 7 Feb 2020 15:48:24 GMT   (17kb,D)

Title: How far away must forced letters be so that squares are still avoidable?
Authors: Matthieu Rosenfeld
Categories: cs.DM math.CO
\\ ( https://arxiv.org/abs/1903.04214 ,  17kb)
------------------------------------------------------------------------------
\\
arXiv:1807.00304
replaced with revised version Fri, 7 Feb 2020 07:19:50 GMT   (24kb)

Title: Quality of local equilibria in discrete exchange economies
Authors: Daniel Lehmann
Categories: cs.GT
Comments: 34 pages, preprint. Previous results are generalized to a-bounded
  valuations. The latest version corrects typos and includes minor changes. It
  also adds an Appendix on quasi-Walrasian equilibria. Title has been changed.
  Version 3 has been revised according to referees comments
\\ ( https://arxiv.org/abs/1807.00304 ,  24kb)
------------------------------------------------------------------------------
\\
arXiv:1908.08642
replaced with revised version Thu, 6 Feb 2020 20:25:58 GMT   (37kb)

Title: A novel approach to multivariate redundancy and synergy
Authors: Artemy Kolchinsky
Categories: cs.IT math.IT q-bio.NC stat.ML
\\ ( https://arxiv.org/abs/1908.08642 ,  37kb)
------------------------------------------------------------------------------
\\
arXiv:2002.02187
replaced with revised version Fri, 7 Feb 2020 16:13:03 GMT   (5kb)

Title: On the Fairness of Name-Based Rationing System for Purchases of Masks
  Policy
Authors: Yu-Ting Liu
Categories: cs.IT math.IT
\\ ( https://arxiv.org/abs/2002.02187 ,  5kb)
------------------------------------------------------------------------------
\\
arXiv:1812.02849
replaced with revised version Thu, 6 Feb 2020 19:39:09 GMT   (1847kb,D)

Title: A Survey of Unsupervised Deep Domain Adaptation
Authors: Garrett Wilson and Diane J. Cook
Categories: cs.LG stat.ML
\\ ( https://arxiv.org/abs/1812.02849 ,  1847kb)
------------------------------------------------------------------------------
\\
arXiv:1901.08247
replaced with revised version Thu, 6 Feb 2020 20:25:25 GMT   (6266kb,D)

Title: Machine Learning and Deep Learning Algorithms for Bearing Fault
  Diagnostics -- A Comprehensive Review
Authors: Shen Zhang, Shibo Zhang, Bingnan Wang, Thomas G. Habetler
Categories: cs.LG stat.ML
\\ ( https://arxiv.org/abs/1901.08247 ,  6266kb)
------------------------------------------------------------------------------
\\
arXiv:1903.04003
replaced with revised version Fri, 7 Feb 2020 15:00:22 GMT   (2158kb)

Title: Multinomial Random Forest: Toward Consistency and Privacy-Preservation
Authors: Yiming Li, Jiawang Bai, Jiawei Li, Xue Yang, Yong Jiang, Chun Li,
  Shutao Xia
Categories: cs.LG stat.ML
Comments: 10 pages
\\ ( https://arxiv.org/abs/1903.04003 ,  2158kb)
------------------------------------------------------------------------------
\\
arXiv:1905.10201
replaced with revised version Fri, 7 Feb 2020 15:12:29 GMT   (2640kb,D)

Title: Perturbation Validation: A New Heuristic to Validate Machine Learning
  Models
Authors: Jie M. Zhang and Mark Harman and Benjamin Guedj and Earl T. Barr and
  John Shawe-Taylor
Categories: cs.LG stat.ML
\\ ( https://arxiv.org/abs/1905.10201 ,  2640kb)
------------------------------------------------------------------------------
\\
arXiv:1905.11286
replaced with revised version Thu, 6 Feb 2020 21:40:02 GMT   (506kb,D)

Title: Stochastic Gradient Methods with Layer-wise Adaptive Moments for
  Training of Deep Networks
Authors: Boris Ginsburg, Patrice Castonguay, Oleksii Hrinchuk, Oleksii
  Kuchaiev, Vitaly Lavrukhin, Ryan Leary, Jason Li, Huyen Nguyen, Yang Zhang,
  Jonathan M. Cohen
Categories: cs.LG stat.ML
Comments: Preprint, under review
\\ ( https://arxiv.org/abs/1905.11286 ,  506kb)
------------------------------------------------------------------------------
\\
arXiv:1905.12256
replaced with revised version Fri, 7 Feb 2020 05:06:07 GMT   (3117kb,D)

Title: DDP-GCN: Multi-Graph Convolutional Network for Spatiotemporal Traffic
  Forecasting
Authors: Kyungeun Lee, Wonjong Rhee
Categories: cs.LG eess.SP
\\ ( https://arxiv.org/abs/1905.12256 ,  3117kb)
------------------------------------------------------------------------------
\\
arXiv:1905.12430
replaced with revised version Fri, 7 Feb 2020 09:46:48 GMT   (167kb,D)

Title: Norm-based generalisation bounds for multi-class convolutional neural
  networks
Authors: Antoine Ledent and Yunwen Lei and Marius Kloft
Categories: cs.LG stat.ML
\\ ( https://arxiv.org/abs/1905.12430 ,  167kb)
------------------------------------------------------------------------------
\\
arXiv:1905.12790
replaced with revised version Fri, 7 Feb 2020 13:18:42 GMT   (1178kb,D)

Title: A Generalized Framework of Sequence Generation with Application to
  Undirected Sequence Models
Authors: Elman Mansimov, Alex Wang, Sean Welleck, Kyunghyun Cho
Categories: cs.LG cs.CL stat.ML
\\ ( https://arxiv.org/abs/1905.12790 ,  1178kb)
------------------------------------------------------------------------------
\\
arXiv:1905.13168
replaced with revised version Fri, 7 Feb 2020 06:35:53 GMT   (611kb,D)

Title: Confirmatory Bayesian Online Change Point Detection in the Covariance
  Structure of Gaussian Processes
Authors: Jiyeon Han, Kyowoon Lee, Anh Tong, Jaesik Choi
Categories: cs.LG stat.ML
Comments: IJCAI 2019 Comments: 12 pages, LaTeX; Revised conditions of Theorems
  in section 4, results unchanged
\\ ( https://arxiv.org/abs/1905.13168 ,  611kb)
------------------------------------------------------------------------------
\\
arXiv:1906.01527
replaced with revised version Fri, 7 Feb 2020 17:47:53 GMT   (680kb,D)

Title: Adversarial Training is a Form of Data-dependent Operator Norm
  Regularization
Authors: Kevin Roth, Yannic Kilcher and Thomas Hofmann
Categories: cs.LG stat.ML
\\ ( https://arxiv.org/abs/1906.01527 ,  680kb)
------------------------------------------------------------------------------
\\
arXiv:1909.11275
replaced with revised version Thu, 6 Feb 2020 22:05:51 GMT   (3346kb,D)

Title: Switched linear projections for neural network interpretability
Authors: Lech Szymanski, Brendan McCane, Craig Atkinson
Categories: cs.LG stat.ML
\\ ( https://arxiv.org/abs/1909.11275 ,  3346kb)
------------------------------------------------------------------------------
\\
arXiv:1910.00577
replaced with revised version Fri, 7 Feb 2020 09:07:27 GMT   (3959kb,D)

Title: Structural Language Models of Code
Authors: Uri Alon, Roy Sadaka, Omer Levy, Eran Yahav
Categories: cs.LG cs.PL stat.ML
\\ ( https://arxiv.org/abs/1910.00577 ,  3959kb)
------------------------------------------------------------------------------
\\
arXiv:1910.09464
replaced with revised version Fri, 7 Feb 2020 06:45:00 GMT   (1170kb,D)

Title: Learning to Learn by Zeroth-Order Oracle
Authors: Yangjun Ruan, Yuanhao Xiong, Sashank Reddi, Sanjiv Kumar, Cho-Jui
  Hsieh
Categories: cs.LG stat.ML
Comments: Published as a conference paper at ICLR 2020
\\ ( https://arxiv.org/abs/1910.09464 ,  1170kb)
------------------------------------------------------------------------------
\\
arXiv:1911.00995
replaced with revised version Fri, 7 Feb 2020 14:58:46 GMT   (6630kb,D)

Title: Novel semi-metrics for multivariate change point analysis and anomaly
  detection
Authors: Nick James, Max Menzies, Lamiae Azizi, Jennifer Chan
Categories: cs.LG math.DS stat.CO stat.ME stat.ML
Comments: Equal contribution from first two authors. v2 edits: restructuring
  and expression
\\ ( https://arxiv.org/abs/1911.00995 ,  6630kb)
------------------------------------------------------------------------------
\\
arXiv:1911.01291
replaced with revised version Fri, 7 Feb 2020 17:03:50 GMT   (1401kb,D)

Title: Ensembles of Locally Independent Prediction Models
Authors: Andrew Slavin Ross, Weiwei Pan, Leo Anthony Celi, Finale Doshi-Velez
Categories: cs.LG stat.ML
Comments: This is an expansion of arXiv:1806.08716 with different applications
  and focus, accepted to AAAI 2020. Latest update clarifies a derivation
\\ ( https://arxiv.org/abs/1911.01291 ,  1401kb)
------------------------------------------------------------------------------
\\
arXiv:1911.04384
replaced with revised version Fri, 7 Feb 2020 15:26:50 GMT   (205kb,D)

Title: Provably Convergent Two-Timescale Off-Policy Actor-Critic with Function
  Approximation
Authors: Shangtong Zhang, Bo Liu, Hengshuai Yao, Shimon Whiteson
Categories: cs.LG stat.ML
Comments: Optimization Foundations of Reinforcement Learning Workshop at
  NeurIPS 2019
\\ ( https://arxiv.org/abs/1911.04384 ,  205kb)
------------------------------------------------------------------------------
\\
arXiv:1911.10120
replaced with revised version Fri, 7 Feb 2020 10:42:24 GMT   (2559kb,D)

Title: Multi-Agent Thompson Sampling for Bandit Applications with Sparse
  Neighbourhood Structures
Authors: Timothy Verstraeten and Eugenio Bargiacchi and Pieter JK Libin and Jan
  Helsen and Diederik M Roijers and Ann Now\'e
Categories: cs.LG cs.AI cs.MA stat.ML
\\ ( https://arxiv.org/abs/1911.10120 ,  2559kb)
------------------------------------------------------------------------------
\\
arXiv:1911.11554
replaced with revised version Fri, 7 Feb 2020 18:21:22 GMT   (687kb,D)

Title: Multi-source Distilling Domain Adaptation
Authors: Sicheng Zhao, Guangzhi Wang, Shanghang Zhang, Yang Gu, Yaxian Li,
  Zhichao Song, Pengfei Xu, Runbo Hu, Hua Chai, Kurt Keutzer
Categories: cs.LG cs.CV stat.ML
Comments: Accepted by AAAI 2020
\\ ( https://arxiv.org/abs/1911.11554 ,  687kb)
------------------------------------------------------------------------------
\\
arXiv:1912.01667
replaced with revised version Fri, 7 Feb 2020 09:17:38 GMT   (1281kb,D)

Title: A Survey of Black-Box Adversarial Attacks on Computer Vision Models
Authors: Siddhant Bhambri, Sumanyu Muku, Avinash Tulasi, Arun Balaji Buduru
Categories: cs.LG cs.CR cs.CV stat.ML
Comments: 33 pages
\\ ( https://arxiv.org/abs/1912.01667 ,  1281kb)
------------------------------------------------------------------------------
\\
arXiv:1912.03049
replaced with revised version Fri, 7 Feb 2020 12:10:55 GMT   (443kb,D)

Title: Regularization Shortcomings for Continual Learning
Authors: Timoth\'ee Lesort, Andrei Stoian, David Filliat
Categories: cs.LG stat.ML
\\ ( https://arxiv.org/abs/1912.03049 ,  443kb)
------------------------------------------------------------------------------
\\
arXiv:2001.11113
replaced with revised version Fri, 7 Feb 2020 15:25:06 GMT   (454kb,D)

Title: GradientDICE: Rethinking Generalized Offline Estimation of Stationary
  Values
Authors: Shangtong Zhang, Bo Liu, Shimon Whiteson
Categories: cs.LG stat.ML
\\ ( https://arxiv.org/abs/2001.11113 ,  454kb)
------------------------------------------------------------------------------
\\
arXiv:2001.11739
replaced with revised version Fri, 7 Feb 2020 15:41:08 GMT   (5880kb,D)

Title: Local intrinsic dimensionality estimators based on concentration of
  measure
Authors: Jonathan Bac, Andrei Zinovyev
Categories: cs.LG stat.ML
\\ ( https://arxiv.org/abs/2001.11739 ,  5880kb)
------------------------------------------------------------------------------
\\
arXiv:2002.01633
replaced with revised version Fri, 7 Feb 2020 01:38:08 GMT   (599kb,D)

Title: Structural Deep Clustering Network
Authors: Deyu Bo, Xiao Wang, Chuan Shi, Meiqi Zhu, Emiao Lu and Peng Cui
Categories: cs.LG stat.ML
Comments: 10 pages
Journal-ref: WWW 2020
DOI: 10.1145/3366423.3380214
\\ ( https://arxiv.org/abs/2002.01633 ,  599kb)
------------------------------------------------------------------------------
\\
arXiv:2002.01711
replaced with revised version Fri, 7 Feb 2020 15:57:52 GMT   (3022kb,D)

Title: A Reinforcement Learning Framework for Time-Dependent Causal Effects
  Evaluation in A/B Testing
Authors: Chengchun Shi, Xiaoyu Wang, Shikai Luo, Rui Song, Hongtu Zhu, Jieping
  Ye
Categories: cs.LG stat.ML
\\ ( https://arxiv.org/abs/2002.01711 ,  3022kb)
------------------------------------------------------------------------------
\\
arXiv:2002.02158
replaced with revised version Fri, 7 Feb 2020 11:48:24 GMT   (219kb)

Title: Bridging Ordinary-Label Learning and Complementary-Label Learning
Authors: Yasuhiro Katsura, Masato Uchida
Categories: cs.LG stat.ML
MSC-class: 68T10
\\ ( https://arxiv.org/abs/2002.02158 ,  219kb)
------------------------------------------------------------------------------
\\
arXiv:2002.02286
replaced with revised version Fri, 7 Feb 2020 14:00:39 GMT   (6608kb,D)

Title: EgoMap: Projective mapping and structured egocentric memory for Deep RL
Authors: Edward Beeching, Christian Wolf, Jilles Dibangoye, Olivier Simonin
Categories: cs.LG cs.AI
\\ ( https://arxiv.org/abs/2002.02286 ,  6608kb)
------------------------------------------------------------------------------
\\
arXiv:1805.02724
replaced with revised version Fri, 7 Feb 2020 07:01:30 GMT   (78kb,D)

Title: Descriptive Complexity for Counting Complexity Classes
Authors: Marcelo Arenas, Martin Mu\~noz and Cristian Riveros
Categories: cs.LO
\\ ( https://arxiv.org/abs/1805.02724 ,  78kb)
------------------------------------------------------------------------------
\\
arXiv:1807.00785
replaced with revised version Fri, 7 Feb 2020 13:53:28 GMT   (1172kb,D)

Title: Rule Algebras for Adhesive Categories
Authors: Nicolas Behr and Pawel Sobocinski
Categories: cs.LO cs.DM math.CO math.CT
Comments: 38 pages, LMCS style; invited extended journal version of
  10.4230/LIPIcs.CSL.2018.11 (cf. V1 -- short version published in the
  Proceedings of the 27th EACSL Annual Conference on Computer Science Logic,
  CSL 2018); V3: Theorem 1.15 replaced; references, further examples and many
  explanations added, typos fixed; main results unchanged
MSC-class: 16B50, 60J27, 68Q42 (Primary) 60J28, 16B50, 05E99 (Secondary)
ACM-class: F.4.2; G.3; G.2.2
\\ ( https://arxiv.org/abs/1807.00785 ,  1172kb)
------------------------------------------------------------------------------
\\
arXiv:1907.05706
replaced with revised version Fri, 7 Feb 2020 13:27:37 GMT   (52kb)

Title: Intersection Types for the Computational lambda-Calculus
Authors: Ugo de'Liguoro and Riccardo Treglia
Categories: cs.LO
ACM-class: F.3.2; F.4.1
\\ ( https://arxiv.org/abs/1907.05706 ,  52kb)
------------------------------------------------------------------------------
\\
arXiv:2002.01865
replaced with revised version Thu, 6 Feb 2020 22:06:42 GMT   (26kb)

Title: Completing Simple Valuations in K-categories
Authors: Xiaodong Jia and Michael Mislove
Categories: cs.LO
Comments: 34 pages, 17 figures
MSC-class: 06B30, 06B35, 06D723, 68Q55
ACM-class: F.3.2
\\ ( https://arxiv.org/abs/2002.01865 ,  26kb)
------------------------------------------------------------------------------
\\
arXiv:1811.03404
replaced with revised version Fri, 7 Feb 2020 09:02:17 GMT   (2691kb,D)

Title: Vlasov-Poisson system tackled by particle simulation utilising boundary
  element methods
Authors: Torsten Ke{\ss}ler and Sergej Rjasanow and Steffen Wei{\ss}er
Categories: math.NA cs.NA
Comments: final draft post-refereeing
MSC-class: 35Q83, 65Z05, 65N75, 65N38, 68W25
\\ ( https://arxiv.org/abs/1811.03404 ,  2691kb)
------------------------------------------------------------------------------
\\
arXiv:1908.08772
replaced with revised version Fri, 7 Feb 2020 14:36:44 GMT   (55kb)

Title: Convergence rates of monotone schemes for conservation laws with
  discontinuous flux
Authors: Jayesh Badwaik and Adrian Montgomery Ruf
Categories: math.NA cs.NA
Comments: 24 pages, 6 figures, 2 tables; The article is published in SIAM
  Journal on Numerical Analysis. The final publication is available at
  https://epubs.siam.org/doi/abs/10.1137/19M1283276
MSC-class: 35L65, 65M08, 65M12, 35R05
Journal-ref: SIAM J. Numer. Anal. 58 (2020) 607-629
DOI: 10.1137/19M1283276
\\ ( https://arxiv.org/abs/1908.08772 ,  55kb)
------------------------------------------------------------------------------
\\
arXiv:1909.06807
replaced with revised version Fri, 7 Feb 2020 05:19:39 GMT   (17kb)

Title: Direct and inverse results for Kantorovich type exponential sampling
  series
Authors: Sathish Kumar Angamuthu and Shivam Bajpeyi
Categories: math.NA cs.NA math.FA
\\ ( https://arxiv.org/abs/1909.06807 ,  17kb)
------------------------------------------------------------------------------
\\
arXiv:1910.12571
replaced with revised version Fri, 7 Feb 2020 06:33:03 GMT   (11kb)

Title: Tractability properties of the discrepancy in Orlicz norms
Authors: Josef Dick and Aicke Hinrichs and Friedrich Pillichshammer and Joscha
  Prochno
Categories: math.NA cs.NA math.NT
Comments: 10 pages
MSC-class: 11K38, 65C05, 65Y20
DOI: 10.1016/j.jco.2020.101468
\\ ( https://arxiv.org/abs/1910.12571 ,  11kb)
------------------------------------------------------------------------------
\\
arXiv:1912.08177
replaced with revised version Fri, 7 Feb 2020 14:55:26 GMT   (238kb,D)

Title: Lift & Learn: Physics-informed machine learning for large-scale
  nonlinear dynamical systems
Authors: Elizabeth Qian, Boris Kramer, Benjamin Peherstorfer, Karen Willcox
Categories: math.NA cs.LG cs.NA
\\ ( https://arxiv.org/abs/1912.08177 ,  238kb)
------------------------------------------------------------------------------
\\
arXiv:2002.02273
replaced with revised version Fri, 7 Feb 2020 09:40:13 GMT   (610kb)

Title: Optimal Control of Sliding Droplets using the Contact Angle Distribution
Authors: Henning Bonart and Christian Kahle
Categories: math.NA cs.NA math.AP math.OC
\\ ( https://arxiv.org/abs/2002.02273 ,  610kb)
------------------------------------------------------------------------------
\\
arXiv:1908.03532
replaced with revised version Fri, 7 Feb 2020 13:56:30 GMT   (2710kb,D)

Title: One-time learning in a biologically-inspired Salience-affected
  Artificial Neural Network (SANN)
Authors: Leendert A Remmelzwaal, George F R Ellis, Jonathan Tapson
Categories: cs.NE q-bio.NC
\\ ( https://arxiv.org/abs/1908.03532 ,  2710kb)
------------------------------------------------------------------------------
\\
arXiv:1906.00245
replaced with revised version Fri, 7 Feb 2020 02:24:50 GMT   (2037kb,D)

Title: Blockchain for Internet of Things: A Survey
Authors: Hong-Ning Dai and Zibin Zheng and Yan Zhang
Categories: cs.NI cs.DC cs.SE
Comments: 19 pages, 9 figures
ACM-class: C.2.4; D.2.11; E.3; J.3
Journal-ref: IEEE Internet of Things Journal, Vol. 6, No. 5, Oct. 2019
DOI: 10.1109/JIOT.2019.2920987
\\ ( https://arxiv.org/abs/1906.00245 ,  2037kb)
------------------------------------------------------------------------------
\\
arXiv:1903.05149
replaced with revised version Thu, 6 Feb 2020 19:38:05 GMT   (724kb,D)

Title: STRATA: A Unified Framework for Task Assignments in Large Teams of
  Heterogeneous Agents
Authors: Harish Ravichandar, Kenneth Shaw, Sonia Chernova
Categories: cs.RO cs.MA
\\ ( https://arxiv.org/abs/1903.05149 ,  724kb)
------------------------------------------------------------------------------
\\
arXiv:1908.03790
replaced with revised version Thu, 6 Feb 2020 19:34:14 GMT   (153kb,D)

Title: Towards Online Observability-Aware Trajectory Optimization for
  Landmark-based Estimators
Authors: Kristoffer M. Frey, Ted J. Steiner, and Jonathan P. How
Categories: cs.RO
Comments: 16 pages
\\ ( https://arxiv.org/abs/1908.03790 ,  153kb)
------------------------------------------------------------------------------
\\
arXiv:1909.00779
replaced with revised version Fri, 7 Feb 2020 12:12:51 GMT   (1547kb,D)

Title: qiBullet, a Bullet-based simulator for the Pepper and NAO robots
Authors: Maxime Busy, Maxime Caniot
Categories: cs.RO
Comments: 4 pages, 5 figures
ACM-class: I.2.9; I.2.5; I.6.0
\\ ( https://arxiv.org/abs/1909.00779 ,  1547kb)
------------------------------------------------------------------------------
\\
arXiv:1909.10737
replaced with revised version Fri, 7 Feb 2020 05:47:39 GMT   (5242kb,D)

Title: Multi-agent Interactive Prediction under Challenging Driving Scenarios
Authors: Weihao Xuan, Ruijie Ren, Yeping Hu
Categories: cs.RO cs.LG cs.MA
Comments: submitted to IV 2020
\\ ( https://arxiv.org/abs/1909.10737 ,  5242kb)
------------------------------------------------------------------------------
\\
arXiv:2002.01779
replaced with revised version Thu, 6 Feb 2020 15:13:52 GMT   (3934kb)

Title: Human Posture Recognition and Gesture Imitation with a Humanoid Robot
Authors: Amir Aly
Categories: cs.RO cs.CV
Comments: 65 Pages. arXiv admin note: text overlap with arXiv:0910.2540 by
  other authors
MSC-class: 14J60 (Robotics)
ACM-class: F.2.2
\\ ( https://arxiv.org/abs/2002.01779 ,  3934kb)
------------------------------------------------------------------------------
\\
arXiv:1908.02590
replaced with revised version Fri, 7 Feb 2020 11:47:41 GMT   (669kb,D)

Title: Audio-visual Speech Enhancement Using Conditional Variational
  Auto-Encoder
Authors: Mostafa Sadeghi, Simon Leglaive, Xavier Alameda-PIneda, Laurent Girin
  and Radu Horaud
Categories: cs.SD cs.LG eess.AS
Comments: Submitted to IEEE/ACM Transactions on Audio, Speech, and Language
  Processing
\\ ( https://arxiv.org/abs/1908.02590 ,  669kb)
------------------------------------------------------------------------------
\\
arXiv:1908.06468
replaced with revised version Thu, 6 Feb 2020 23:28:51 GMT   (4027kb,D)

Title: A Dual-Staged Context Aggregation Method Towards Efficient End-To-End
  Speech Enhancement
Authors: Kai Zhen, Mi Suk Lee, Minje Kim
Categories: cs.SD cs.LG eess.AS
Comments: Accepted in Proceedings of the ICASSP, Barcelona, Spain, May 4-8,
  2020
\\ ( https://arxiv.org/abs/1908.06468 ,  4027kb)
------------------------------------------------------------------------------
\\
arXiv:1912.10093
replaced with revised version Fri, 7 Feb 2020 01:51:42 GMT   (197kb,D)

Title: Assessing Practitioner Beliefs about Software Defect Prediction
Authors: N.C. Shrikanth and Tim Menzies
Categories: cs.SE
Comments: 9 pages, 3 Figures, 4 Tables, ICSE SEIP 2020
DOI: 10.1145/3377813.3381367
\\ ( https://arxiv.org/abs/1912.10093 ,  197kb)
------------------------------------------------------------------------------
\\
arXiv:1905.04448
replaced with revised version Thu, 6 Feb 2020 20:31:05 GMT   (610kb)

Title: Influencing Opinions of Heterogeneous Populations over Finite Time
  Horizons
Authors: Arunabh Saxena, Bhumesh Kumar, Anmol Gupta, Neeraja Sahasrabudhe and
  Sharayu Moharir
Categories: cs.SI cs.SY
\\ ( https://arxiv.org/abs/1905.04448 ,  610kb)
------------------------------------------------------------------------------
\\
arXiv:1905.10683
replaced with revised version Fri, 7 Feb 2020 16:16:31 GMT   (1997kb,D)

Title: Measuring Directed Triadic Closure with Closure Coefficients
Authors: Hao Yin, Austin R. Benson, Johan Ugander
Categories: cs.SI physics.soc-ph
\\ ( https://arxiv.org/abs/1905.10683 ,  1997kb)
------------------------------------------------------------------------------
\\
arXiv:1909.09037
replaced with revised version Thu, 6 Feb 2020 20:21:54 GMT   (3432kb,D)

Title: Moments of Uniform Random Multigraphs with Fixed Degree Sequences
Authors: Philip S. Chodrow
Categories: cs.SI math.PR physics.data-an physics.soc-ph
Comments: 31 pages, 5 figures, 5 pages of supplementary material
MSC-class: 05C80, 05C82, 91D30, 62-07, 65C05
\\ ( https://arxiv.org/abs/1909.09037 ,  3432kb)
------------------------------------------------------------------------------
\\
arXiv:2001.07849 (*cross-listing*)
replaced with revised version Fri, 7 Feb 2020 10:16:28 GMT   (9332kb,D)

Title: Unsupervised Representation Disentanglement using Cross Domain Features
  and Adversarial Learning in Variational Autoencoder based Voice Conversion
Authors: Wen-Chin Huang, Hao Luo, Hsin-Te Hwang, Chen-Chou Lo, Yu-Huai Peng, Yu
  Tsao, Hsin-Min Wang
Categories: eess.AS cs.CL cs.LG cs.SD
Comments: Accepted to IEEE Transactions on Emerging Topics in Computational
  Intelligence
\\ ( https://arxiv.org/abs/2001.07849 ,  9332kb)
------------------------------------------------------------------------------
\\
arXiv:2001.11838 (*cross-listing*)
replaced with revised version Fri, 7 Feb 2020 12:53:54 GMT   (14kb)

Title: The time-adaptive statistical testing for random number generators
Authors: Boris Ryabko
Categories: math.ST cs.CR stat.TH
Comments: arXiv admin note: text overlap with arXiv:1912.06542
\\ ( https://arxiv.org/abs/2001.11838 ,  14kb)
------------------------------------------------------------------------------
\\
arXiv:1912.06013 (*cross-listing*)
replaced with revised version Fri, 7 Feb 2020 17:01:17 GMT   (5437kb,D)

Title: An Approach to Super-Resolution of Sentinel-2 Images Based on Generative
  Adversarial Networks
Authors: Kexin Zhang, Gencer Sumbul, Beg\"um Demir
Categories: eess.IV cs.CV
Comments: Accepted at IEEE Mediterranean and Middle-East Geoscience and Remote
  Sensing Symposium (M2GARSS) 2020
\\ ( https://arxiv.org/abs/1912.06013 ,  5437kb)
------------------------------------------------------------------------------
\\
arXiv:1908.01524 (*cross-listing*)
replaced with revised version Fri, 7 Feb 2020 08:41:33 GMT   (47kb,D)

Title: Recognizing and realizing cactus metrics
Authors: Momoko Hayamizu, Katharina T. Huber, Vincent Moulton, Yukihiro
  Murakami
Categories: math.CO cs.DM
Comments: 7 pages, 2 figures
\\ ( https://arxiv.org/abs/1908.01524 ,  47kb)
------------------------------------------------------------------------------
\\
arXiv:1908.03169 (*cross-listing*)
replaced with revised version Thu, 6 Feb 2020 20:38:44 GMT   (19kb)

Title: The repetition threshold for binary rich words
Authors: James D. Currie and Lucas Mol and Narad Rampersad
Categories: math.CO cs.FL
Comments: 16 pages
MSC-class: 68R15
\\ ( https://arxiv.org/abs/1908.03169 ,  19kb)
------------------------------------------------------------------------------
\\
arXiv:1802.04672 (*cross-listing*)
replaced with revised version Fri, 7 Feb 2020 08:22:54 GMT   (466kb,D)

Title: Delta-Ramp Encoder for Amplitude Sampling and its Interpretation as Time
  Encoding
Authors: Pablo Mart\'inez-Nuevo, Hsin-Yu Lai, Alan V. Oppenheim
Categories: eess.SP cs.IT math.CV math.IT
Comments: 12 pages, 11 figures, journal paper
MSC-class: 30D20 (Primary) 30D15 (Secondary)
ACM-class: H.1.0; H.1.1; E.4
DOI: 10.1109/TSP.2019.2904027
\\ ( https://arxiv.org/abs/1802.04672 ,  466kb)
------------------------------------------------------------------------------
\\
arXiv:1908.01596 (*cross-listing*)
replaced with revised version Fri, 7 Feb 2020 13:59:20 GMT   (1298kb,D)

Title: A Class of Doubly Stochastic Shift Operators for Random Graph Signals
  and their Boundedness
Authors: Bruno Scalzo Dees, Ljubisa Stankovic, Milos Dakovic, Anthony G.
  Constantinides, Danilo P. Mandic
Categories: eess.SP cs.IT math.IT
Comments: 5 pages, 1 figure
\\ ( https://arxiv.org/abs/1908.01596 ,  1298kb)
------------------------------------------------------------------------------
\\
arXiv:1912.12827 (*cross-listing*)
replaced with revised version Fri, 7 Feb 2020 02:51:21 GMT   (20kb)

Title: Max-Min Fairness in IRS-Aided Multi-Cell MISO Systems via Joint Transmit
  and Reflective Beamforming
Authors: Hailiang Xie, Jie Xu, and Ya-Feng Liu
Categories: eess.SP cs.IT math.IT
Comments: The paper has been accepted by International Conference on
  Communications (ICC) 2020
\\ ( https://arxiv.org/abs/1912.12827 ,  20kb)
------------------------------------------------------------------------------
\\
arXiv:2001.08519 (*cross-listing*)
replaced with revised version Fri, 7 Feb 2020 02:59:30 GMT   (329kb)

Title: $(p,q)$-frames in shift-invariant subspaces of mixed Lebesgue spaces
  $L^{p,q}(\mathbf{R}\times \mathbf{R}^{d})$
Authors: Yingchun Jiang and Jiao Li
Categories: math.FA cs.IT math.CA math.IT
\\ ( https://arxiv.org/abs/2001.08519 ,  329kb)
------------------------------------------------------------------------------
\\
arXiv:1802.07051 (*cross-listing*)
replaced with revised version Fri, 7 Feb 2020 05:49:25 GMT   (2507kb,D)

Title: On Learning Causal Structures from Non-Experimental Data without Any
  Faithfulness Assumption
Authors: Hanti Lin and Jiji Zhang
Categories: stat.ML cs.LG
Comments: To be published in Proceedings of Machine Learning Research, volume
  117
\\ ( https://arxiv.org/abs/1802.07051 ,  2507kb)
------------------------------------------------------------------------------
\\
arXiv:1805.07852 (*cross-listing*)
replaced with revised version Thu, 6 Feb 2020 22:37:23 GMT   (766kb,D)

Title: Accelerated Bayesian Optimization throughWeight-Prior Tuning
Authors: Alistair Shilton, Sunil Gupta, Santu Rana, Pratibha Vellanki, Laurence
  Park, Cheng Li, Svetha Venkatesh, Alessandra Sutti, David Rubin, Thomas
  Dorin, Alireza Vahid, Murray Height, Teo Slezak
Categories: stat.ML cs.LG
\\ ( https://arxiv.org/abs/1805.07852 ,  766kb)
------------------------------------------------------------------------------
\\
arXiv:1905.02685 (*cross-listing*)
replaced with revised version Fri, 7 Feb 2020 15:24:01 GMT   (2608kb,D)

Title: Knowing The What But Not The Where in Bayesian Optimization
Authors: Vu Nguyen and Michael A. Osborne
Categories: stat.ML cs.LG
Comments: 16 pages
\\ ( https://arxiv.org/abs/1905.02685 ,  2608kb)
------------------------------------------------------------------------------
\\
arXiv:1906.03886 (*cross-listing*)
replaced with revised version Fri, 7 Feb 2020 18:20:09 GMT   (4789kb,D)

Title: Goodness-of-fit Test for Latent Block Models
Authors: Chihiro Watanabe, Taiji Suzuki
Categories: stat.ML cs.LG
\\ ( https://arxiv.org/abs/1906.03886 ,  4789kb)
------------------------------------------------------------------------------
\\
arXiv:1910.01544 (*cross-listing*)
replaced with revised version Fri, 7 Feb 2020 13:50:51 GMT   (228kb,D)

Title: Robust Risk Minimization for Statistical Learning
Authors: Muhammad Osama, Dave Zachariah, Peter Stoica
Categories: stat.ML cs.LG eess.SP
\\ ( https://arxiv.org/abs/1910.01544 ,  228kb)
------------------------------------------------------------------------------
\\
arXiv:1910.08408 (*cross-listing*)
replaced with revised version Fri, 7 Feb 2020 14:21:35 GMT   (1987kb,D)

Title: Identification of Model Uncertainty via Optimal Design of Experiments
  applied to a Mechanical Press
Authors: Tristan Gally, Peter Groche, Florian Hoppe, Anja Kuttich, Alexander
  Matei, Marc E. Pfetsch, Martin Rakowitsch, Stefan Ulbrich
Categories: stat.ML cs.LG math.OC stat.AP
\\ ( https://arxiv.org/abs/1910.08408 ,  1987kb)
------------------------------------------------------------------------------
\\
arXiv:1910.11617 (*cross-listing*)
replaced with revised version Fri, 7 Feb 2020 18:44:12 GMT   (10859kb,D)

Title: Mobile Traffic Classification through Physical Channel Fingerprinting: a
  Deep Learning Approach
Authors: Hoang Duy Trinh, Angel Fernandez Gambin, Lorenza Giupponi, Michele
  Rossi, Paolo Dini
Categories: eess.SP cs.LG stat.ML
\\ ( https://arxiv.org/abs/1910.11617 ,  10859kb)
------------------------------------------------------------------------------
\\
arXiv:1912.00331 (*cross-listing*)
replaced with revised version Fri, 7 Feb 2020 03:16:16 GMT   (293kb,D)

Title: Inverse Cognitive Radar -- A Revealed Preferences Approach
Authors: Vikram Krishnamurthy and Daniel Angley and Robin Evans and William
  Moran
Categories: eess.SP cs.LG
\\ ( https://arxiv.org/abs/1912.00331 ,  293kb)
------------------------------------------------------------------------------
\\
arXiv:2001.01395 (*cross-listing*)
replaced with revised version Fri, 7 Feb 2020 16:19:04 GMT   (1660kb)

Title: Accumulated Polar Feature-based Deep Learning for Efficient and
  Lightweight Automatic Modulation Classification with Channel Compensation
  Mechanism
Authors: Chieh-Fang Teng, Ching-Yao Chou, Chun-Hsiang Chen, and An-Yeu Wu
Categories: eess.SP cs.LG
Comments: 13 pages, 13 figures, 8 tables
\\ ( https://arxiv.org/abs/2001.01395 ,  1660kb)
------------------------------------------------------------------------------
\\
arXiv:2001.07034 (*cross-listing*)
replaced with revised version Fri, 7 Feb 2020 09:32:10 GMT   (76kb,D)

Title: Pairwise Discriminative Neural PLDA for Speaker Verification
Authors: Shreyas Ramoji, Prashant Krishnan V, Prachi Singh, Sriram Ganapathy
Categories: eess.AS cs.LG cs.SD eess.SP
Comments: This paper was submitted to IEEE International Conference on
  Acoustics, Speech, and Signal Processing (ICASSP) 2020. Link to GitHub
  Repository: https://github.com/iiscleap/NeuralPlda
\\ ( https://arxiv.org/abs/2001.07034 ,  76kb)
------------------------------------------------------------------------------
\\
arXiv:2001.10616 (*cross-listing*)
replaced with revised version Fri, 7 Feb 2020 16:09:52 GMT   (966kb,D)

Title: On Newton Screening
Authors: Jian Huang, Yuling Jiao, Lican Kang, Jin Liu, Yanyan Liu, Xiliang Lu,
  and Yuanyuan Yang
Categories: stat.ML cs.LG math.OC stat.ME
\\ ( https://arxiv.org/abs/2001.10616 ,  966kb)
------------------------------------------------------------------------------
\\
arXiv:1907.11608 (*cross-listing*)
replaced with revised version Fri, 7 Feb 2020 03:16:08 GMT   (1176kb,D)

Title: Fitting In and Breaking Up: A Nonlinear Version of Coevolving Voter
  Models
Authors: Yacoub H. Kureh and Mason A. Porter
Categories: physics.soc-ph cond-mat.stat-mech cs.SI math.DS nlin.AO
\\ ( https://arxiv.org/abs/1907.11608 ,  1176kb)
%%%---%%%---%%%---%%%---%%%---%%%---%%%---%%%---%%%---%%%---%%%---%%%---%%%---